{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp keras.experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "> The code implementing the experiments in the paper:\n",
    "> \n",
    "> Davor Runje, Sharath M. Shankaranarayana. <i>Constrained Monotonic Neural Networks</i>. 40th International Conference on Machine Learning, 2023.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "import shutil\n",
    "import urllib.request\n",
    "from contextlib import contextmanager\n",
    "from datetime import datetime\n",
    "from os import environ\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import *\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytest\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras_tuner import (\n",
    "    BayesianOptimization,\n",
    "    HyperModel,\n",
    "    HyperParameters,\n",
    "    Objective,\n",
    "    Tuner,\n",
    ")\n",
    "from numpy.typing import ArrayLike, NDArray\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.backend import count_params\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers.experimental import AdamW\n",
    "from tensorflow.types.experimental import TensorLike\n",
    "from tqdm import tqdm\n",
    "\n",
    "from airt.keras.layers import MonoDense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "For our experiments, we employ the datasets used by the authors of Certified Monotonic Network [1] and COMET [2]. We use the exact train-test split provided by the authors. Their respective repositories are linked below in the references. We directly load the saved train-test data split which have been saved after running the codes from respective papers' authors. \n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "\n",
    "1.   Xingchao Liu, Xing Han, Na Zhang, and Qiang Liu. Certified monotonic neural networks. Advances in Neural Information Processing Systems, 33:15427–15438, 2020\n",
    "  \n",
    "  Github repo: https://github.com/gnobitab/CertifiedMonotonicNetwork\n",
    "\n",
    "\n",
    "\n",
    "2.   Aishwarya Sivaraman, Golnoosh Farnadi, Todd Millstein, and Guy Van den Broeck. Counterexample-guided learning of monotonic neural networks. Advances in Neural Information Processing Systems, 33:11936–11948, 2020\n",
    "\n",
    "  Github repo: https://github.com/AishwaryaSivaraman/COMET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "\n",
    "class _DownloadProgressBar(tqdm):\n",
    "    def update_to(\n",
    "        self, b: int = 1, bsize: int = 1, tsize: Optional[int] = None\n",
    "    ) -> None:\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "\n",
    "def _download_url(url: str, output_path: Path) -> None:\n",
    "    with _DownloadProgressBar(\n",
    "        unit=\"B\", unit_scale=True, miniters=1, desc=url.split(\"/\")[-1]\n",
    "    ) as t:\n",
    "        # nosemgrep: python.lang.security.audit.dynamic-urllib-use-detected.dynamic-urllib-use-detected\n",
    "        urllib.request.urlretrieve(\n",
    "            url, filename=output_path, reporthook=t.update_to\n",
    "        )  # nosec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "\n",
    "def _get_data_path(data_path: Optional[Union[Path, str]] = None) -> Path:\n",
    "    if data_path is None:\n",
    "        data_path = \"./data\"\n",
    "    return Path(data_path)\n",
    "\n",
    "\n",
    "def _download_data(\n",
    "    dataset_name: str,\n",
    "    data_path: Optional[Union[Path, str]] = \"data\",\n",
    "    force_download: bool = False,\n",
    ") -> None:\n",
    "    data_path = _get_data_path(data_path)\n",
    "    data_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    for prefix in [\"train\", \"test\"]:\n",
    "        filename = f\"{prefix}_{dataset_name}.csv\"\n",
    "        if not (data_path / filename).exists() or force_download:\n",
    "            with TemporaryDirectory() as d:\n",
    "                _download_url(\n",
    "                    f\"https://zenodo.org/record/7968969/files/{filename}\",\n",
    "                    Path(d) / filename,\n",
    "                )\n",
    "                shutil.copyfile(Path(d) / filename, data_path / filename)\n",
    "        else:\n",
    "            print(f\"Upload skipped, file {(data_path / filename).resolve()} exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_auto.csv: 49.2kB [00:01, 48.4kB/s]                            \n",
      "test_auto.csv: 16.4kB [00:00, 20.2kB/s]                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 257812\r\n",
      "-rw-rw-r-- 1 davor davor    11161 Jun  2 13:28 test_auto.csv\r\n",
      "-rw-rw-r-- 1 davor davor 11340054 May 25 04:48 test_blog.csv\r\n",
      "-rw-rw-r-- 1 davor davor   101210 May 25 04:48 test_compas.csv\r\n",
      "-rw-rw-r-- 1 davor davor    15798 May 25 04:48 test_heart.csv\r\n",
      "-rw-rw-r-- 1 davor davor 13339777 May 25 04:48 test_loan.csv\r\n",
      "-rw-rw-r-- 1 davor davor    44626 Jun  2 13:28 train_auto.csv\r\n",
      "-rw-rw-r-- 1 davor davor 79478767 May 25 04:48 train_blog.csv\r\n",
      "-rw-rw-r-- 1 davor davor   405660 May 25 04:48 train_compas.csv\r\n",
      "-rw-rw-r-- 1 davor davor    62282 May 25 04:48 train_heart.csv\r\n",
      "-rw-rw-r-- 1 davor davor 79588030 May 25 04:48 train_loan.csv\r\n",
      "-rw-rw-r-- 1 davor davor 79588030 May 29 13:57 {prefix}_{name}.csv\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_download_data(\"auto\", force_download=True)\n",
    "\n",
    "!ls -l data\n",
    "\n",
    "assert (Path(\"data\") / \"train_auto.csv\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "\n",
    "def _sanitize_col_names(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    columns = {c: c.replace(\" \", \"_\") for c in df}\n",
    "    df = df.rename(columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a_b\n",
       "0    1\n",
       "1    2\n",
       "2    3"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_sanitize_col_names(pd.DataFrame({\"a b\": [1, 2, 3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def get_train_n_test_data(\n",
    "    dataset_name: str,\n",
    "    *,\n",
    "    data_path: Optional[Union[Path, str]] = \"./data\",\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Download data\n",
    "\n",
    "    Args:\n",
    "        dataset_name: name of the dataset, one of \"auto\", \"heart\", compas\", \"blog\", \"loan\"\n",
    "        data_path: root directory where to download data to\n",
    "    \"\"\"\n",
    "    data_path = _get_data_path(data_path)\n",
    "    _download_data(dataset_name=dataset_name, data_path=data_path)\n",
    "\n",
    "    dfx = [\n",
    "        pd.read_csv(data_path / f\"{prefix}_{dataset_name}.csv\")\n",
    "        for prefix in [\"train\", \"test\"]\n",
    "    ]\n",
    "    dfx = [_sanitize_col_names(df) for df in dfx]\n",
    "    return dfx[0], dfx[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload skipped, file /home/davor/work/projects/airt/mono-dense-keras/nbs/data/train_auto.csv exists.\n",
      "Upload skipped, file /home/davor/work/projects/airt/mono-dense-keras/nbs/data/test_auto.csv exists.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model_Year</th>\n",
       "      <th>Origin</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.482807</td>\n",
       "      <td>1.073028</td>\n",
       "      <td>0.650564</td>\n",
       "      <td>0.606625</td>\n",
       "      <td>-1.275546</td>\n",
       "      <td>-1.631803</td>\n",
       "      <td>-0.701669</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.482807</td>\n",
       "      <td>1.482902</td>\n",
       "      <td>1.548993</td>\n",
       "      <td>0.828131</td>\n",
       "      <td>-1.452517</td>\n",
       "      <td>-1.631803</td>\n",
       "      <td>-0.701669</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.482807</td>\n",
       "      <td>1.044432</td>\n",
       "      <td>1.163952</td>\n",
       "      <td>0.523413</td>\n",
       "      <td>-1.275546</td>\n",
       "      <td>-1.631803</td>\n",
       "      <td>-0.701669</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.482807</td>\n",
       "      <td>1.025368</td>\n",
       "      <td>0.907258</td>\n",
       "      <td>0.542165</td>\n",
       "      <td>-1.806460</td>\n",
       "      <td>-1.631803</td>\n",
       "      <td>-0.701669</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.482807</td>\n",
       "      <td>2.235927</td>\n",
       "      <td>2.396084</td>\n",
       "      <td>1.587581</td>\n",
       "      <td>-1.983431</td>\n",
       "      <td>-1.631803</td>\n",
       "      <td>-0.701669</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0.310007</td>\n",
       "      <td>0.358131</td>\n",
       "      <td>0.188515</td>\n",
       "      <td>-0.177437</td>\n",
       "      <td>-0.319901</td>\n",
       "      <td>1.720778</td>\n",
       "      <td>-0.701669</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>-0.862792</td>\n",
       "      <td>-0.566468</td>\n",
       "      <td>-0.530229</td>\n",
       "      <td>-0.722413</td>\n",
       "      <td>-0.921604</td>\n",
       "      <td>1.720778</td>\n",
       "      <td>-0.701669</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>-0.862792</td>\n",
       "      <td>-0.928683</td>\n",
       "      <td>-1.351650</td>\n",
       "      <td>-1.003691</td>\n",
       "      <td>3.184131</td>\n",
       "      <td>1.720778</td>\n",
       "      <td>0.557325</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>-0.862792</td>\n",
       "      <td>-0.566468</td>\n",
       "      <td>-0.530229</td>\n",
       "      <td>-0.810312</td>\n",
       "      <td>-1.417123</td>\n",
       "      <td>1.720778</td>\n",
       "      <td>-0.701669</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>-0.862792</td>\n",
       "      <td>-0.709448</td>\n",
       "      <td>-0.658576</td>\n",
       "      <td>-0.423555</td>\n",
       "      <td>1.060475</td>\n",
       "      <td>1.720778</td>\n",
       "      <td>-0.701669</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cylinders  Displacement  Horsepower    Weight  Acceleration  Model_Year  \\\n",
       "0     1.482807      1.073028    0.650564  0.606625     -1.275546   -1.631803   \n",
       "1     1.482807      1.482902    1.548993  0.828131     -1.452517   -1.631803   \n",
       "2     1.482807      1.044432    1.163952  0.523413     -1.275546   -1.631803   \n",
       "3     1.482807      1.025368    0.907258  0.542165     -1.806460   -1.631803   \n",
       "4     1.482807      2.235927    2.396084  1.587581     -1.983431   -1.631803   \n",
       "..         ...           ...         ...       ...           ...         ...   \n",
       "309   0.310007      0.358131    0.188515 -0.177437     -0.319901    1.720778   \n",
       "310  -0.862792     -0.566468   -0.530229 -0.722413     -0.921604    1.720778   \n",
       "311  -0.862792     -0.928683   -1.351650 -1.003691      3.184131    1.720778   \n",
       "312  -0.862792     -0.566468   -0.530229 -0.810312     -1.417123    1.720778   \n",
       "313  -0.862792     -0.709448   -0.658576 -0.423555      1.060475    1.720778   \n",
       "\n",
       "       Origin  ground_truth  \n",
       "0   -0.701669          18.0  \n",
       "1   -0.701669          15.0  \n",
       "2   -0.701669          16.0  \n",
       "3   -0.701669          17.0  \n",
       "4   -0.701669          15.0  \n",
       "..        ...           ...  \n",
       "309 -0.701669          22.0  \n",
       "310 -0.701669          36.0  \n",
       "311  0.557325          44.0  \n",
       "312 -0.701669          32.0  \n",
       "313 -0.701669          28.0  \n",
       "\n",
       "[314 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model_Year</th>\n",
       "      <th>Origin</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862792</td>\n",
       "      <td>-1.043066</td>\n",
       "      <td>-1.017947</td>\n",
       "      <td>-1.027131</td>\n",
       "      <td>1.272841</td>\n",
       "      <td>1.162014</td>\n",
       "      <td>1.816319</td>\n",
       "      <td>40.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.482807</td>\n",
       "      <td>1.177880</td>\n",
       "      <td>1.163952</td>\n",
       "      <td>0.526929</td>\n",
       "      <td>-1.629489</td>\n",
       "      <td>-1.631803</td>\n",
       "      <td>-0.701669</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.482807</td>\n",
       "      <td>1.482902</td>\n",
       "      <td>1.934034</td>\n",
       "      <td>0.794143</td>\n",
       "      <td>-1.629489</td>\n",
       "      <td>-0.793657</td>\n",
       "      <td>-0.701669</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.310007</td>\n",
       "      <td>0.529707</td>\n",
       "      <td>-0.119518</td>\n",
       "      <td>0.346443</td>\n",
       "      <td>-0.213718</td>\n",
       "      <td>-1.352421</td>\n",
       "      <td>-0.701669</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.862792</td>\n",
       "      <td>-1.004939</td>\n",
       "      <td>-0.863931</td>\n",
       "      <td>-1.243949</td>\n",
       "      <td>-0.567661</td>\n",
       "      <td>0.882633</td>\n",
       "      <td>0.557325</td>\n",
       "      <td>31.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>-0.862792</td>\n",
       "      <td>-0.699916</td>\n",
       "      <td>0.188515</td>\n",
       "      <td>-0.062582</td>\n",
       "      <td>-0.390690</td>\n",
       "      <td>-1.073039</td>\n",
       "      <td>0.557325</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-0.862792</td>\n",
       "      <td>-0.518809</td>\n",
       "      <td>-0.838261</td>\n",
       "      <td>-0.686081</td>\n",
       "      <td>1.379024</td>\n",
       "      <td>-0.793657</td>\n",
       "      <td>-0.701669</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.310007</td>\n",
       "      <td>-0.251914</td>\n",
       "      <td>0.701903</td>\n",
       "      <td>-0.089538</td>\n",
       "      <td>-1.487912</td>\n",
       "      <td>1.162014</td>\n",
       "      <td>1.816319</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.482807</td>\n",
       "      <td>1.492434</td>\n",
       "      <td>1.138283</td>\n",
       "      <td>1.580549</td>\n",
       "      <td>-0.390690</td>\n",
       "      <td>0.323869</td>\n",
       "      <td>-0.701669</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.310007</td>\n",
       "      <td>-0.375829</td>\n",
       "      <td>0.060168</td>\n",
       "      <td>-0.602870</td>\n",
       "      <td>-0.567661</td>\n",
       "      <td>-0.793657</td>\n",
       "      <td>-0.701669</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Cylinders  Displacement  Horsepower    Weight  Acceleration  Model_Year  \\\n",
       "0   -0.862792     -1.043066   -1.017947 -1.027131      1.272841    1.162014   \n",
       "1    1.482807      1.177880    1.163952  0.526929     -1.629489   -1.631803   \n",
       "2    1.482807      1.482902    1.934034  0.794143     -1.629489   -0.793657   \n",
       "3    0.310007      0.529707   -0.119518  0.346443     -0.213718   -1.352421   \n",
       "4   -0.862792     -1.004939   -0.863931 -1.243949     -0.567661    0.882633   \n",
       "..        ...           ...         ...       ...           ...         ...   \n",
       "73  -0.862792     -0.699916    0.188515 -0.062582     -0.390690   -1.073039   \n",
       "74  -0.862792     -0.518809   -0.838261 -0.686081      1.379024   -0.793657   \n",
       "75   0.310007     -0.251914    0.701903 -0.089538     -1.487912    1.162014   \n",
       "76   1.482807      1.492434    1.138283  1.580549     -0.390690    0.323869   \n",
       "77   0.310007     -0.375829    0.060168 -0.602870     -0.567661   -0.793657   \n",
       "\n",
       "      Origin  ground_truth  \n",
       "0   1.816319          40.8  \n",
       "1  -0.701669          18.0  \n",
       "2  -0.701669          11.0  \n",
       "3  -0.701669          19.0  \n",
       "4   0.557325          31.9  \n",
       "..       ...           ...  \n",
       "73  0.557325          18.0  \n",
       "74 -0.701669          21.0  \n",
       "75  1.816319          32.7  \n",
       "76 -0.701669          16.0  \n",
       "77 -0.701669          21.0  \n",
       "\n",
       "[78 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df, test_df = get_train_n_test_data(\"auto\")\n",
    "display(train_df)\n",
    "display(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def df2ds(df: pd.DataFrame) -> tf.data.Dataset:\n",
    "    \"\"\"Converts DataFrame to Dataset\n",
    "\n",
    "    Args:\n",
    "        df: input DataFrame\n",
    "\n",
    "    Returns:\n",
    "        dataset\n",
    "    \"\"\"\n",
    "    x = df.to_dict(\"list\")\n",
    "    y = x.pop(\"ground_truth\")\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def peek(ds: tf.data.Dataset) -> tf.Tensor:\n",
    "    \"\"\"Returns the first element of the dataset\n",
    "\n",
    "    Args:\n",
    "        ds: dataset\n",
    "\n",
    "    Returns:\n",
    "        the first element of the dataset\n",
    "    \"\"\"\n",
    "    for x in ds:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cylinders': <tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([1.4828068, 1.4828068, 1.4828068, 1.4828068, 1.4828068, 1.4828068,\n",
       "        1.4828068, 1.4828068], dtype=float32)>,\n",
       " 'Displacement': <tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([1.0730283, 1.4829025, 1.0444324, 1.0253685, 2.235927 , 2.474226 ,\n",
       "        2.3407786, 1.8641808], dtype=float32)>,\n",
       " 'Horsepower': <tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([0.65056413, 1.5489933 , 1.1639522 , 0.9072582 , 2.3960838 ,\n",
       "        2.9608107 , 2.8324637 , 2.1907284 ], dtype=float32)>,\n",
       " 'Weight': <tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([0.6066247, 0.828131 , 0.5234134, 0.5421652, 1.5875812, 1.602817 ,\n",
       "        1.5535934, 1.0121336], dtype=float32)>,\n",
       " 'Acceleration': <tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([-1.2755462, -1.4525175, -1.2755462, -1.8064601, -1.9834315,\n",
       "        -2.3373742, -2.5143454, -2.5143454], dtype=float32)>,\n",
       " 'Model_Year': <tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([-1.6318026, -1.6318026, -1.6318026, -1.6318026, -1.6318026,\n",
       "        -1.6318026, -1.6318026, -1.6318026], dtype=float32)>,\n",
       " 'Origin': <tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       " array([-0.7016686, -0.7016686, -0.7016686, -0.7016686, -0.7016686,\n",
       "        -0.7016686, -0.7016686, -0.7016686], dtype=float32)>}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=float32, numpy=array([18., 15., 16., 17., 15., 14., 14., 15.], dtype=float32)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = peek(df2ds(train_df).batch(8))\n",
    "display(x)\n",
    "display(y)\n",
    "\n",
    "expected = {\n",
    "    \"Acceleration\",\n",
    "    \"Cylinders\",\n",
    "    \"Displacement\",\n",
    "    \"Horsepower\",\n",
    "    \"Model_Year\",\n",
    "    \"Origin\",\n",
    "    \"Weight\",\n",
    "}\n",
    "assert set(x.keys()) == expected\n",
    "for k in expected:\n",
    "    assert x[k].shape == (8,)\n",
    "assert y.shape == (8,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "\n",
    "def _build_mono_model_f(\n",
    "    *,\n",
    "    monotonicity_indicator: Dict[str, int],\n",
    "    final_activation: Union[str, Callable[[TensorLike], TensorLike]],\n",
    "    loss: Union[str, Callable[[TensorLike, TensorLike], TensorLike]],\n",
    "    metrics: Union[str, Callable[[TensorLike, TensorLike], TensorLike]],\n",
    "    train_ds: tf.data.Dataset,\n",
    "    batch_size: int,\n",
    "    units: int,\n",
    "    n_layers: int,\n",
    "    activation: Union[str, Callable[[TensorLike], TensorLike]],\n",
    "    learning_rate: float,\n",
    "    weight_decay: float,\n",
    "    dropout: float,\n",
    "    decay_rate: float,\n",
    ") -> Model:\n",
    "    inputs = {k: Input(name=k, shape=(1,)) for k in monotonicity_indicator.keys()}\n",
    "    outputs = MonoDense.create_type_2(\n",
    "        inputs,\n",
    "        units=units,\n",
    "        final_units=1,\n",
    "        activation=activation,\n",
    "        n_layers=n_layers,\n",
    "        monotonicity_indicator=monotonicity_indicator,\n",
    "        is_convex=False,\n",
    "        is_concave=False,\n",
    "        dropout=dropout,\n",
    "        final_activation=final_activation,\n",
    "    )\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        learning_rate,\n",
    "        decay_steps=len(train_ds.batch(batch_size)),\n",
    "        decay_rate=decay_rate,\n",
    "        staircase=True,\n",
    "    )\n",
    "\n",
    "    optimizer = AdamW(learning_rate=lr_schedule, weight_decay=weight_decay)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload skipped, file /home/davor/work/projects/airt/mono-dense-keras/nbs/data/train_auto.csv exists.\n",
      "Upload skipped, file /home/davor/work/projects/airt/mono-dense-keras/nbs/data/test_auto.csv exists.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Acceleration (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Cylinders (InputLayer)         [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Displacement (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Horsepower (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Model_Year (InputLayer)        [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Origin (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " Weight (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_Acceleration (Dense)     (None, 4)            8           ['Acceleration[0][0]']           \n",
      "                                                                                                  \n",
      " dense_Cylinders (Dense)        (None, 4)            8           ['Cylinders[0][0]']              \n",
      "                                                                                                  \n",
      " mono_dense_Displacement_decrea  (None, 4)           8           ['Displacement[0][0]']           \n",
      " sing (MonoDense)                                                                                 \n",
      "                                                                                                  \n",
      " mono_dense_Horsepower_decreasi  (None, 4)           8           ['Horsepower[0][0]']             \n",
      " ng (MonoDense)                                                                                   \n",
      "                                                                                                  \n",
      " dense_Model_Year (Dense)       (None, 4)            8           ['Model_Year[0][0]']             \n",
      "                                                                                                  \n",
      " dense_Origin (Dense)           (None, 4)            8           ['Origin[0][0]']                 \n",
      "                                                                                                  \n",
      " mono_dense_Weight_decreasing (  (None, 4)           8           ['Weight[0][0]']                 \n",
      " MonoDense)                                                                                       \n",
      "                                                                                                  \n",
      " preprocessed_features (Concate  (None, 28)          0           ['dense_Acceleration[0][0]',     \n",
      " nate)                                                            'dense_Cylinders[0][0]',        \n",
      "                                                                  'mono_dense_Displacement_decreas\n",
      "                                                                 ing[0][0]',                      \n",
      "                                                                  'mono_dense_Horsepower_decreasin\n",
      "                                                                 g[0][0]',                        \n",
      "                                                                  'dense_Model_Year[0][0]',       \n",
      "                                                                  'dense_Origin[0][0]',           \n",
      "                                                                  'mono_dense_Weight_decreasing[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " mono_dense_0 (MonoDense)       (None, 16)           464         ['preprocessed_features[0][0]']  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 16)           0           ['mono_dense_0[0][0]']           \n",
      "                                                                                                  \n",
      " mono_dense_1_increasing (MonoD  (None, 16)          272         ['dropout[0][0]']                \n",
      " ense)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 16)           0           ['mono_dense_1_increasing[0][0]']\n",
      "                                                                                                  \n",
      " mono_dense_2_increasing (MonoD  (None, 1)           17          ['dropout_1[0][0]']              \n",
      " ense)                                                                                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 809\n",
      "Trainable params: 809\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "40/40 [==============================] - 4s 12ms/step - loss: 150.6315 - mse: 150.6315 - val_loss: 342.8134 - val_mse: 342.8134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = get_train_n_test_data(\"auto\")\n",
    "train_ds = df2ds(train_df)\n",
    "test_ds = df2ds(test_df)\n",
    "\n",
    "build_model_f = lambda: _build_mono_model_f(\n",
    "    monotonicity_indicator={\n",
    "        \"Cylinders\": 0,\n",
    "        \"Displacement\": -1,\n",
    "        \"Horsepower\": -1,\n",
    "        \"Weight\": -1,\n",
    "        \"Acceleration\": 0,\n",
    "        \"Model_Year\": 0,\n",
    "        \"Origin\": 0,\n",
    "    },\n",
    "    final_activation=None,\n",
    "    loss=\"mse\",\n",
    "    metrics=\"mse\",\n",
    "    train_ds=train_ds,\n",
    "    batch_size=8,\n",
    "    units=16,\n",
    "    n_layers=3,\n",
    "    activation=\"elu\",\n",
    "    learning_rate=0.01,\n",
    "    weight_decay=0.001,\n",
    "    dropout=0.25,\n",
    "    decay_rate=0.95,\n",
    ")\n",
    "model = build_model_f()\n",
    "model.summary()\n",
    "model.fit(train_ds.batch(8), validation_data=test_ds.batch(256), epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "\n",
    "def _get_build_model_with_hp_f(\n",
    "    build_model_f: Callable[[], Model],\n",
    "    hp_params_f: Optional[Callable[[HyperParameters], Dict[str, Any]]] = None,\n",
    "    **kwargs: Any,\n",
    ") -> Callable[[HyperParameters], Model]:\n",
    "    def build_model_with_hp_f(\n",
    "        hp: HyperParameters,\n",
    "        hp_params_f: Optional[\n",
    "            Callable[[HyperParameters], Dict[str, Any]]\n",
    "        ] = hp_params_f,\n",
    "        kwargs: Dict[str, Any] = kwargs,\n",
    "    ) -> Model:\n",
    "        override_kwargs = hp_params_f(hp) if hp_params_f is not None else {}\n",
    "\n",
    "        default_kwargs = dict(\n",
    "            units=hp.Int(\"units\", min_value=8, max_value=32, step=1),\n",
    "            n_layers=hp.Int(\"n_layers\", min_value=1, max_value=4),\n",
    "            activation=hp.Choice(\"activation\", values=[\"elu\"]),\n",
    "            learning_rate=hp.Float(\n",
    "                \"learning_rate\", min_value=1e-3, max_value=0.3, sampling=\"log\"\n",
    "            ),\n",
    "            weight_decay=hp.Float(\n",
    "                \"weight_decay\", min_value=1e-1, max_value=0.3, sampling=\"log\"\n",
    "            ),\n",
    "            dropout=hp.Float(\n",
    "                \"dropout\", min_value=0.0, max_value=0.5, sampling=\"linear\"\n",
    "            ),\n",
    "            decay_rate=hp.Float(\n",
    "                \"decay_rate\", min_value=0.5, max_value=1.0, sampling=\"reverse_log\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        default_kwargs.update(**override_kwargs)\n",
    "        model = build_model_f(**default_kwargs, **kwargs)\n",
    "        return model\n",
    "\n",
    "    return build_model_with_hp_f\n",
    "\n",
    "\n",
    "class _TestHyperModel(HyperModel):\n",
    "    def __init__(self, **kwargs: Any):\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def build(self, hp: HyperParameters) -> Model:\n",
    "        build_model_with_hp_f = _get_build_model_with_hp_f(\n",
    "            _build_mono_model_f, **self.kwargs  # type: ignore\n",
    "        )\n",
    "        return build_model_with_hp_f(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 03s]\n",
      "val_loss: 28.08372688293457\n",
      "\n",
      "Best val_loss So Far: 28.08372688293457\n",
      "Total elapsed time: 00h 00m 07s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "def hp_params_f(hp: HyperParameters):\n",
    "    return dict(\n",
    "        units=hp.Fixed(name=\"units\", value=3),\n",
    "        layers=hp.Fixed(name=\"units\", value=1),\n",
    "    )\n",
    "\n",
    "\n",
    "with TemporaryDirectory() as d:\n",
    "    tuner = RandomSearch(\n",
    "        hypermodel=_TestHyperModel(\n",
    "            monotonicity_indicator={\n",
    "                \"Cylinders\": 0,\n",
    "                \"Displacement\": -1,\n",
    "                \"Horsepower\": -1,\n",
    "                \"Weight\": -1,\n",
    "                \"Acceleration\": 0,\n",
    "                \"Model_Year\": 0,\n",
    "                \"Origin\": 0,\n",
    "            },\n",
    "            hp_params_f=lambda hp: {\"units\": hp.Fixed(name=\"units\", value=3)},\n",
    "            final_activation=None,\n",
    "            loss=\"mse\",\n",
    "            metrics=\"mse\",\n",
    "            train_ds=train_ds,\n",
    "            batch_size=8,\n",
    "        ),\n",
    "        directory=d,\n",
    "        project_name=\"testing\",\n",
    "        max_trials=2,\n",
    "        objective=\"val_loss\",\n",
    "    )\n",
    "    tuner.search(\n",
    "        train_ds.shuffle(len(train_ds)).batch(8).prefetch(2),\n",
    "        validation_data=test_ds.batch(256),\n",
    "        epochs=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def find_hyperparameters(\n",
    "    dataset_name: str,\n",
    "    *,\n",
    "    monotonicity_indicator: Dict[str, int],\n",
    "    final_activation: Union[str, Callable[[TensorLike, TensorLike], TensorLike]],\n",
    "    loss: Union[str, Callable[[TensorLike, TensorLike], TensorLike]],\n",
    "    metrics: Union[str, Callable[[TensorLike, TensorLike], TensorLike]],\n",
    "    hp_params_f: Optional[Callable[[HyperParameters], Dict[str, Any]]] = None,\n",
    "    max_trials: int = 100,\n",
    "    max_epochs: int = 50,\n",
    "    batch_size: int = 8,\n",
    "    objective: Union[str, Objective],\n",
    "    direction: str,\n",
    "    dir_root: Union[Path, str] = \"tuner\",\n",
    "    seed: int = 42,\n",
    "    executions_per_trial: int = 3,\n",
    "    max_consecutive_failed_trials: int = 5,\n",
    "    patience: int = 10,\n",
    ") -> Tuner:\n",
    "    \"\"\"Search for optimal hyperparameters\n",
    "\n",
    "    Args:\n",
    "        monotonicity_indicator: monotonicity indicator as used in `MonoDense.__init__`\n",
    "        final_activation:  final activation of the neural network\n",
    "        loss: Tensorflow loss function\n",
    "        metrics: Tensorflow metrics function\n",
    "        hp_params_f: a function constructing sampling hyperparameters using Keras Tuner\n",
    "        max_trials: maximum number of trials\n",
    "        max_epochs: maximum number of epochs in each trial\n",
    "        batch_size: batch size\n",
    "        objective: objective, typically f\"val_{metrics}\"\n",
    "        direction: direction of the objective, either \"min\" or \"max\"\n",
    "        dir_root: root directory for storing Keras Tuner data\n",
    "        seed: random seed used to guarantee reproducibility of results\n",
    "        executions_per_trial: number of executions per trial. Set it to number higher than zero for small datasets\n",
    "        max_consecutive_failed_trials: maximum number of failed trials as used in Keras Tuner\n",
    "        patience: number of epoch with worse objective before stopping trial early\n",
    "\n",
    "    Returns:\n",
    "        An instance of Keras Tuner\n",
    "\n",
    "    \"\"\"\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "    train_df, test_df = get_train_n_test_data(dataset_name)\n",
    "    train_ds, test_ds = df2ds(train_df), df2ds(test_df)\n",
    "\n",
    "    oracle = _TestHyperModel(\n",
    "        monotonicity_indicator=monotonicity_indicator,\n",
    "        hp_params_f=hp_params_f,\n",
    "        final_activation=final_activation,\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "        train_ds=train_ds,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "    tuner = BayesianOptimization(\n",
    "        oracle,\n",
    "        objective=Objective(objective, direction),\n",
    "        max_trials=max_trials,\n",
    "        seed=seed,\n",
    "        directory=Path(dir_root),\n",
    "        project_name=dataset_name,\n",
    "        executions_per_trial=executions_per_trial,\n",
    "        max_consecutive_failed_trials=max_consecutive_failed_trials,\n",
    "    )\n",
    "\n",
    "    stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=patience)\n",
    "\n",
    "    tuner.search(\n",
    "        train_ds.shuffle(len(train_ds)).batch(batch_size).prefetch(2),\n",
    "        validation_data=test_ds.batch(256),\n",
    "        callbacks=[stop_early],\n",
    "        epochs=max_epochs,\n",
    "    )\n",
    "\n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 03s]\n",
      "val_mse: 32.87412643432617\n",
      "\n",
      "Best val_mse So Far: 32.87412643432617\n",
      "Total elapsed time: 00h 00m 06s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree(\"tuner\", ignore_errors=True)\n",
    "\n",
    "tuner = find_hyperparameters(\n",
    "    \"auto\",\n",
    "    monotonicity_indicator={\n",
    "        \"Cylinders\": 0,\n",
    "        \"Displacement\": -1,\n",
    "        \"Horsepower\": -1,\n",
    "        \"Weight\": -1,\n",
    "        \"Acceleration\": 0,\n",
    "        \"Model_Year\": 0,\n",
    "        \"Origin\": 0,\n",
    "    },\n",
    "    max_trials=2,\n",
    "    final_activation=None,\n",
    "    loss=\"mse\",\n",
    "    metrics=\"mse\",\n",
    "    objective=\"val_mse\",\n",
    "    direction=\"min\",\n",
    "    max_epochs=1,\n",
    "    executions_per_trial=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | exporti\n",
    "\n",
    "\n",
    "def _count_model_params(model: Model) -> int:\n",
    "    return sum([sum([count_params(v) for v in l.variables]) for l in model.layers])\n",
    "\n",
    "\n",
    "def _create_model_stats(\n",
    "    tuner: Tuner,\n",
    "    hp: Dict[str, Any],\n",
    "    *,\n",
    "    stats: Optional[pd.DataFrame] = None,\n",
    "    max_epochs: int,\n",
    "    num_runs: int,\n",
    "    top_runs: int,\n",
    "    batch_size: int,\n",
    "    patience: int,\n",
    "    verbose: int,\n",
    "    train_ds: tf.data.Dataset,\n",
    "    test_ds: tf.data.Dataset,\n",
    ") -> pd.DataFrame:\n",
    "    tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "    def model_stats(\n",
    "        tuner: Tuner = tuner,\n",
    "        hp: Dict[str, Any] = hp,\n",
    "        max_epochs: int = max_epochs,\n",
    "        batch_size: int = batch_size,\n",
    "        patience: int = patience,\n",
    "        verbose: int = verbose,\n",
    "        train_ds: tf.data.Dataset = train_ds,\n",
    "        test_ds: tf.data.Dataset = test_ds,\n",
    "    ) -> float:\n",
    "        model = tuner.hypermodel.build(hp)\n",
    "        stop_early = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=patience\n",
    "        )\n",
    "        history = model.fit(\n",
    "            train_ds.shuffle(len(train_ds)).batch(batch_size).prefetch(2),\n",
    "            epochs=max_epochs,\n",
    "            validation_data=test_ds.batch(256),\n",
    "            verbose=verbose,\n",
    "            callbacks=[stop_early],\n",
    "        )\n",
    "        objective = history.history[tuner.oracle.objective.name]\n",
    "        if tuner.oracle.objective.direction == \"max\":\n",
    "            best_epoch = objective.index(max(objective))\n",
    "        else:\n",
    "            best_epoch = objective.index(min(objective))\n",
    "        return objective[best_epoch]  # type: ignore\n",
    "\n",
    "    xs = sorted(\n",
    "        [model_stats() for _ in range(num_runs)],\n",
    "        reverse=tuner.oracle.objective.direction == \"max\",\n",
    "    )\n",
    "    stats = pd.Series(xs[:top_runs])\n",
    "    stats = stats.describe()\n",
    "    stats = {\n",
    "        f\"{tuner.oracle.objective.name}_{k}\": stats[k]\n",
    "        for k in [\"mean\", \"std\", \"min\", \"max\"]\n",
    "    }\n",
    "    model = tuner.hypermodel.build(hp)\n",
    "    stats_df = pd.DataFrame(\n",
    "        dict(**hp.values, **stats, params=_count_model_params(model)),  # type: ignore\n",
    "        index=[0],\n",
    "    )\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def create_tuner_stats(\n",
    "    tuner: Tuner,\n",
    "    *,\n",
    "    num_models: int = 10,\n",
    "    max_epochs: int = 50,\n",
    "    batch_size: int = 8,\n",
    "    patience: int = 10,\n",
    "    verbose: int = 0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Calculates statistics for the best models found by Keras Tuner\n",
    "\n",
    "    Args:\n",
    "        tuner: an instance of Keras Tuner\n",
    "        num_models: number of best models to use for calculating statistics\n",
    "        max_epochs: maximum number of epochs used in runs\n",
    "        batch_size: batch_size\n",
    "        patience: maximum number of epochs with worse objective before stopping trial early\n",
    "        verbose: verbosity level of `Model.fit` function\n",
    "\n",
    "    Returns:\n",
    "        A dataframe with statistics\n",
    "    \"\"\"\n",
    "    stats = None\n",
    "\n",
    "    train_df, test_df = get_train_n_test_data(tuner.project_name)\n",
    "    train_ds, test_ds = df2ds(train_df), df2ds(test_df)\n",
    "\n",
    "    for hp in tuner.get_best_hyperparameters(num_trials=num_models):\n",
    "        new_entry = _create_model_stats(\n",
    "            tuner,\n",
    "            hp,\n",
    "            stats=stats,\n",
    "            max_epochs=max_epochs,\n",
    "            num_runs=10,\n",
    "            top_runs=5,\n",
    "            batch_size=batch_size,\n",
    "            patience=patience,\n",
    "            verbose=verbose,\n",
    "            train_ds=train_ds,\n",
    "            test_ds=test_ds,\n",
    "        )\n",
    "        if stats is None:\n",
    "            stats = new_entry\n",
    "        else:\n",
    "            stats = pd.concat([stats, new_entry]).reset_index(drop=True)\n",
    "\n",
    "        try:\n",
    "            display(stats.sort_values(f\"{tuner.oracle.objective.name}_mean\"))  # type: ignore\n",
    "        # nosemgrep\n",
    "        except Exception as e:  # nosec\n",
    "            pass\n",
    "\n",
    "    return stats.sort_values(f\"{tuner.oracle.objective.name}_mean\")  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload skipped, file /home/davor/work/projects/airt/mono-dense-keras/nbs/data/train_auto.csv exists.\n",
      "Upload skipped, file /home/davor/work/projects/airt/mono-dense-keras/nbs/data/test_auto.csv exists.\n",
      "WARNING:tensorflow:6 out of the last 8 calls to <function Model.make_test_function.<locals>.test_function> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>dropout</th>\n",
       "      <th>decay_rate</th>\n",
       "      <th>val_mse_mean</th>\n",
       "      <th>val_mse_std</th>\n",
       "      <th>val_mse_min</th>\n",
       "      <th>val_mse_max</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.265157</td>\n",
       "      <td>0.196993</td>\n",
       "      <td>0.456821</td>\n",
       "      <td>0.560699</td>\n",
       "      <td>12.738773</td>\n",
       "      <td>1.8673</td>\n",
       "      <td>10.745923</td>\n",
       "      <td>15.125115</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  n_layers activation  learning_rate  weight_decay   dropout  \\\n",
       "0      9         2        elu       0.265157      0.196993  0.456821   \n",
       "\n",
       "   decay_rate  val_mse_mean  val_mse_std  val_mse_min  val_mse_max  params  \n",
       "0    0.560699     12.738773       1.8673    10.745923    15.125115     173  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>n_layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>dropout</th>\n",
       "      <th>decay_rate</th>\n",
       "      <th>val_mse_mean</th>\n",
       "      <th>val_mse_std</th>\n",
       "      <th>val_mse_min</th>\n",
       "      <th>val_mse_max</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.265157</td>\n",
       "      <td>0.196993</td>\n",
       "      <td>0.456821</td>\n",
       "      <td>0.560699</td>\n",
       "      <td>12.738773</td>\n",
       "      <td>1.86730</td>\n",
       "      <td>10.745923</td>\n",
       "      <td>15.125115</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>elu</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.265345</td>\n",
       "      <td>0.175923</td>\n",
       "      <td>0.816107</td>\n",
       "      <td>21.378424</td>\n",
       "      <td>1.74334</td>\n",
       "      <td>18.393272</td>\n",
       "      <td>22.992588</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  n_layers activation  learning_rate  weight_decay   dropout  \\\n",
       "0      9         2        elu       0.265157      0.196993  0.456821   \n",
       "1     23         1        elu       0.004715      0.265345  0.175923   \n",
       "\n",
       "   decay_rate  val_mse_mean  val_mse_std  val_mse_min  val_mse_max  params  \n",
       "0    0.560699     12.738773      1.86730    10.745923    15.125115     173  \n",
       "1    0.816107     21.378424      1.74334    18.393272    22.992588     106  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | notest\n",
    "\n",
    "\n",
    "stats = create_tuner_stats(tuner, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
