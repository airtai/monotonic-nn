COMPAS
================

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

COMPAS \[1\] is a dataset containing the criminal records of 6,172
individuals arrested in Florida. The task is to predict whether the
individual will commit a crime again in 2 years. The probability
predicted by the system will be used as a risk score. As mentioned in
\[2\] 13 attributes for prediction. The risk score should be
monotonically increasing w.r.t. four attributes, number of prior adult
convictions, number of juvenile felony, number of juvenile misdemeanor,
and number of other convictions. The `monotonicity_indicator`
corrsponding to these features are set to 1.

References:

1.  S. Mattu J. Angwin, J. Larson and L. Kirchner. Machine bias: There’s
    software used across the country to predict future criminals. and
    it’s biased against blacks. ProPublica, 2016.

2.  Xingchao Liu, Xing Han, Na Zhang, and Qiang Liu. Certified monotonic
    neural networks. Advances in Neural Information Processing Systems,
    33:15427–15438, 2020

``` python
monotonicity_indicator = {
    "priors_count": 1,
    "juv_fel_count": 1,
    "juv_misd_count": 1,
    "juv_other_count": 1,
    "age": 0,
    "race_0": 0,
    "race_1": 0,
    "race_2": 0,
    "race_3": 0,
    "race_4": 0,
    "race_5": 0,
    "sex_0": 0,
    "sex_1": 0,
}
```

## Running in Google Colab

<a href="https://colab.research.google.com/github/airtai/monotonic-nn/blob/main/nbs/experiments/Compas.ipynb" target=”_blank”>
<img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab" />
</a>

These are a few examples of the dataset:

<style type="text/css">
</style>
<table id="T_693c1">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_693c1_level0_col0" class="col_heading level0 col0" >0</th>
      <th id="T_693c1_level0_col1" class="col_heading level0 col1" >1</th>
      <th id="T_693c1_level0_col2" class="col_heading level0 col2" >2</th>
      <th id="T_693c1_level0_col3" class="col_heading level0 col3" >3</th>
      <th id="T_693c1_level0_col4" class="col_heading level0 col4" >4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_693c1_level0_row0" class="row_heading level0 row0" >priors_count</th>
      <td id="T_693c1_row0_col0" class="data row0 col0" >0.368421</td>
      <td id="T_693c1_row0_col1" class="data row0 col1" >0.000000</td>
      <td id="T_693c1_row0_col2" class="data row0 col2" >0.026316</td>
      <td id="T_693c1_row0_col3" class="data row0 col3" >0.394737</td>
      <td id="T_693c1_row0_col4" class="data row0 col4" >0.052632</td>
    </tr>
    <tr>
      <th id="T_693c1_level0_row1" class="row_heading level0 row1" >juv_fel_count</th>
      <td id="T_693c1_row1_col0" class="data row1 col0" >0.000000</td>
      <td id="T_693c1_row1_col1" class="data row1 col1" >0.000000</td>
      <td id="T_693c1_row1_col2" class="data row1 col2" >0.000000</td>
      <td id="T_693c1_row1_col3" class="data row1 col3" >0.000000</td>
      <td id="T_693c1_row1_col4" class="data row1 col4" >0.000000</td>
    </tr>
    <tr>
      <th id="T_693c1_level0_row2" class="row_heading level0 row2" >juv_misd_count</th>
      <td id="T_693c1_row2_col0" class="data row2 col0" >0.000000</td>
      <td id="T_693c1_row2_col1" class="data row2 col1" >0.000000</td>
      <td id="T_693c1_row2_col2" class="data row2 col2" >0.000000</td>
      <td id="T_693c1_row2_col3" class="data row2 col3" >0.000000</td>
      <td id="T_693c1_row2_col4" class="data row2 col4" >0.000000</td>
    </tr>
    <tr>
      <th id="T_693c1_level0_row3" class="row_heading level0 row3" >juv_other_count</th>
      <td id="T_693c1_row3_col0" class="data row3 col0" >0.000000</td>
      <td id="T_693c1_row3_col1" class="data row3 col1" >0.000000</td>
      <td id="T_693c1_row3_col2" class="data row3 col2" >0.000000</td>
      <td id="T_693c1_row3_col3" class="data row3 col3" >0.000000</td>
      <td id="T_693c1_row3_col4" class="data row3 col4" >0.000000</td>
    </tr>
    <tr>
      <th id="T_693c1_level0_row4" class="row_heading level0 row4" >age</th>
      <td id="T_693c1_row4_col0" class="data row4 col0" >0.230769</td>
      <td id="T_693c1_row4_col1" class="data row4 col1" >0.051282</td>
      <td id="T_693c1_row4_col2" class="data row4 col2" >0.179487</td>
      <td id="T_693c1_row4_col3" class="data row4 col3" >0.230769</td>
      <td id="T_693c1_row4_col4" class="data row4 col4" >0.102564</td>
    </tr>
    <tr>
      <th id="T_693c1_level0_row5" class="row_heading level0 row5" >race_0</th>
      <td id="T_693c1_row5_col0" class="data row5 col0" >1.000000</td>
      <td id="T_693c1_row5_col1" class="data row5 col1" >1.000000</td>
      <td id="T_693c1_row5_col2" class="data row5 col2" >0.000000</td>
      <td id="T_693c1_row5_col3" class="data row5 col3" >1.000000</td>
      <td id="T_693c1_row5_col4" class="data row5 col4" >1.000000</td>
    </tr>
    <tr>
      <th id="T_693c1_level0_row6" class="row_heading level0 row6" >race_1</th>
      <td id="T_693c1_row6_col0" class="data row6 col0" >0.000000</td>
      <td id="T_693c1_row6_col1" class="data row6 col1" >0.000000</td>
      <td id="T_693c1_row6_col2" class="data row6 col2" >1.000000</td>
      <td id="T_693c1_row6_col3" class="data row6 col3" >0.000000</td>
      <td id="T_693c1_row6_col4" class="data row6 col4" >0.000000</td>
    </tr>
    <tr>
      <th id="T_693c1_level0_row7" class="row_heading level0 row7" >race_2</th>
      <td id="T_693c1_row7_col0" class="data row7 col0" >0.000000</td>
      <td id="T_693c1_row7_col1" class="data row7 col1" >0.000000</td>
      <td id="T_693c1_row7_col2" class="data row7 col2" >0.000000</td>
      <td id="T_693c1_row7_col3" class="data row7 col3" >0.000000</td>
      <td id="T_693c1_row7_col4" class="data row7 col4" >0.000000</td>
    </tr>
    <tr>
      <th id="T_693c1_level0_row8" class="row_heading level0 row8" >race_3</th>
      <td id="T_693c1_row8_col0" class="data row8 col0" >0.000000</td>
      <td id="T_693c1_row8_col1" class="data row8 col1" >0.000000</td>
      <td id="T_693c1_row8_col2" class="data row8 col2" >0.000000</td>
      <td id="T_693c1_row8_col3" class="data row8 col3" >0.000000</td>
      <td id="T_693c1_row8_col4" class="data row8 col4" >0.000000</td>
    </tr>
    <tr>
      <th id="T_693c1_level0_row9" class="row_heading level0 row9" >race_4</th>
      <td id="T_693c1_row9_col0" class="data row9 col0" >0.000000</td>
      <td id="T_693c1_row9_col1" class="data row9 col1" >0.000000</td>
      <td id="T_693c1_row9_col2" class="data row9 col2" >0.000000</td>
      <td id="T_693c1_row9_col3" class="data row9 col3" >0.000000</td>
      <td id="T_693c1_row9_col4" class="data row9 col4" >0.000000</td>
    </tr>
    <tr>
      <th id="T_693c1_level0_row10" class="row_heading level0 row10" >race_5</th>
      <td id="T_693c1_row10_col0" class="data row10 col0" >0.000000</td>
      <td id="T_693c1_row10_col1" class="data row10 col1" >0.000000</td>
      <td id="T_693c1_row10_col2" class="data row10 col2" >0.000000</td>
      <td id="T_693c1_row10_col3" class="data row10 col3" >0.000000</td>
      <td id="T_693c1_row10_col4" class="data row10 col4" >0.000000</td>
    </tr>
    <tr>
      <th id="T_693c1_level0_row11" class="row_heading level0 row11" >sex_0</th>
      <td id="T_693c1_row11_col0" class="data row11 col0" >1.000000</td>
      <td id="T_693c1_row11_col1" class="data row11 col1" >1.000000</td>
      <td id="T_693c1_row11_col2" class="data row11 col2" >1.000000</td>
      <td id="T_693c1_row11_col3" class="data row11 col3" >1.000000</td>
      <td id="T_693c1_row11_col4" class="data row11 col4" >1.000000</td>
    </tr>
    <tr>
      <th id="T_693c1_level0_row12" class="row_heading level0 row12" >sex_1</th>
      <td id="T_693c1_row12_col0" class="data row12 col0" >0.000000</td>
      <td id="T_693c1_row12_col1" class="data row12 col1" >0.000000</td>
      <td id="T_693c1_row12_col2" class="data row12 col2" >0.000000</td>
      <td id="T_693c1_row12_col3" class="data row12 col3" >0.000000</td>
      <td id="T_693c1_row12_col4" class="data row12 col4" >0.000000</td>
    </tr>
    <tr>
      <th id="T_693c1_level0_row13" class="row_heading level0 row13" >ground_truth</th>
      <td id="T_693c1_row13_col0" class="data row13 col0" >1.000000</td>
      <td id="T_693c1_row13_col1" class="data row13 col1" >0.000000</td>
      <td id="T_693c1_row13_col2" class="data row13 col2" >0.000000</td>
      <td id="T_693c1_row13_col3" class="data row13 col3" >0.000000</td>
      <td id="T_693c1_row13_col4" class="data row13 col4" >1.000000</td>
    </tr>
  </tbody>
</table>

## Hyperparameter search

The choice of the batch size and the maximum number of epochs depends on
the dataset size. For this dataset, we use the following values:

``` python
batch_size = 8
max_epochs = 50
```

We use the Type-2 architecture built using
[`MonoDense`](api/airt/keras/layers/MonoDense/#airt.keras.layers.MonoDense)
layer with the following set of hyperparameters ranges:

``` python
def hp_params_f(hp):
    return dict(
        units=hp.Int("units", min_value=16, max_value=32, step=1),
        n_layers=hp.Int("n_layers", min_value=2, max_value=2),
        activation=hp.Choice("activation", values=["elu"]),
        learning_rate=hp.Float(
            "learning_rate", min_value=1e-4, max_value=1e-2, sampling="log"
        ),
        weight_decay=hp.Float(
            "weight_decay", min_value=3e-2, max_value=0.3, sampling="log"
        ),
        dropout=hp.Float("dropout", min_value=0.0, max_value=0.5, sampling="linear"),
        decay_rate=hp.Float(
            "decay_rate", min_value=0.8, max_value=1.0, sampling="reverse_log"
        ),
    )
```

The following fixed parameters are used to build the Type-2 architecture
for this dataset:

- `final_activation` is used to build the final layer for regression
  problem (set to `None`) or for the classification problem
  (`"sigmoid"`),

- `loss` is used for training regression (`"mse"`) or classification
  (`"binary_crossentropy"`) problem, and

- `metrics` denotes metrics used to compare with previosly published
  results: `"accuracy"` for classification and “`mse`” or “`rmse`” for
  regression.

Parameters `objective` and `direction` are used by the tuner such that
`objective=f"val_{metrics}"` and direction is either `"min` or `"max"`.

Parameters `max_trials` denotes the number of trial performed buy the
tuner, `patience` is the number of epochs allowed to perform worst than
the best one before stopping the current trial. The parameter
`execution_per_trial` denotes the number of runs before calculating the
results of a trial, it should be set to value greater than 1 for small
datasets that have high variance in results.

``` python
final_activation = "sigmoid"
loss = "binary_crossentropy"
metrics = "accuracy"
objective = "val_accuracy"
direction = "max"
max_trials = 50
executions_per_trial = 1
patience = 5
```

The following table describes the best models and their hyperparameters
found by the tuner:

<style type="text/css">
</style>
<table id="T_158e9">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_158e9_level0_col0" class="col_heading level0 col0" >0</th>
      <th id="T_158e9_level0_col1" class="col_heading level0 col1" >1</th>
      <th id="T_158e9_level0_col2" class="col_heading level0 col2" >2</th>
      <th id="T_158e9_level0_col3" class="col_heading level0 col3" >3</th>
      <th id="T_158e9_level0_col4" class="col_heading level0 col4" >4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_158e9_level0_row0" class="row_heading level0 row0" >units</th>
      <td id="T_158e9_row0_col0" class="data row0 col0" >27</td>
      <td id="T_158e9_row0_col1" class="data row0 col1" >28</td>
      <td id="T_158e9_row0_col2" class="data row0 col2" >26</td>
      <td id="T_158e9_row0_col3" class="data row0 col3" >31</td>
      <td id="T_158e9_row0_col4" class="data row0 col4" >25</td>
    </tr>
    <tr>
      <th id="T_158e9_level0_row1" class="row_heading level0 row1" >n_layers</th>
      <td id="T_158e9_row1_col0" class="data row1 col0" >2</td>
      <td id="T_158e9_row1_col1" class="data row1 col1" >3</td>
      <td id="T_158e9_row1_col2" class="data row1 col2" >2</td>
      <td id="T_158e9_row1_col3" class="data row1 col3" >3</td>
      <td id="T_158e9_row1_col4" class="data row1 col4" >2</td>
    </tr>
    <tr>
      <th id="T_158e9_level0_row2" class="row_heading level0 row2" >activation</th>
      <td id="T_158e9_row2_col0" class="data row2 col0" >elu</td>
      <td id="T_158e9_row2_col1" class="data row2 col1" >elu</td>
      <td id="T_158e9_row2_col2" class="data row2 col2" >elu</td>
      <td id="T_158e9_row2_col3" class="data row2 col3" >elu</td>
      <td id="T_158e9_row2_col4" class="data row2 col4" >elu</td>
    </tr>
    <tr>
      <th id="T_158e9_level0_row3" class="row_heading level0 row3" >learning_rate</th>
      <td id="T_158e9_row3_col0" class="data row3 col0" >0.084685</td>
      <td id="T_158e9_row3_col1" class="data row3 col1" >0.105227</td>
      <td id="T_158e9_row3_col2" class="data row3 col2" >0.086301</td>
      <td id="T_158e9_row3_col3" class="data row3 col3" >0.018339</td>
      <td id="T_158e9_row3_col4" class="data row3 col4" >0.069011</td>
    </tr>
    <tr>
      <th id="T_158e9_level0_row4" class="row_heading level0 row4" >weight_decay</th>
      <td id="T_158e9_row4_col0" class="data row4 col0" >0.137518</td>
      <td id="T_158e9_row4_col1" class="data row4 col1" >0.120702</td>
      <td id="T_158e9_row4_col2" class="data row4 col2" >0.147297</td>
      <td id="T_158e9_row4_col3" class="data row4 col3" >0.105921</td>
      <td id="T_158e9_row4_col4" class="data row4 col4" >0.153525</td>
    </tr>
    <tr>
      <th id="T_158e9_level0_row5" class="row_heading level0 row5" >dropout</th>
      <td id="T_158e9_row5_col0" class="data row5 col0" >0.175917</td>
      <td id="T_158e9_row5_col1" class="data row5 col1" >0.160270</td>
      <td id="T_158e9_row5_col2" class="data row5 col2" >0.162063</td>
      <td id="T_158e9_row5_col3" class="data row5 col3" >0.480390</td>
      <td id="T_158e9_row5_col4" class="data row5 col4" >0.180772</td>
    </tr>
    <tr>
      <th id="T_158e9_level0_row6" class="row_heading level0 row6" >decay_rate</th>
      <td id="T_158e9_row6_col0" class="data row6 col0" >0.899399</td>
      <td id="T_158e9_row6_col1" class="data row6 col1" >0.872222</td>
      <td id="T_158e9_row6_col2" class="data row6 col2" >0.927282</td>
      <td id="T_158e9_row6_col3" class="data row6 col3" >0.964135</td>
      <td id="T_158e9_row6_col4" class="data row6 col4" >0.874505</td>
    </tr>
    <tr>
      <th id="T_158e9_level0_row7" class="row_heading level0 row7" >val_accuracy_mean</th>
      <td id="T_158e9_row7_col0" class="data row7 col0" >0.694413</td>
      <td id="T_158e9_row7_col1" class="data row7 col1" >0.693603</td>
      <td id="T_158e9_row7_col2" class="data row7 col2" >0.692955</td>
      <td id="T_158e9_row7_col3" class="data row7 col3" >0.692308</td>
      <td id="T_158e9_row7_col4" class="data row7 col4" >0.692146</td>
    </tr>
    <tr>
      <th id="T_158e9_level0_row8" class="row_heading level0 row8" >val_accuracy_std</th>
      <td id="T_158e9_row8_col0" class="data row8 col0" >0.003464</td>
      <td id="T_158e9_row8_col1" class="data row8 col1" >0.000923</td>
      <td id="T_158e9_row8_col2" class="data row8 col2" >0.002710</td>
      <td id="T_158e9_row8_col3" class="data row8 col3" >0.002217</td>
      <td id="T_158e9_row8_col4" class="data row8 col4" >0.002649</td>
    </tr>
    <tr>
      <th id="T_158e9_level0_row9" class="row_heading level0 row9" >val_accuracy_min</th>
      <td id="T_158e9_row9_col0" class="data row9 col0" >0.689879</td>
      <td id="T_158e9_row9_col1" class="data row9 col1" >0.692308</td>
      <td id="T_158e9_row9_col2" class="data row9 col2" >0.689069</td>
      <td id="T_158e9_row9_col3" class="data row9 col3" >0.689069</td>
      <td id="T_158e9_row9_col4" class="data row9 col4" >0.689879</td>
    </tr>
    <tr>
      <th id="T_158e9_level0_row10" class="row_heading level0 row10" >val_accuracy_max</th>
      <td id="T_158e9_row10_col0" class="data row10 col0" >0.698785</td>
      <td id="T_158e9_row10_col1" class="data row10 col1" >0.694737</td>
      <td id="T_158e9_row10_col2" class="data row10 col2" >0.695547</td>
      <td id="T_158e9_row10_col3" class="data row10 col3" >0.694737</td>
      <td id="T_158e9_row10_col4" class="data row10 col4" >0.696356</td>
    </tr>
    <tr>
      <th id="T_158e9_level0_row11" class="row_heading level0 row11" >params</th>
      <td id="T_158e9_row11_col0" class="data row11 col0" >2317</td>
      <td id="T_158e9_row11_col1" class="data row11 col1" >3599</td>
      <td id="T_158e9_row11_col2" class="data row11 col2" >2237</td>
      <td id="T_158e9_row11_col3" class="data row11 col3" >4058</td>
      <td id="T_158e9_row11_col4" class="data row11 col4" >2157</td>
    </tr>
  </tbody>
</table>

## The optimal model

These are the best hyperparameters found by previous runs of the tuner:

``` python
def final_hp_params_f(hp):
    return dict(
        units=hp.Fixed("units", value=27),
        n_layers=hp.Fixed("n_layers", 2),
        activation=hp.Fixed("activation", value="elu"),
        learning_rate=hp.Fixed("learning_rate", value=0.084685),
        weight_decay=hp.Fixed("weight_decay", value=0.137518),
        dropout=hp.Fixed("dropout", value=0.175917),
        decay_rate=hp.Fixed("decay_rate", value=0.899399),
    )
```

The final evaluation of the optimal model:

<style type="text/css">
</style>
<table id="T_c7cc6">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_c7cc6_level0_col0" class="col_heading level0 col0" >0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_c7cc6_level0_row0" class="row_heading level0 row0" >units</th>
      <td id="T_c7cc6_row0_col0" class="data row0 col0" >27</td>
    </tr>
    <tr>
      <th id="T_c7cc6_level0_row1" class="row_heading level0 row1" >n_layers</th>
      <td id="T_c7cc6_row1_col0" class="data row1 col0" >2</td>
    </tr>
    <tr>
      <th id="T_c7cc6_level0_row2" class="row_heading level0 row2" >activation</th>
      <td id="T_c7cc6_row2_col0" class="data row2 col0" >elu</td>
    </tr>
    <tr>
      <th id="T_c7cc6_level0_row3" class="row_heading level0 row3" >learning_rate</th>
      <td id="T_c7cc6_row3_col0" class="data row3 col0" >0.084685</td>
    </tr>
    <tr>
      <th id="T_c7cc6_level0_row4" class="row_heading level0 row4" >weight_decay</th>
      <td id="T_c7cc6_row4_col0" class="data row4 col0" >0.137518</td>
    </tr>
    <tr>
      <th id="T_c7cc6_level0_row5" class="row_heading level0 row5" >dropout</th>
      <td id="T_c7cc6_row5_col0" class="data row5 col0" >0.175917</td>
    </tr>
    <tr>
      <th id="T_c7cc6_level0_row6" class="row_heading level0 row6" >decay_rate</th>
      <td id="T_c7cc6_row6_col0" class="data row6 col0" >0.899399</td>
    </tr>
    <tr>
      <th id="T_c7cc6_level0_row7" class="row_heading level0 row7" >val_accuracy_mean</th>
      <td id="T_c7cc6_row7_col0" class="data row7 col0" >0.691660</td>
    </tr>
    <tr>
      <th id="T_c7cc6_level0_row8" class="row_heading level0 row8" >val_accuracy_std</th>
      <td id="T_c7cc6_row8_col0" class="data row8 col0" >0.001056</td>
    </tr>
    <tr>
      <th id="T_c7cc6_level0_row9" class="row_heading level0 row9" >val_accuracy_min</th>
      <td id="T_c7cc6_row9_col0" class="data row9 col0" >0.690688</td>
    </tr>
    <tr>
      <th id="T_c7cc6_level0_row10" class="row_heading level0 row10" >val_accuracy_max</th>
      <td id="T_c7cc6_row10_col0" class="data row10 col0" >0.693117</td>
    </tr>
    <tr>
      <th id="T_c7cc6_level0_row11" class="row_heading level0 row11" >params</th>
      <td id="T_c7cc6_row11_col0" class="data row11 col0" >2317</td>
    </tr>
  </tbody>
</table>
