Auto MPG
================

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

The Auto MPG Dataset is a regression dataset \[1\] with 7 features:

- Cylinders

- Displacement

- Horsepower

- Weight

- Acceleration

- Model Year

- Origin.

The dependant variable MPG is monotonically decreasing with respect to
features Weigh, Displacement, and Horsepower. The
`monotonicity_indicator` corrsponding to these features are set to -1,
since the relationship is a monotonically decreasing one with respect to
the dependant variable.

This is a part of comparison with methods and datasets from COMET \[2\].

References:

1.  Ross Quinlan. Combining Instance-Based and Model-Based Learning. In
    Proceedings on the Tenth International Conference of Machine
    Learning, 236-243, University of Massachusetts, Amherst. Morgan
    Kaufmann, 1993.

    https://archive.ics.uci.edu/ml/datasets/auto+mpg

2.  Aishwarya Sivaraman, Golnoosh Farnadi, Todd Millstein, and Guy Van
    den Broeck. Counterexample-guided learning of monotonic neural
    networks. Advances in Neural Information Processing Systems,
    33:11936–11948, 2020.

    Github repo: https://github.com/AishwaryaSivaraman/COMET

``` python
monotonicity_indicator = {
    "Cylinders": 0,
    "Displacement": -1,
    "Horsepower": -1,
    "Weight": -1,
    "Acceleration": 0,
    "Model_Year": 0,
    "Origin": 0,
}
```

## Running in Google Colab

<a href="https://colab.research.google.com/github/airtai/monotonic-nn/blob/main/nbs/experiments/AutoMPG.ipynb" target=”_blank”>
<img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open in Colab" />
</a>

These are a few examples of the dataset:

<style type="text/css">
</style>
<table id="T_2a425">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_2a425_level0_col0" class="col_heading level0 col0" >0</th>
      <th id="T_2a425_level0_col1" class="col_heading level0 col1" >1</th>
      <th id="T_2a425_level0_col2" class="col_heading level0 col2" >2</th>
      <th id="T_2a425_level0_col3" class="col_heading level0 col3" >3</th>
      <th id="T_2a425_level0_col4" class="col_heading level0 col4" >4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_2a425_level0_row0" class="row_heading level0 row0" >Cylinders</th>
      <td id="T_2a425_row0_col0" class="data row0 col0" >1.482807</td>
      <td id="T_2a425_row0_col1" class="data row0 col1" >1.482807</td>
      <td id="T_2a425_row0_col2" class="data row0 col2" >1.482807</td>
      <td id="T_2a425_row0_col3" class="data row0 col3" >1.482807</td>
      <td id="T_2a425_row0_col4" class="data row0 col4" >1.482807</td>
    </tr>
    <tr>
      <th id="T_2a425_level0_row1" class="row_heading level0 row1" >Displacement</th>
      <td id="T_2a425_row1_col0" class="data row1 col0" >1.073028</td>
      <td id="T_2a425_row1_col1" class="data row1 col1" >1.482902</td>
      <td id="T_2a425_row1_col2" class="data row1 col2" >1.044432</td>
      <td id="T_2a425_row1_col3" class="data row1 col3" >1.025368</td>
      <td id="T_2a425_row1_col4" class="data row1 col4" >2.235927</td>
    </tr>
    <tr>
      <th id="T_2a425_level0_row2" class="row_heading level0 row2" >Horsepower</th>
      <td id="T_2a425_row2_col0" class="data row2 col0" >0.650564</td>
      <td id="T_2a425_row2_col1" class="data row2 col1" >1.548993</td>
      <td id="T_2a425_row2_col2" class="data row2 col2" >1.163952</td>
      <td id="T_2a425_row2_col3" class="data row2 col3" >0.907258</td>
      <td id="T_2a425_row2_col4" class="data row2 col4" >2.396084</td>
    </tr>
    <tr>
      <th id="T_2a425_level0_row3" class="row_heading level0 row3" >Weight</th>
      <td id="T_2a425_row3_col0" class="data row3 col0" >0.606625</td>
      <td id="T_2a425_row3_col1" class="data row3 col1" >0.828131</td>
      <td id="T_2a425_row3_col2" class="data row3 col2" >0.523413</td>
      <td id="T_2a425_row3_col3" class="data row3 col3" >0.542165</td>
      <td id="T_2a425_row3_col4" class="data row3 col4" >1.587581</td>
    </tr>
    <tr>
      <th id="T_2a425_level0_row4" class="row_heading level0 row4" >Acceleration</th>
      <td id="T_2a425_row4_col0" class="data row4 col0" >-1.275546</td>
      <td id="T_2a425_row4_col1" class="data row4 col1" >-1.452517</td>
      <td id="T_2a425_row4_col2" class="data row4 col2" >-1.275546</td>
      <td id="T_2a425_row4_col3" class="data row4 col3" >-1.806460</td>
      <td id="T_2a425_row4_col4" class="data row4 col4" >-1.983431</td>
    </tr>
    <tr>
      <th id="T_2a425_level0_row5" class="row_heading level0 row5" >Model_Year</th>
      <td id="T_2a425_row5_col0" class="data row5 col0" >-1.631803</td>
      <td id="T_2a425_row5_col1" class="data row5 col1" >-1.631803</td>
      <td id="T_2a425_row5_col2" class="data row5 col2" >-1.631803</td>
      <td id="T_2a425_row5_col3" class="data row5 col3" >-1.631803</td>
      <td id="T_2a425_row5_col4" class="data row5 col4" >-1.631803</td>
    </tr>
    <tr>
      <th id="T_2a425_level0_row6" class="row_heading level0 row6" >Origin</th>
      <td id="T_2a425_row6_col0" class="data row6 col0" >-0.701669</td>
      <td id="T_2a425_row6_col1" class="data row6 col1" >-0.701669</td>
      <td id="T_2a425_row6_col2" class="data row6 col2" >-0.701669</td>
      <td id="T_2a425_row6_col3" class="data row6 col3" >-0.701669</td>
      <td id="T_2a425_row6_col4" class="data row6 col4" >-0.701669</td>
    </tr>
    <tr>
      <th id="T_2a425_level0_row7" class="row_heading level0 row7" >ground_truth</th>
      <td id="T_2a425_row7_col0" class="data row7 col0" >18.000000</td>
      <td id="T_2a425_row7_col1" class="data row7 col1" >15.000000</td>
      <td id="T_2a425_row7_col2" class="data row7 col2" >16.000000</td>
      <td id="T_2a425_row7_col3" class="data row7 col3" >17.000000</td>
      <td id="T_2a425_row7_col4" class="data row7 col4" >15.000000</td>
    </tr>
  </tbody>
</table>

## Hyperparameter search

The choice of the batch size and the maximum number of epochs depends on
the dataset size. For this dataset, we use the following values:

``` python
batch_size = 16
max_epochs = 50
```

We use the Type-2 architecture built using
[`MonoDense`](api/airt/keras/layers/MonoDense/#airt.keras.layers.MonoDense)
layer with the following set of hyperparameters ranges:

``` python
def hp_params_f(hp):
    return dict(
        units=hp.Int("units", min_value=16, max_value=24, step=1),
        n_layers=hp.Int("n_layers", min_value=2, max_value=2),
        activation=hp.Choice("activation", values=["elu"]),
        learning_rate=hp.Float(
            "learning_rate", min_value=1e-2, max_value=0.3, sampling="log"
        ),
        weight_decay=hp.Float(
            "weight_decay", min_value=1e-2, max_value=0.3, sampling="log"
        ),
        dropout=hp.Float("dropout", min_value=0.0, max_value=0.5, sampling="linear"),
        decay_rate=hp.Float(
            "decay_rate", min_value=0.8, max_value=1.0, sampling="reverse_log"
        ),
    )
```

The following fixed parameters are used to build the Type-2 architecture
for this dataset:

- `final_activation` is used to build the final layer for regression
  problem (set to `None`) or for the classification problem
  (`"sigmoid"`),

- `loss` is used for training regression (`"mse"`) or classification
  (`"binary_crossentropy"`) problem, and

- `metrics` denotes metrics used to compare with previosly published
  results: `"accuracy"` for classification and “`mse`” or “`rmse`” for
  regression.

Parameters `objective` and `direction` are used by the tuner such that
`objective=f"val_{metrics}"` and direction is either `"min` or `"max"`.

Parameters `max_trials` denotes the number of trial performed buy the
tuner, `patience` is the number of epochs allowed to perform worst than
the best one before stopping the current trial. The parameter
`execution_per_trial` denotes the number of runs before calculating the
results of a trial, it should be set to value greater than 1 for small
datasets that have high variance in results.

``` python
final_activation = None
loss = "mse"
metrics = "mse"
objective = "val_mse"
direction = "min"
max_trials = 200
patience = 5
executions_per_trial = 3
```

The following code runs the tuner using the hyperparameter ranges
defined above:

The following table describes the best models and their hyperparameters
found by the tuner:

<style type="text/css">
</style>
<table id="T_4aedf">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_4aedf_level0_col0" class="col_heading level0 col0" >0</th>
      <th id="T_4aedf_level0_col1" class="col_heading level0 col1" >1</th>
      <th id="T_4aedf_level0_col2" class="col_heading level0 col2" >2</th>
      <th id="T_4aedf_level0_col3" class="col_heading level0 col3" >3</th>
      <th id="T_4aedf_level0_col4" class="col_heading level0 col4" >4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_4aedf_level0_row0" class="row_heading level0 row0" >units</th>
      <td id="T_4aedf_row0_col0" class="data row0 col0" >21</td>
      <td id="T_4aedf_row0_col1" class="data row0 col1" >17</td>
      <td id="T_4aedf_row0_col2" class="data row0 col2" >19</td>
      <td id="T_4aedf_row0_col3" class="data row0 col3" >21</td>
      <td id="T_4aedf_row0_col4" class="data row0 col4" >22</td>
    </tr>
    <tr>
      <th id="T_4aedf_level0_row1" class="row_heading level0 row1" >n_layers</th>
      <td id="T_4aedf_row1_col0" class="data row1 col0" >2</td>
      <td id="T_4aedf_row1_col1" class="data row1 col1" >2</td>
      <td id="T_4aedf_row1_col2" class="data row1 col2" >2</td>
      <td id="T_4aedf_row1_col3" class="data row1 col3" >2</td>
      <td id="T_4aedf_row1_col4" class="data row1 col4" >2</td>
    </tr>
    <tr>
      <th id="T_4aedf_level0_row2" class="row_heading level0 row2" >activation</th>
      <td id="T_4aedf_row2_col0" class="data row2 col0" >elu</td>
      <td id="T_4aedf_row2_col1" class="data row2 col1" >elu</td>
      <td id="T_4aedf_row2_col2" class="data row2 col2" >elu</td>
      <td id="T_4aedf_row2_col3" class="data row2 col3" >elu</td>
      <td id="T_4aedf_row2_col4" class="data row2 col4" >elu</td>
    </tr>
    <tr>
      <th id="T_4aedf_level0_row3" class="row_heading level0 row3" >learning_rate</th>
      <td id="T_4aedf_row3_col0" class="data row3 col0" >0.073407</td>
      <td id="T_4aedf_row3_col1" class="data row3 col1" >0.105021</td>
      <td id="T_4aedf_row3_col2" class="data row3 col2" >0.080618</td>
      <td id="T_4aedf_row3_col3" class="data row3 col3" >0.042817</td>
      <td id="T_4aedf_row3_col4" class="data row3 col4" >0.107845</td>
    </tr>
    <tr>
      <th id="T_4aedf_level0_row4" class="row_heading level0 row4" >weight_decay</th>
      <td id="T_4aedf_row4_col0" class="data row4 col0" >0.058583</td>
      <td id="T_4aedf_row4_col1" class="data row4 col1" >0.064151</td>
      <td id="T_4aedf_row4_col2" class="data row4 col2" >0.023706</td>
      <td id="T_4aedf_row4_col3" class="data row4 col3" >0.045050</td>
      <td id="T_4aedf_row4_col4" class="data row4 col4" >0.032343</td>
    </tr>
    <tr>
      <th id="T_4aedf_level0_row5" class="row_heading level0 row5" >dropout</th>
      <td id="T_4aedf_row5_col0" class="data row5 col0" >0.157718</td>
      <td id="T_4aedf_row5_col1" class="data row5 col1" >0.189830</td>
      <td id="T_4aedf_row5_col2" class="data row5 col2" >0.149354</td>
      <td id="T_4aedf_row5_col3" class="data row5 col3" >0.324661</td>
      <td id="T_4aedf_row5_col4" class="data row5 col4" >0.237459</td>
    </tr>
    <tr>
      <th id="T_4aedf_level0_row6" class="row_heading level0 row6" >decay_rate</th>
      <td id="T_4aedf_row6_col0" class="data row6 col0" >0.887923</td>
      <td id="T_4aedf_row6_col1" class="data row6 col1" >0.828540</td>
      <td id="T_4aedf_row6_col2" class="data row6 col2" >0.800000</td>
      <td id="T_4aedf_row6_col3" class="data row6 col3" >0.988544</td>
      <td id="T_4aedf_row6_col4" class="data row6 col4" >0.886158</td>
    </tr>
    <tr>
      <th id="T_4aedf_level0_row7" class="row_heading level0 row7" >val_mse_mean</th>
      <td id="T_4aedf_row7_col0" class="data row7 col0" >8.371161</td>
      <td id="T_4aedf_row7_col1" class="data row7 col1" >8.404634</td>
      <td id="T_4aedf_row7_col2" class="data row7 col2" >8.420449</td>
      <td id="T_4aedf_row7_col3" class="data row7 col3" >8.421339</td>
      <td id="T_4aedf_row7_col4" class="data row7 col4" >8.430901</td>
    </tr>
    <tr>
      <th id="T_4aedf_level0_row8" class="row_heading level0 row8" >val_mse_std</th>
      <td id="T_4aedf_row8_col0" class="data row8 col0" >0.084437</td>
      <td id="T_4aedf_row8_col1" class="data row8 col1" >0.149566</td>
      <td id="T_4aedf_row8_col2" class="data row8 col2" >0.110670</td>
      <td id="T_4aedf_row8_col3" class="data row8 col3" >0.063357</td>
      <td id="T_4aedf_row8_col4" class="data row8 col4" >0.115722</td>
    </tr>
    <tr>
      <th id="T_4aedf_level0_row9" class="row_heading level0 row9" >val_mse_min</th>
      <td id="T_4aedf_row9_col0" class="data row9 col0" >8.251875</td>
      <td id="T_4aedf_row9_col1" class="data row9 col1" >8.255271</td>
      <td id="T_4aedf_row9_col2" class="data row9 col2" >8.294801</td>
      <td id="T_4aedf_row9_col3" class="data row9 col3" >8.352478</td>
      <td id="T_4aedf_row9_col4" class="data row9 col4" >8.297507</td>
    </tr>
    <tr>
      <th id="T_4aedf_level0_row10" class="row_heading level0 row10" >val_mse_max</th>
      <td id="T_4aedf_row10_col0" class="data row10 col0" >8.476566</td>
      <td id="T_4aedf_row10_col1" class="data row10 col1" >8.614701</td>
      <td id="T_4aedf_row10_col2" class="data row10 col2" >8.576631</td>
      <td id="T_4aedf_row10_col3" class="data row10 col3" >8.520736</td>
      <td id="T_4aedf_row10_col4" class="data row10 col4" >8.565886</td>
    </tr>
    <tr>
      <th id="T_4aedf_level0_row11" class="row_heading level0 row11" >params</th>
      <td id="T_4aedf_row11_col0" class="data row11 col0" >848</td>
      <td id="T_4aedf_row11_col1" class="data row11 col1" >567</td>
      <td id="T_4aedf_row11_col2" class="data row11 col2" >627</td>
      <td id="T_4aedf_row11_col3" class="data row11 col3" >848</td>
      <td id="T_4aedf_row11_col4" class="data row11 col4" >885</td>
    </tr>
  </tbody>
</table>

## The optimal model

These are the best hyperparameters found by previous runs of the tuner:

``` python
def final_hp_params_f(hp):
    return dict(
        units=hp.Fixed("units", value=21),
        n_layers=hp.Fixed("n_layers", 2),
        activation=hp.Fixed("activation", value="elu"),
        learning_rate=hp.Fixed("learning_rate", value=0.073407),
        weight_decay=hp.Fixed("weight_decay", value=0.058583),
        dropout=hp.Fixed("dropout", value=0.157718),
        decay_rate=hp.Fixed("decay_rate", value=0.887923),
    )
```

The final evaluation of the optimal model:

<style type="text/css">
</style>
<table id="T_fe906">
  <thead>
    <tr>
      <th class="blank level0" >&nbsp;</th>
      <th id="T_fe906_level0_col0" class="col_heading level0 col0" >0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_fe906_level0_row0" class="row_heading level0 row0" >units</th>
      <td id="T_fe906_row0_col0" class="data row0 col0" >21</td>
    </tr>
    <tr>
      <th id="T_fe906_level0_row1" class="row_heading level0 row1" >n_layers</th>
      <td id="T_fe906_row1_col0" class="data row1 col0" >2</td>
    </tr>
    <tr>
      <th id="T_fe906_level0_row2" class="row_heading level0 row2" >activation</th>
      <td id="T_fe906_row2_col0" class="data row2 col0" >elu</td>
    </tr>
    <tr>
      <th id="T_fe906_level0_row3" class="row_heading level0 row3" >learning_rate</th>
      <td id="T_fe906_row3_col0" class="data row3 col0" >0.073407</td>
    </tr>
    <tr>
      <th id="T_fe906_level0_row4" class="row_heading level0 row4" >weight_decay</th>
      <td id="T_fe906_row4_col0" class="data row4 col0" >0.058583</td>
    </tr>
    <tr>
      <th id="T_fe906_level0_row5" class="row_heading level0 row5" >dropout</th>
      <td id="T_fe906_row5_col0" class="data row5 col0" >0.157718</td>
    </tr>
    <tr>
      <th id="T_fe906_level0_row6" class="row_heading level0 row6" >decay_rate</th>
      <td id="T_fe906_row6_col0" class="data row6 col0" >0.887923</td>
    </tr>
    <tr>
      <th id="T_fe906_level0_row7" class="row_heading level0 row7" >val_mse_mean</th>
      <td id="T_fe906_row7_col0" class="data row7 col0" >8.371155</td>
    </tr>
    <tr>
      <th id="T_fe906_level0_row8" class="row_heading level0 row8" >val_mse_std</th>
      <td id="T_fe906_row8_col0" class="data row8 col0" >0.084440</td>
    </tr>
    <tr>
      <th id="T_fe906_level0_row9" class="row_heading level0 row9" >val_mse_min</th>
      <td id="T_fe906_row9_col0" class="data row9 col0" >8.251865</td>
    </tr>
    <tr>
      <th id="T_fe906_level0_row10" class="row_heading level0 row10" >val_mse_max</th>
      <td id="T_fe906_row10_col0" class="data row10 col0" >8.476567</td>
    </tr>
    <tr>
      <th id="T_fe906_level0_row11" class="row_heading level0 row11" >params</th>
      <td id="T_fe906_row11_col0" class="data row11 col0" >848</td>
    </tr>
  </tbody>
</table>
