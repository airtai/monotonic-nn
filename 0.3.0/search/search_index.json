{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#running-in-google-colab","title":"Running in Google Colab","text":"<p>You can execute this interactive tutorial in Google Colab by clicking the button below:</p> <p> </p>"},{"location":"#summary","title":"Summary","text":"<p>This Python library implements Constrained Monotonic Neural Networks as described in:</p> <p>Davor Runje, Sharath M. Shankaranarayana, \u201cConstrained Monotonic Neural Networks\u201d, in Proceedings of the 40th International Conference on Machine Learning, 2023. [PDF].</p>"},{"location":"#abstract","title":"Abstract","text":"<p>Wider adoption of neural networks in many critical domains such as finance and healthcare is being hindered by the need to explain their predictions and to impose additional constraints on them. Monotonicity constraint is one of the most requested properties in real-world scenarios and is the focus of this paper. One of the oldest ways to construct a monotonic fully connected neural network is to constrain signs on its weights. Unfortunately, this construction does not work with popular non-saturated activation functions as it can only approximate convex functions. We show this shortcoming can be fixed by constructing two additional activation functions from a typical unsaturated monotonic activation function and employing each of them on the part of neurons. Our experiments show this approach of building monotonic neural networks has better accuracy when compared to other state-of-the-art methods, while being the simplest one in the sense of having the least number of parameters, and not requiring any modifications to the learning procedure or post-learning steps. Finally, we prove it can approximate any continuous monotone function on a compact subset of \\(\\mathbb{R}^n\\).</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use this library, please cite:</p> bibtex<pre><code>@inproceedings{runje2023,\n  title={Constrained Monotonic Neural Networks},\n  author={Davor Runje and Sharath M. Shankaranarayana},\n  booktitle={Proceedings of the 40th {International Conference on Machine Learning}},\n  year={2023}\n}\n</code></pre>"},{"location":"#python-package","title":"Python package","text":"<p>This package contains an implementation of our Monotonic Dense Layer <code>MonoDense</code> (Constrained Monotonic Fully Connected Layer). Below is the figure from the paper for reference.</p> <p>In the code, the variable <code>monotonicity_indicator</code> corresponds to t in the figure and parameters <code>is_convex</code>, <code>is_concave</code> and <code>activation_weights</code> are used to calculate the activation selector s as follows:</p> <ul> <li> <p>if <code>is_convex</code> or <code>is_concave</code> is True, then the activation   selector s will be (<code>units</code>, 0, 0) and (0, <code>units</code>, 0),   respecively.</p> </li> <li> <p>if both <code>is_convex</code> or <code>is_concave</code> is False, then the   <code>activation_weights</code> represent ratios between \\(\\breve{s}\\), \\(\\hat{s}\\)   and \\(\\tilde{s}\\), respecively. E.g. if <code>activation_weights = (2, 2, 1)</code>   and <code>units = 10</code>, then</p> </li> </ul> \\[ (\\breve{s}, \\hat{s}, \\tilde{s}) = (4, 4, 2) \\] <p></p>"},{"location":"#install","title":"Install","text":"<pre><code>pip install monotonic-nn\n</code></pre>"},{"location":"#how-to-use","title":"How to use","text":"<p>In this example, we\u2019ll assume we have a simple dataset with three inputs values \\(x_1\\), \\(x_2\\) and \\(x_3\\) sampled from the normal distribution, while the output value \\(y\\) is calculated according to the following formula before adding Gaussian noise to it:</p> <p>\\(y = x_1^3 + \\sin\\left(\\frac{x_2}{2 \\pi}\\right) + e^{-x_3}\\)</p> x0 x1 x2 y 0.304717 -1.039984 0.750451 0.234541 0.940565 -1.951035 -1.302180 4.199094 0.127840 -0.316243 -0.016801 0.834086 -0.853044 0.879398 0.777792 -0.093359 0.066031 1.127241 0.467509 0.780875 <p>Now, we\u2019ll use the <code>MonoDense</code> layer instead of <code>Dense</code> layer to build a simple monotonic network. By default, the <code>MonoDense</code> layer assumes the output of the layer is monotonically increasing with all inputs. This assumtion is always true for all layers except possibly the first one. For the first layer, we use <code>monotonicity_indicator</code> to specify which input parameters are monotonic and to specify are they increasingly or decreasingly monotonic:</p> <ul> <li> <p>set 1 for increasingly monotonic parameter,</p> </li> <li> <p>set -1 for decreasingly monotonic parameter, and</p> </li> <li> <p>set 0 otherwise.</p> </li> </ul> <p>In our case, the <code>monotonicity_indicator</code> is <code>[1, 0, -1]</code> because \\(y\\) is:</p> <ul> <li> <p>monotonically increasing w.r.t. \\(x_1\\) \\(\\left(\\frac{\\partial y}{x_1} = 3 {x_1}^2 \\geq 0\\right)\\), and</p> </li> <li> <p>monotonically decreasing w.r.t. \\(x_3\\) \\(\\left(\\frac{\\partial y}{x_3} = - e^{-x_2} \\leq 0\\right)\\).</p> </li> </ul> <pre><code>from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Input\n\nfrom airt.keras.layers import MonoDense\n\nmodel = Sequential()\n\nmodel.add(Input(shape=(3,)))\nmonotonicity_indicator = [1, 0, -1]\nmodel.add(\n    MonoDense(128, activation=\"elu\", monotonicity_indicator=monotonicity_indicator)\n)\nmodel.add(MonoDense(128, activation=\"elu\"))\nmodel.add(MonoDense(1))\n\nmodel.summary()\n</code></pre> <pre><code>Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n mono_dense (MonoDense)      (None, 128)               512\n\n mono_dense_1 (MonoDense)    (None, 128)               16512\n\n mono_dense_2 (MonoDense)    (None, 1)                 129\n\n=================================================================\nTotal params: 17,153\nTrainable params: 17,153\nNon-trainable params: 0\n_________________________________________________________________\n</code></pre> <p>Now we can train the model as usual using <code>Model.fit</code>:</p> <pre><code>from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\nlr_schedule = ExponentialDecay(\n    initial_learning_rate=0.01,\n    decay_steps=10_000 // 32,\n    decay_rate=0.9,\n)\noptimizer = Adam(learning_rate=lr_schedule)\nmodel.compile(optimizer=optimizer, loss=\"mse\")\n\nmodel.fit(\n    x=x_train, y=y_train, batch_size=32, validation_data=(x_val, y_val), epochs=10\n)\n</code></pre> <pre><code>Epoch 1/10\n313/313 [==============================] - 3s 5ms/step - loss: 9.4221 - val_loss: 6.1277\nEpoch 2/10\n313/313 [==============================] - 1s 4ms/step - loss: 4.6001 - val_loss: 2.7813\nEpoch 3/10\n313/313 [==============================] - 1s 4ms/step - loss: 1.6221 - val_loss: 2.1111\nEpoch 4/10\n313/313 [==============================] - 1s 4ms/step - loss: 0.9479 - val_loss: 0.2976\nEpoch 5/10\n313/313 [==============================] - 1s 4ms/step - loss: 0.9008 - val_loss: 0.3240\nEpoch 6/10\n313/313 [==============================] - 1s 4ms/step - loss: 0.5027 - val_loss: 0.1455\nEpoch 7/10\n313/313 [==============================] - 1s 4ms/step - loss: 0.4360 - val_loss: 0.1144\nEpoch 8/10\n313/313 [==============================] - 1s 4ms/step - loss: 0.4993 - val_loss: 0.1211\nEpoch 9/10\n313/313 [==============================] - 1s 4ms/step - loss: 0.3162 - val_loss: 1.0021\nEpoch 10/10\n313/313 [==============================] - 1s 4ms/step - loss: 0.2640 - val_loss: 0.2522\n\n&lt;keras.callbacks.History&gt;\n</code></pre>"},{"location":"#license","title":"License","text":"<p>This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.</p> <p>You are free to:</p> <ul> <li> <p>Share \u2014 copy and redistribute the material in any medium or format</p> </li> <li> <p>Adapt \u2014 remix, transform, and build upon the material</p> </li> </ul> <p>The licensor cannot revoke these freedoms as long as you follow the license terms.</p> <p>Under the following terms:</p> <ul> <li> <p>Attribution \u2014 You must give appropriate credit, provide a link to the   license, and indicate if changes were made. You may do so in any   reasonable manner, but not in any way that suggests the licensor   endorses you or your use.</p> </li> <li> <p>NonCommercial \u2014 You may not use the material for commercial purposes.</p> </li> <li> <p>ShareAlike \u2014 If you remix, transform, or build upon the material, you   must distribute your contributions under the same license as the   original.</p> </li> <li> <p>No additional restrictions \u2014 You may not apply legal terms or   technological measures that legally restrict others from doing   anything the license permits.</p> </li> </ul>"},{"location":"CHANGELOG/","title":"Release notes","text":""},{"location":"CHANGELOG/#034","title":"0.3.4","text":"<ul> <li>fix bug: old version in init.py</li> </ul>"},{"location":"CHANGELOG/#033","title":"0.3.3","text":"<ul> <li>removed support for saving Keras model since it was unstable</li> </ul>"},{"location":"CHANGELOG/#032","title":"0.3.2","text":"<ul> <li>add support for saving Keras model</li> </ul>"},{"location":"CHANGELOG/#031","title":"0.3.1","text":"<ul> <li>add support for import different subpackages with the same root packge name and different locations</li> </ul>"},{"location":"CHANGELOG/#030","title":"0.3.0","text":"<p>Initial version as published at ICML 2023</p>"},{"location":"Experiments/","title":"Experiments","text":""},{"location":"Experiments/#imports","title":"Imports","text":"<pre><code>from keras_tuner import RandomSearch\n</code></pre> <pre><code>environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n</code></pre>"},{"location":"Experiments/#experiments_1","title":"Experiments","text":"<p>For our experiments, we employ the datasets used by the authors of Certified Monotonic Network [1] and COMET [2]. We use the exact train-test split provided by the authors. Their respective repositories are linked below in the references. We directly load the saved train-test data split which have been saved after running the codes from respective papers\u2019 authors.</p> <p>References:</p> <ol> <li>Xingchao Liu, Xing Han, Na Zhang, and Qiang Liu. Certified monotonic     neural networks. Advances in Neural Information Processing Systems,     33:15427\u201315438, 2020</li> </ol> <p>Github repo: https://github.com/gnobitab/CertifiedMonotonicNetwork</p> <ol> <li>Aishwarya Sivaraman, Golnoosh Farnadi, Todd Millstein, and Guy Van     den Broeck. Counterexample-guided learning of monotonic neural     networks. Advances in Neural Information Processing Systems,     33:11936\u201311948, 2020</li> </ol> <p>Github repo: https://github.com/AishwaryaSivaraman/COMET</p> <pre><code>_download_data(\"auto\", force_download=True)\n\n!ls -l data\n\nassert (Path(\"data\") / \"train_auto.csv\").exists()\n</code></pre> <pre><code>train_auto.csv: 49.2kB [00:01, 48.4kB/s]                            \ntest_auto.csv: 16.4kB [00:00, 20.2kB/s]\n\ntotal 257812\n-rw-rw-r-- 1 davor davor    11161 Jun  2 13:28 test_auto.csv\n-rw-rw-r-- 1 davor davor 11340054 May 25 04:48 test_blog.csv\n-rw-rw-r-- 1 davor davor   101210 May 25 04:48 test_compas.csv\n-rw-rw-r-- 1 davor davor    15798 May 25 04:48 test_heart.csv\n-rw-rw-r-- 1 davor davor 13339777 May 25 04:48 test_loan.csv\n-rw-rw-r-- 1 davor davor    44626 Jun  2 13:28 train_auto.csv\n-rw-rw-r-- 1 davor davor 79478767 May 25 04:48 train_blog.csv\n-rw-rw-r-- 1 davor davor   405660 May 25 04:48 train_compas.csv\n-rw-rw-r-- 1 davor davor    62282 May 25 04:48 train_heart.csv\n-rw-rw-r-- 1 davor davor 79588030 May 25 04:48 train_loan.csv\n-rw-rw-r-- 1 davor davor 79588030 May 29 13:57 {prefix}_{name}.csv\n</code></pre> <pre><code>_sanitize_col_names(pd.DataFrame({\"a b\": [1, 2, 3]}))\n</code></pre>   |     | a_b | |-----|-----| | 0   | 1   | | 1   | 2   | | 2   | 3   |   <p>source</p>"},{"location":"Experiments/#get_train_n_test_data","title":"get_train_n_test_data","text":"<pre><code> get_train_n_test_data (dataset_name:str,\n                        data_path:Union[pathlib.Path,str,NoneType]='./data\n                        ')\n</code></pre> <p>Download data</p> <p>Args: dataset_name: name of the dataset, one of \u201cauto\u201d, \u201cheart\u201d, compas\u201d, \u201cblog\u201d, \u201cloan\u201d data_path: root directory where to download data to</p> <pre><code>train_df, test_df = get_train_n_test_data(\"auto\")\ndisplay(train_df)\ndisplay(test_df)\n</code></pre> <pre><code>Upload skipped, file /home/davor/work/projects/airt/mono-dense-keras/nbs/data/train_auto.csv exists.\nUpload skipped, file /home/davor/work/projects/airt/mono-dense-keras/nbs/data/test_auto.csv exists.\n</code></pre>   |     | Cylinders | Displacement | Horsepower | Weight    | Acceleration | Model_Year | Origin    | ground_truth | |-----|-----------|--------------|------------|-----------|--------------|------------|-----------|--------------| | 0   | 1.482807  | 1.073028     | 0.650564   | 0.606625  | -1.275546    | -1.631803  | -0.701669 | 18.0         | | 1   | 1.482807  | 1.482902     | 1.548993   | 0.828131  | -1.452517    | -1.631803  | -0.701669 | 15.0         | | 2   | 1.482807  | 1.044432     | 1.163952   | 0.523413  | -1.275546    | -1.631803  | -0.701669 | 16.0         | | 3   | 1.482807  | 1.025368     | 0.907258   | 0.542165  | -1.806460    | -1.631803  | -0.701669 | 17.0         | | 4   | 1.482807  | 2.235927     | 2.396084   | 1.587581  | -1.983431    | -1.631803  | -0.701669 | 15.0         | | ... | ...       | ...          | ...        | ...       | ...          | ...        | ...       | ...          | | 309 | 0.310007  | 0.358131     | 0.188515   | -0.177437 | -0.319901    | 1.720778   | -0.701669 | 22.0         | | 310 | -0.862792 | -0.566468    | -0.530229  | -0.722413 | -0.921604    | 1.720778   | -0.701669 | 36.0         | | 311 | -0.862792 | -0.928683    | -1.351650  | -1.003691 | 3.184131     | 1.720778   | 0.557325  | 44.0         | | 312 | -0.862792 | -0.566468    | -0.530229  | -0.810312 | -1.417123    | 1.720778   | -0.701669 | 32.0         | | 313 | -0.862792 | -0.709448    | -0.658576  | -0.423555 | 1.060475     | 1.720778   | -0.701669 | 28.0         |  <p>314 rows \u00d7 8 columns</p>   |     | Cylinders | Displacement | Horsepower | Weight    | Acceleration | Model_Year | Origin    | ground_truth | |-----|-----------|--------------|------------|-----------|--------------|------------|-----------|--------------| | 0   | -0.862792 | -1.043066    | -1.017947  | -1.027131 | 1.272841     | 1.162014   | 1.816319  | 40.8         | | 1   | 1.482807  | 1.177880     | 1.163952   | 0.526929  | -1.629489    | -1.631803  | -0.701669 | 18.0         | | 2   | 1.482807  | 1.482902     | 1.934034   | 0.794143  | -1.629489    | -0.793657  | -0.701669 | 11.0         | | 3   | 0.310007  | 0.529707     | -0.119518  | 0.346443  | -0.213718    | -1.352421  | -0.701669 | 19.0         | | 4   | -0.862792 | -1.004939    | -0.863931  | -1.243949 | -0.567661    | 0.882633   | 0.557325  | 31.9         | | ... | ...       | ...          | ...        | ...       | ...          | ...        | ...       | ...          | | 73  | -0.862792 | -0.699916    | 0.188515   | -0.062582 | -0.390690    | -1.073039  | 0.557325  | 18.0         | | 74  | -0.862792 | -0.518809    | -0.838261  | -0.686081 | 1.379024     | -0.793657  | -0.701669 | 21.0         | | 75  | 0.310007  | -0.251914    | 0.701903   | -0.089538 | -1.487912    | 1.162014   | 1.816319  | 32.7         | | 76  | 1.482807  | 1.492434     | 1.138283   | 1.580549  | -0.390690    | 0.323869   | -0.701669 | 16.0         | | 77  | 0.310007  | -0.375829    | 0.060168   | -0.602870 | -0.567661    | -0.793657  | -0.701669 | 21.0         |  <p>78 rows \u00d7 8 columns</p> <p>source</p>"},{"location":"Experiments/#peek","title":"peek","text":"<pre><code> peek (ds:tensorflow.python.data.ops.dataset_ops.DatasetV2)\n</code></pre> <p>Returns the first element of the dataset</p> <p>Args: ds: dataset</p> <p>Returns: the first element of the dataset</p> <p>source</p>"},{"location":"Experiments/#df2ds","title":"df2ds","text":"<pre><code> df2ds (df:pandas.core.frame.DataFrame)\n</code></pre> <p>Converts DataFrame to Dataset</p> <p>Args: df: input DataFrame</p> <p>Returns: dataset</p> <pre><code>x, y = peek(df2ds(train_df).batch(8))\ndisplay(x)\ndisplay(y)\n\nexpected = {\n    \"Acceleration\",\n    \"Cylinders\",\n    \"Displacement\",\n    \"Horsepower\",\n    \"Model_Year\",\n    \"Origin\",\n    \"Weight\",\n}\nassert set(x.keys()) == expected\nfor k in expected:\n    assert x[k].shape == (8,)\nassert y.shape == (8,)\n</code></pre> <pre><code>{'Cylinders': &lt;tf.Tensor: shape=(8,), dtype=float32, numpy=\n array([1.4828068, 1.4828068, 1.4828068, 1.4828068, 1.4828068, 1.4828068,\n        1.4828068, 1.4828068], dtype=float32)&gt;,\n 'Displacement': &lt;tf.Tensor: shape=(8,), dtype=float32, numpy=\n array([1.0730283, 1.4829025, 1.0444324, 1.0253685, 2.235927 , 2.474226 ,\n        2.3407786, 1.8641808], dtype=float32)&gt;,\n 'Horsepower': &lt;tf.Tensor: shape=(8,), dtype=float32, numpy=\n array([0.65056413, 1.5489933 , 1.1639522 , 0.9072582 , 2.3960838 ,\n        2.9608107 , 2.8324637 , 2.1907284 ], dtype=float32)&gt;,\n 'Weight': &lt;tf.Tensor: shape=(8,), dtype=float32, numpy=\n array([0.6066247, 0.828131 , 0.5234134, 0.5421652, 1.5875812, 1.602817 ,\n        1.5535934, 1.0121336], dtype=float32)&gt;,\n 'Acceleration': &lt;tf.Tensor: shape=(8,), dtype=float32, numpy=\n array([-1.2755462, -1.4525175, -1.2755462, -1.8064601, -1.9834315,\n        -2.3373742, -2.5143454, -2.5143454], dtype=float32)&gt;,\n 'Model_Year': &lt;tf.Tensor: shape=(8,), dtype=float32, numpy=\n array([-1.6318026, -1.6318026, -1.6318026, -1.6318026, -1.6318026,\n        -1.6318026, -1.6318026, -1.6318026], dtype=float32)&gt;,\n 'Origin': &lt;tf.Tensor: shape=(8,), dtype=float32, numpy=\n array([-0.7016686, -0.7016686, -0.7016686, -0.7016686, -0.7016686,\n        -0.7016686, -0.7016686, -0.7016686], dtype=float32)&gt;}\n\n&lt;tf.Tensor: shape=(8,), dtype=float32, numpy=array([18., 15., 16., 17., 15., 14., 14., 15.], dtype=float32)&gt;\n</code></pre> <pre><code>train_df, test_df = get_train_n_test_data(\"auto\")\ntrain_ds = df2ds(train_df)\ntest_ds = df2ds(test_df)\n\nbuild_model_f = lambda: _build_mono_model_f(\n    monotonicity_indicator={\n        \"Cylinders\": 0,\n        \"Displacement\": -1,\n        \"Horsepower\": -1,\n        \"Weight\": -1,\n        \"Acceleration\": 0,\n        \"Model_Year\": 0,\n        \"Origin\": 0,\n    },\n    final_activation=None,\n    loss=\"mse\",\n    metrics=\"mse\",\n    train_ds=train_ds,\n    batch_size=8,\n    units=16,\n    n_layers=3,\n    activation=\"elu\",\n    learning_rate=0.01,\n    weight_decay=0.001,\n    dropout=0.25,\n    decay_rate=0.95,\n)\nmodel = build_model_f()\nmodel.summary()\nmodel.fit(train_ds.batch(8), validation_data=test_ds.batch(256), epochs=1)\n</code></pre> <pre><code>Upload skipped, file /home/davor/work/projects/airt/mono-dense-keras/nbs/data/train_auto.csv exists.\nUpload skipped, file /home/davor/work/projects/airt/mono-dense-keras/nbs/data/test_auto.csv exists.\nModel: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n Acceleration (InputLayer)      [(None, 1)]          0           []\n\n Cylinders (InputLayer)         [(None, 1)]          0           []\n\n Displacement (InputLayer)      [(None, 1)]          0           []\n\n Horsepower (InputLayer)        [(None, 1)]          0           []\n\n Model_Year (InputLayer)        [(None, 1)]          0           []\n\n Origin (InputLayer)            [(None, 1)]          0           []\n\n Weight (InputLayer)            [(None, 1)]          0           []\n\n dense_Acceleration (Dense)     (None, 4)            8           ['Acceleration[0][0]']\n\n dense_Cylinders (Dense)        (None, 4)            8           ['Cylinders[0][0]']\n\n mono_dense_Displacement_decrea  (None, 4)           8           ['Displacement[0][0]']           \n sing (MonoDense)\n\n mono_dense_Horsepower_decreasi  (None, 4)           8           ['Horsepower[0][0]']             \n ng (MonoDense)\n\n dense_Model_Year (Dense)       (None, 4)            8           ['Model_Year[0][0]']\n\n dense_Origin (Dense)           (None, 4)            8           ['Origin[0][0]']\n\n mono_dense_Weight_decreasing (  (None, 4)           8           ['Weight[0][0]']                 \n MonoDense)\n\n preprocessed_features (Concate  (None, 28)          0           ['dense_Acceleration[0][0]',     \n nate)                                                            'dense_Cylinders[0][0]',        \n                                                                  'mono_dense_Displacement_decreas\n                                                                 ing[0][0]',                      \n                                                                  'mono_dense_Horsepower_decreasin\n                                                                 g[0][0]',                        \n                                                                  'dense_Model_Year[0][0]',       \n                                                                  'dense_Origin[0][0]',           \n                                                                  'mono_dense_Weight_decreasing[0]\n                                                                 [0]']\n\n mono_dense_0 (MonoDense)       (None, 16)           464         ['preprocessed_features[0][0]']\n\n dropout (Dropout)              (None, 16)           0           ['mono_dense_0[0][0]']\n\n mono_dense_1_increasing (MonoD  (None, 16)          272         ['dropout[0][0]']                \n ense)\n\n dropout_1 (Dropout)            (None, 16)           0           ['mono_dense_1_increasing[0][0]']\n\n mono_dense_2_increasing (MonoD  (None, 1)           17          ['dropout_1[0][0]']              \n ense)\n\n==================================================================================================\nTotal params: 809\nTrainable params: 809\nNon-trainable params: 0\n__________________________________________________________________________________________________\n40/40 [==============================] - 4s 12ms/step - loss: 150.6315 - mse: 150.6315 - val_loss: 342.8134 - val_mse: 342.8134\n\n&lt;keras.callbacks.History&gt;\n</code></pre> <pre><code>def hp_params_f(hp: HyperParameters):\n    return dict(\n        units=hp.Fixed(name=\"units\", value=3),\n        layers=hp.Fixed(name=\"units\", value=1),\n    )\n\n\nwith TemporaryDirectory() as d:\n    tuner = RandomSearch(\n        hypermodel=_TestHyperModel(\n            monotonicity_indicator={\n                \"Cylinders\": 0,\n                \"Displacement\": -1,\n                \"Horsepower\": -1,\n                \"Weight\": -1,\n                \"Acceleration\": 0,\n                \"Model_Year\": 0,\n                \"Origin\": 0,\n            },\n            hp_params_f=lambda hp: {\"units\": hp.Fixed(name=\"units\", value=3)},\n            final_activation=None,\n            loss=\"mse\",\n            metrics=\"mse\",\n            train_ds=train_ds,\n            batch_size=8,\n        ),\n        directory=d,\n        project_name=\"testing\",\n        max_trials=2,\n        objective=\"val_loss\",\n    )\n    tuner.search(\n        train_ds.shuffle(len(train_ds)).batch(8).prefetch(2),\n        validation_data=test_ds.batch(256),\n        epochs=2,\n    )\n</code></pre> <pre><code>Trial 2 Complete [00h 00m 03s]\nval_loss: 28.08372688293457\n\nBest val_loss So Far: 28.08372688293457\nTotal elapsed time: 00h 00m 07s\nINFO:tensorflow:Oracle triggered exit\n</code></pre> <p>source</p>"},{"location":"Experiments/#find_hyperparameters","title":"find_hyperparameters","text":"<pre><code> find_hyperparameters (dataset_name:str,\n                       monotonicity_indicator:Dict[str,int], final_activat\n                       ion:Union[str,Callable[[Union[tensorflow.python.typ\n                       es.core.Tensor,tensorflow.python.types.core.TensorP\n                       rotocol,int,float,bool,str,bytes,complex,tuple,list\n                       ,numpy.ndarray,numpy.generic],Union[tensorflow.pyth\n                       on.types.core.Tensor,tensorflow.python.types.core.T\n                       ensorProtocol,int,float,bool,str,bytes,complex,tupl\n                       e,list,numpy.ndarray,numpy.generic]],Union[tensorfl\n                       ow.python.types.core.Tensor,tensorflow.python.types\n                       .core.TensorProtocol,int,float,bool,str,bytes,compl\n                       ex,tuple,list,numpy.ndarray,numpy.generic]]], loss:\n                       Union[str,Callable[[Union[tensorflow.python.types.c\n                       ore.Tensor,tensorflow.python.types.core.TensorProto\n                       col,int,float,bool,str,bytes,complex,tuple,list,num\n                       py.ndarray,numpy.generic],Union[tensorflow.python.t\n                       ypes.core.Tensor,tensorflow.python.types.core.Tenso\n                       rProtocol,int,float,bool,str,bytes,complex,tuple,li\n                       st,numpy.ndarray,numpy.generic]],Union[tensorflow.p\n                       ython.types.core.Tensor,tensorflow.python.types.cor\n                       e.TensorProtocol,int,float,bool,str,bytes,complex,t\n                       uple,list,numpy.ndarray,numpy.generic]]], metrics:U\n                       nion[str,Callable[[Union[tensorflow.python.types.co\n                       re.Tensor,tensorflow.python.types.core.TensorProtoc\n                       ol,int,float,bool,str,bytes,complex,tuple,list,nump\n                       y.ndarray,numpy.generic],Union[tensorflow.python.ty\n                       pes.core.Tensor,tensorflow.python.types.core.Tensor\n                       Protocol,int,float,bool,str,bytes,complex,tuple,lis\n                       t,numpy.ndarray,numpy.generic]],Union[tensorflow.py\n                       thon.types.core.Tensor,tensorflow.python.types.core\n                       .TensorProtocol,int,float,bool,str,bytes,complex,tu\n                       ple,list,numpy.ndarray,numpy.generic]]], hp_params_\n                       f:Optional[Callable[[keras_tuner.engine.hyperparame\n                       ters.hyperparameters.HyperParameters],Dict[str,Any]\n                       ]]=None, max_trials:int=100, max_epochs:int=50,\n                       batch_size:int=8, objective:Union[str,keras_tuner.e\n                       ngine.objective.Objective], direction:str,\n                       dir_root:Union[pathlib.Path,str]='tuner',\n                       seed:int=42, executions_per_trial:int=3,\n                       max_consecutive_failed_trials:int=5,\n                       patience:int=10)\n</code></pre> <p>Search for optimal hyperparameters</p> <p>Args: dataset_name: name of the dataset, one of \u201cauto\u201d, \u201cheart\u201d, compas\u201d, \u201cblog\u201d, \u201cloan\u201d monotonicity_indicator: monotonicity indicator as used in <code>MonoDense.__init__</code> final_activation: final activation of the neural network loss: Tensorflow loss function metrics: Tensorflow metrics function hp_params_f: a function constructing sampling hyperparameters using Keras Tuner max_trials: maximum number of trials max_epochs: maximum number of epochs in each trial batch_size: batch size objective: objective, typically f\u201dval_{metrics}\u201d direction: direction of the objective, either \u201cmin\u201d or \u201cmax\u201d dir_root: root directory for storing Keras Tuner data seed: random seed used to guarantee reproducibility of results executions_per_trial: number of executions per trial. Set it to number higher than zero for small datasets max_consecutive_failed_trials: maximum number of failed trials as used in Keras Tuner patience: number of epoch with worse objective before stopping trial early</p> <p>Returns: An instance of Keras Tuner</p> <pre><code>shutil.rmtree(\"tuner\", ignore_errors=True)\n\ntuner = find_hyperparameters(\n    \"auto\",\n    monotonicity_indicator={\n        \"Cylinders\": 0,\n        \"Displacement\": -1,\n        \"Horsepower\": -1,\n        \"Weight\": -1,\n        \"Acceleration\": 0,\n        \"Model_Year\": 0,\n        \"Origin\": 0,\n    },\n    max_trials=2,\n    final_activation=None,\n    loss=\"mse\",\n    metrics=\"mse\",\n    objective=\"val_mse\",\n    direction=\"min\",\n    max_epochs=1,\n    executions_per_trial=1,\n)\n</code></pre> <pre><code>Trial 2 Complete [00h 00m 03s]\nval_mse: 32.87412643432617\n\nBest val_mse So Far: 32.87412643432617\nTotal elapsed time: 00h 00m 06s\nINFO:tensorflow:Oracle triggered exit\n</code></pre> <p>source</p>"},{"location":"Experiments/#create_tuner_stats","title":"create_tuner_stats","text":"<pre><code> create_tuner_stats (tuner:keras_tuner.engine.tuner.Tuner,\n                     num_models:int=10, max_epochs:int=50,\n                     batch_size:int=8, patience:int=10, verbose:int=0)\n</code></pre> <p>Calculates statistics for the best models found by Keras Tuner</p> <p>Args: tuner: an instance of Keras Tuner num_models: number of best models to use for calculating statistics max_epochs: maximum number of epochs used in runs batch_size: batch_size patience: maximum number of epochs with worse objective before stopping trial early verbose: verbosity level of <code>Model.fit</code> function</p> <p>Returns: A dataframe with statistics</p> <pre><code>stats = create_tuner_stats(tuner, verbose=0)\n</code></pre> <pre><code>Upload skipped, file /home/davor/work/projects/airt/mono-dense-keras/nbs/data/train_auto.csv exists.\nUpload skipped, file /home/davor/work/projects/airt/mono-dense-keras/nbs/data/test_auto.csv exists.\nWARNING:tensorflow:6 out of the last 8 calls to &lt;function Model.make_test_function.&lt;locals&gt;.test_function&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n</code></pre>   |     | units | n_layers | activation | learning_rate | weight_decay | dropout  | decay_rate | val_mse_mean | val_mse_std | val_mse_min | val_mse_max | params | |-----|-------|----------|------------|---------------|--------------|----------|------------|--------------|-------------|-------------|-------------|--------| | 0   | 9     | 2        | elu        | 0.265157      | 0.196993     | 0.456821 | 0.560699   | 12.738773    | 1.8673      | 10.745923   | 15.125115   | 173    |     |     | units | n_layers | activation | learning_rate | weight_decay | dropout  | decay_rate | val_mse_mean | val_mse_std | val_mse_min | val_mse_max | params | |-----|-------|----------|------------|---------------|--------------|----------|------------|--------------|-------------|-------------|-------------|--------| | 0   | 9     | 2        | elu        | 0.265157      | 0.196993     | 0.456821 | 0.560699   | 12.738773    | 1.86730     | 10.745923   | 15.125115   | 173    | | 1   | 23    | 1        | elu        | 0.004715      | 0.265345     | 0.175923 | 0.816107   | 21.378424    | 1.74334     | 18.393272   | 22.992588   | 106    |"},{"location":"Helpers/","title":"Helpers","text":"<p>source</p>"},{"location":"Helpers/#export","title":"export","text":"<pre><code> export (o:~T, module:str='airt.keras.layers')\n</code></pre> <pre><code>@export\ndef f():\n    pass\n\n\nassert f.__module__ == \"airt.keras.layers\"\n</code></pre>"},{"location":"InDepth/","title":"In-depth explanation","text":""},{"location":"InDepth/#introduction","title":"Introduction","text":"<p>The simplest method to achieve monotonicity by construction is to constrain the weights of the fully connected neural network to have only non-negative (for non-decreasing variables) or only non-positive values (for non-ascending) variables when used in conjunction with a monotonic activation function, a technique known for 30 years (Archer &amp; Wang, 1993). When used in conjunction with saturated (bounded) activation functions such as the sigmoid and hyperbolic tangent, these models are difficult to train, i.e.\u00a0they do not converge to a good solution. On the other hand, when used with non-saturated (unbounded) convex activation functions such as ReLU (Nair &amp; Hinton, 2010), the resulting models are always convex (Liu et al., 2020), severely limiting the applicability of the method in practice.</p> <p>Our main contribution is a modification of the method above which, in conjunction with non-saturated activation functions, is capable of approximating non-convex functions as well: when the original activation function is used with additional two monotonic activation functions constructed from it in a neural network with constrained weights, it can approximate any monotone continuous functions. The resulting model is guaranteed to be monotonic, can be used in conjunction with popular convex monotonic nonsaturated activation function, doesn\u2019t have any additional parameters compared to a non-monotonic fully-connected network for the same task, and can be trained without any additional requirements on the learning procedure. Experimental results show it is exceeding the performance of all other state-of-the-art methods, all while being both simpler (in the number of parameters) and easier to train. Our contributions can be summarized as follows:</p> <ol> <li> <p>A modification to an existing constrained neural network layer     enabling it to model arbitrary monotonic function when used with     non-saturated monotone convex activation functions such as ReLU,     ELU, SELU, and alike.</p> </li> <li> <p>Experimental comparisons with other recent works showing that the     proposed architecture can yield equal or better results than the     previous state-of-the-art and with significantly fewer parameters.</p> </li> <li> <p>A proof showing that the proposed architecture can approximate any     monotone continuous function on a compact subset of \\(\\mathbb{R}^n\\)     for a large class of non-saturated activation functions.</p> </li> </ol>"},{"location":"InDepth/#the-problem","title":"The problem","text":"<p>Most of the commonly used activation functions such as ReLU, ELU, SELU, etc. are monotonically increasing zero-centred, convex, lower-bounded non-polynomial functions. When used in a fully-connected, feed-forward neural network with at least one hidden layer and with unconstrained weights, they can approximate any continuous function on a compact subset. The simplest way to construct a monotonic neural network is to constrain its weights when used in conjunction with a monotone activation function. However, when the activation function is convex as well, the constrained neural network is not able to approximate non-convex functions.</p> <p>To better illustrate this, and to propose a simple solution in this particular example, we refer the readers to plots below where the goal is to approximate the simple cubic function \\(x^3\\) using a neural network with a single hidden layer with either \\(2\\) or \\(32\\) neurons and with ReLU activation. A cubic function is apt for our illustration since it is concave in the considered interval \\([-1, 0]\\) and convex in the interval \\([0, 1]\\).</p>   The plot to the left shows two fully-connected neural networks with one hidden layer with 2 and 32 neurons and ReLU activations approximating the qubic function on the interval $[-1, 1]$.  An unconstrained ReLU network with n neurons can approximate both concave and convex segments of the cubic function using at most $n + 1$ piecewise linear segments. Increasing the number of neurons will provide a better fit with the function being approximated. Notice that even though the cubic function is monotonic, there is no guarantee that the trained model will be monotonic as well.     If we constrain the weights of the network to be non-negative while still employing ReLU activation, the resulting model is monotone and convex. We can no longer approximate non-convex segments such as the cubic function on $[\u22121, 0]$ in the figure, and increasing the number of neurons from 2 to 32 does not yield any significant improvement in the approximation.     Our proposed solution uses a combination of three activation functions in the hidden layer in order to gain the ability to model non-convex, monotone continuous functions. Notice that increasing the number of neurons increases the number of piecewise linear segments to approximate the cubic function. The resulting net- work is monotone by construction even when trained on noisy data."},{"location":"InDepth/#activation-functions","title":"Activation Functions","text":"<p>Our construction is based on generating two additional activation functions from a typical non-saturated activation function such as ReLU, ELU and SELU.</p> <p>We use \\(\\breve{\\mathcal{A}}\\) to denote the set of all zero-centred, monotonically increasing, convex, lower-bounded functions. Let \\(\\breve{\\rho} \\in \\breve{\\mathcal{A}}\\). Then</p> \\[ \\hat{\\rho}(x) = -\\breve{\\rho}(-x) \\] \\[ \\tilde{\\rho}(x) = \\begin{cases}       \\breve{\\rho}(x+1)-\\breve{\\rho}(1) &amp; \\text{if }x &lt; 0\\\\       \\hat{\\rho}(x-1)+\\breve{\\rho}(1) &amp; \\text{otherwise}     \\end{cases}  \\] <p>An example of such activation functions are given in figures below:</p> <p> </p>"},{"location":"InDepth/#monotonicity-indicator","title":"Monotonicity indicator","text":"<p>Our construction is preconditioned on a priori knowledge of (partial) monotonicity of a multivariate, multidimensional function \\(f\\). Let \\(f: K \\mapsto \\mathbb{R}^m\\) be defined on a compact segment \\(K \\subseteq \\mathbb{R}^n\\). Then we define its \\(n\\)-dimensional monotonicity indicator vector \\(\\mathbf{t} = [t_1, \\dots, t_n]\\) element-wise as follows:</p> \\[     t_j= \\begin{cases}       1 &amp; \\text{if }\\cfrac{\\partial f(\\mathbf{x})_i} {\\partial x_j} \\geq 0 \\      \\text{ for each } i \\in \\{1, \\dots , m\\}\\\\       -1 &amp; \\text{if }\\cfrac{\\partial f(\\mathbf{x})_i} {\\partial x_j} \\leq 0 \\      \\text{ for each } i \\in \\{1, \\dots , m\\}\\\\       0 &amp; \\text{otherwise}     \\end{cases}      \\:  \\] <p>Given an \\((m \\times n)\\)-dimensional matrix \\(\\mathbf{M}\\) and \\(n\\)-dimensional monotonicity indicator vector \\(\\mathbf{t}\\), we define the operation \\(|.|_{t}\\) assigning an \\((m \\times n)\\)-dimensional matrix \\(\\mathbf{M'} = |\\mathbf{M}|_{t}\\) to \\(\\mathbf{M}\\) element-wise as follows:</p> \\[     m'_{j,i}= \\begin{cases}       |m_{j,i}| &amp; \\text{if }t_i=1\\\\       -|m_{j,i}| &amp; \\text{if }t_i=-1\\\\       m_{j,i} &amp; \\text{otherwise}     \\end{cases} \\] <p>Below is an example of a kernel \\(W\\in \\mathbb{R}^{9 \u00d7 12}\\) with 12 units and 9 inputs before and after applying the monotonicity indicator \\(t =(-1, -1, -1, 0, 0, 0, 1, 1, 1)\\):</p> <p> </p>"},{"location":"InDepth/#monotonic-dense-layer","title":"Monotonic Dense Layer","text":"<p>Monotonic Dense Unit (<code>MonoDense</code> class) uses weight constrains and activation functions constructed as explained above to construct partially monotonic neural networks. The below is the figure from the paper for reference.</p> <p>In the constructor of <code>MonoDense</code> class:</p> <ul> <li> <p>the parameter <code>monotonicity_indicator</code> corresponds to t in the   figure below, and</p> </li> <li> <p>parameters <code>is_convex</code>, <code>is_concave</code> and <code>activation_weights</code> are used   to calculate the activation selector s as follows:</p> </li> <li> <p>if <code>is_convex</code> or <code>is_concave</code> is True, then the activation     selector s will be (<code>units</code>, 0, 0) and (0, <code>units</code>, 0),     respecively.</p> </li> <li> <p>if both <code>is_convex</code> or <code>is_concave</code> is False, then the     <code>activation_weights</code> represent ratios between \\(\\breve{s}\\), \\(\\hat{s}\\)     and \\(\\tilde{s}\\), respecively. E.g. if     <code>activation_weights = (2, 2, 1)</code> and <code>units = 10</code>, then</p> </li> </ul> \\[ (\\breve{s}, \\hat{s}, \\tilde{s}) = (4, 4, 2) \\] <p></p> <p>Bellow is an example of a batched input to <code>MoneDense</code> layer with batch size 9 and 12 inputs features.</p> <p></p> <p>The figure below is an example of a kernel with 18 units and 12 input features.</p> <p></p> <p>The input \\(x\\) is multiplied with kernel \\((|W^T|_t)^T \\in \\mathbb{R}^{12 \u00d7 18}\\) after applying monotonicity indicator \\(t \\in \\mathbb{R}^{12}\\) to it and then the bias \\(b\\) (initially set to 0) is added to it:</p> <p></p>"},{"location":"InDepth/#architecture-types","title":"Architecture types","text":"<p>The main advantage of our proposed monotonic dense unit is its simplicity. We can build deep neural nets with different architectures by plugging in our monotonic dense blocks. We have two functions for building neural networks using <code>MonoDense</code> layer.</p>"},{"location":"InDepth/#type-1-architecture","title":"Type-1 architecture","text":"<p>The first example shown in the figure below corresponds to the standard MLP type of neural network architecture used in general, where each of the input features is concatenated to form one single input feature vector \\(\\mathbf{x}\\) and fed into the network, with the only difference being that instead of standard fully connected or dense layers, we employ monotonic dense units throughout. For the first (or input layer) layer, the indicator vector \\(\\mathbf{t}\\), is used to identify the monotonicity property of the input feature with respect to the output. Specifically, \\(\\mathbf{t}\\) is set to \\(1\\) for those components in the input feature vector that are monotonically increasing and is set to \\(-1\\) for those components that are monotonically decreasing and set to \\(0\\) if the feature is non-monotonic. For the subsequent hidden layers, monotonic dense units with the indicator vector \\(\\mathbf{t}\\) always being set to \\(1\\) are used in order to preserve monotonicity. Finally, depending on whether the problem at hand is a regression problem or a classification problem (or even a multi-task problem), an appropriate activation function (such as linear activation or sigmoid or softmax) to obtain the final output.</p> <p></p> <pre><code>inputs = {name: Input(name=name, shape=(1,)) for name in list(\"abcd\")}\n\noutputs = MonoDense.create_type_1(\n    inputs=inputs,\n    units=64,\n    final_units=10,\n    activation=\"elu\",\n    n_layers=3,\n    final_activation=\"softmax\",\n    monotonicity_indicator=dict(a=1, b=0, c=-1, d=0),\n    dropout=0.1,\n)\n\nmodel = Model(inputs=inputs, outputs=outputs)\nmodel.summary()\n</code></pre> <pre><code>Model: \"model_7\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n a (InputLayer)                 [(None, 1)]          0           []\n\n b (InputLayer)                 [(None, 1)]          0           []\n\n c (InputLayer)                 [(None, 1)]          0           []\n\n d (InputLayer)                 [(None, 1)]          0           []\n\n concatenate (Concatenate)      (None, 4)            0           ['a[0][0]',                      \n                                                                  'b[0][0]',                      \n                                                                  'c[0][0]',                      \n                                                                  'd[0][0]']\n\n mono_dense_0 (MonoDense)       (None, 64)           320         ['concatenate[0][0]']\n\n dropout (Dropout)              (None, 64)           0           ['mono_dense_0[0][0]']\n\n mono_dense_1_increasing (MonoD  (None, 64)          4160        ['dropout[0][0]']                \n ense)\n\n dropout_1 (Dropout)            (None, 64)           0           ['mono_dense_1_increasing[0][0]']\n\n mono_dense_2_increasing (MonoD  (None, 10)          650         ['dropout_1[0][0]']              \n ense)\n\n tf.nn.softmax (TFOpLambda)     (None, 10)           0           ['mono_dense_2_increasing[0][0]']\n\n==================================================================================================\nTotal params: 5,130\nTrainable params: 5,130\nNon-trainable params: 0\n__________________________________________________________________________________________________\n</code></pre>"},{"location":"InDepth/#type-2-architecture","title":"Type-2 architecture","text":"<p>The figure below shows another example of a neural network architecture that can be built employing proposed monotonic dense blocks. The difference when compared to the architecture described above lies in the way input features are fed into the hidden layers of neural network architecture. Instead of concatenating the features directly, this architecture provides flexibility to employ any form of complex feature extractors for the non-monotonic features and use the extracted feature vectors as inputs. Another difference is that each monotonic input is passed through separate monotonic dense units. This provides an advantage since depending on whether the input is completely concave or convex or both, we can adjust the activation selection vector \\(\\mathbf{s}\\) appropriately along with an appropriate value for the indicator vector \\(\\mathbf{t}\\). Thus, each of the monotonic input features has a separate monotonic dense layer associated with it. Thus as the major difference to the above-mentioned architecture, we concatenate the feature vectors instead of concatenating the inputs directly. The subsequent parts of the network are similar to the architecture described above wherein for the rest of the hidden monotonic dense units, the indicator vector \\(\\mathbf{t}\\) is always set to \\(1\\) to preserve monotonicity.</p> <p></p> <pre><code>inputs = {name: Input(name=name, shape=(1,)) for name in list(\"abcd\")}\noutputs = MonoDense.create_type_2(\n    inputs,\n    units=32,\n    final_units=10,\n    activation=\"elu\",\n    final_activation=\"softmax\",\n    n_layers=3,\n    dropout=0.2,\n    monotonicity_indicator=dict(a=1, b=0, c=-1, d=0),\n    is_convex=dict(a=True, b=False, c=False, d=False),\n)\nmodel = Model(inputs=inputs, outputs=outputs)\nmodel.summary()\n</code></pre> <pre><code>Model: \"model_8\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n a (InputLayer)                 [(None, 1)]          0           []\n\n b (InputLayer)                 [(None, 1)]          0           []\n\n c (InputLayer)                 [(None, 1)]          0           []\n\n d (InputLayer)                 [(None, 1)]          0           []\n\n mono_dense_a_increasing_convex  (None, 8)           16          ['a[0][0]']                      \n  (MonoDense)\n\n dense_b (Dense)                (None, 8)            16          ['b[0][0]']\n\n mono_dense_c_decreasing (MonoD  (None, 8)           16          ['c[0][0]']                      \n ense)\n\n dense_d (Dense)                (None, 8)            16          ['d[0][0]']\n\n preprocessed_features (Concate  (None, 32)          0           ['mono_dense_a_increasing_convex[\n nate)                                                           0][0]',                          \n                                                                  'dense_b[0][0]',                \n                                                                  'mono_dense_c_decreasing[0][0]',\n                                                                  'dense_d[0][0]']\n\n mono_dense_0_convex (MonoDense  (None, 32)          1056        ['preprocessed_features[0][0]']  \n )\n\n dropout_2 (Dropout)            (None, 32)           0           ['mono_dense_0_convex[0][0]']\n\n mono_dense_1_increasing_convex  (None, 32)          1056        ['dropout_2[0][0]']              \n  (MonoDense)\n\n dropout_3 (Dropout)            (None, 32)           0           ['mono_dense_1_increasing_convex[\n                                                                 0][0]']\n\n mono_dense_2_increasing_convex  (None, 10)          330         ['dropout_3[0][0]']              \n  (MonoDense)\n\n tf.nn.softmax_1 (TFOpLambda)   (None, 10)           0           ['mono_dense_2_increasing_convex[\n                                                                 0][0]']\n\n==================================================================================================\nTotal params: 2,506\nTrainable params: 2,506\nNon-trainable params: 0\n__________________________________________________________________________________________________\n</code></pre>"},{"location":"Layers/","title":"Layers","text":"<pre><code>from os import environ\nfrom pathlib import Path\nfrom tempfile import TemporaryDirectory\n\nimport numpy as np\n</code></pre> <pre><code>environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n</code></pre>"},{"location":"Layers/#dummy","title":"dummy","text":"<pre><code> dummy ()\n</code></pre>"},{"location":"License/","title":"License","text":"<p>This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.</p> <p>The full text of the license is given below:</p> <pre><code>Attribution-NonCommercial-ShareAlike 4.0 International\n\n=======================================================================\n\nCreative Commons Corporation (\"Creative Commons\") is not a law firm and\ndoes not provide legal services or legal advice. Distribution of\nCreative Commons public licenses does not create a lawyer-client or\nother relationship. Creative Commons makes its licenses and related\ninformation available on an \"as-is\" basis. Creative Commons gives no\nwarranties regarding its licenses, any material licensed under their\nterms and conditions, or any related information. Creative Commons\ndisclaims all liability for damages resulting from their use to the\nfullest extent possible.\n\nUsing Creative Commons Public Licenses\n\nCreative Commons public licenses provide a standard set of terms and\nconditions that creators and other rights holders may use to share\noriginal works of authorship and other material subject to copyright\nand certain other rights specified in the public license below. The\nfollowing considerations are for informational purposes only, are not\nexhaustive, and do not form part of our licenses.\n\n     Considerations for licensors: Our public licenses are\n     intended for use by those authorized to give the public\n     permission to use material in ways otherwise restricted by\n     copyright and certain other rights. Our licenses are\n     irrevocable. Licensors should read and understand the terms\n     and conditions of the license they choose before applying it.\n     Licensors should also secure all rights necessary before\n     applying our licenses so that the public can reuse the\n     material as expected. Licensors should clearly mark any\n     material not subject to the license. This includes other CC-\n     licensed material, or material used under an exception or\n     limitation to copyright. More considerations for licensors:\n    wiki.creativecommons.org/Considerations_for_licensors\n\n     Considerations for the public: By using one of our public\n     licenses, a licensor grants the public permission to use the\n     licensed material under specified terms and conditions. If\n     the licensor's permission is not necessary for any reason--for\n     example, because of any applicable exception or limitation to\n     copyright--then that use is not regulated by the license. Our\n     licenses grant only permissions under copyright and certain\n     other rights that a licensor has authority to grant. Use of\n     the licensed material may still be restricted for other\n     reasons, including because others have copyright or other\n     rights in the material. A licensor may make special requests,\n     such as asking that all changes be marked or described.\n     Although not required by our licenses, you are encouraged to\n     respect those requests where reasonable. More considerations\n     for the public:\n    wiki.creativecommons.org/Considerations_for_licensees\n\n=======================================================================\n\nCreative Commons Attribution-NonCommercial-ShareAlike 4.0 International\nPublic License\n\nBy exercising the Licensed Rights (defined below), You accept and agree\nto be bound by the terms and conditions of this Creative Commons\nAttribution-NonCommercial-ShareAlike 4.0 International Public License\n(\"Public License\"). To the extent this Public License may be\ninterpreted as a contract, You are granted the Licensed Rights in\nconsideration of Your acceptance of these terms and conditions, and the\nLicensor grants You such rights in consideration of benefits the\nLicensor receives from making the Licensed Material available under\nthese terms and conditions.\n\n\nSection 1 -- Definitions.\n\n  a. Adapted Material means material subject to Copyright and Similar\n     Rights that is derived from or based upon the Licensed Material\n     and in which the Licensed Material is translated, altered,\n     arranged, transformed, or otherwise modified in a manner requiring\n     permission under the Copyright and Similar Rights held by the\n     Licensor. For purposes of this Public License, where the Licensed\n     Material is a musical work, performance, or sound recording,\n     Adapted Material is always produced where the Licensed Material is\n     synched in timed relation with a moving image.\n\n  b. Adapter's License means the license You apply to Your Copyright\n     and Similar Rights in Your contributions to Adapted Material in\n     accordance with the terms and conditions of this Public License.\n\n  c. BY-NC-SA Compatible License means a license listed at\n     creativecommons.org/compatiblelicenses, approved by Creative\n     Commons as essentially the equivalent of this Public License.\n\n  d. Copyright and Similar Rights means copyright and/or similar rights\n     closely related to copyright including, without limitation,\n     performance, broadcast, sound recording, and Sui Generis Database\n     Rights, without regard to how the rights are labeled or\n     categorized. For purposes of this Public License, the rights\n     specified in Section 2(b)(1)-(2) are not Copyright and Similar\n     Rights.\n\n  e. Effective Technological Measures means those measures that, in the\n     absence of proper authority, may not be circumvented under laws\n     fulfilling obligations under Article 11 of the WIPO Copyright\n     Treaty adopted on December 20, 1996, and/or similar international\n     agreements.\n\n  f. Exceptions and Limitations means fair use, fair dealing, and/or\n     any other exception or limitation to Copyright and Similar Rights\n     that applies to Your use of the Licensed Material.\n\n  g. License Elements means the license attributes listed in the name\n     of a Creative Commons Public License. The License Elements of this\n     Public License are Attribution, NonCommercial, and ShareAlike.\n\n  h. Licensed Material means the artistic or literary work, database,\n     or other material to which the Licensor applied this Public\n     License.\n\n  i. Licensed Rights means the rights granted to You subject to the\n     terms and conditions of this Public License, which are limited to\n     all Copyright and Similar Rights that apply to Your use of the\n     Licensed Material and that the Licensor has authority to license.\n\n  j. Licensor means the individual(s) or entity(ies) granting rights\n     under this Public License.\n\n  k. NonCommercial means not primarily intended for or directed towards\n     commercial advantage or monetary compensation. For purposes of\n     this Public License, the exchange of the Licensed Material for\n     other material subject to Copyright and Similar Rights by digital\n     file-sharing or similar means is NonCommercial provided there is\n     no payment of monetary compensation in connection with the\n     exchange.\n\n  l. Share means to provide material to the public by any means or\n     process that requires permission under the Licensed Rights, such\n     as reproduction, public display, public performance, distribution,\n     dissemination, communication, or importation, and to make material\n     available to the public including in ways that members of the\n     public may access the material from a place and at a time\n     individually chosen by them.\n\n  m. Sui Generis Database Rights means rights other than copyright\n     resulting from Directive 96/9/EC of the European Parliament and of\n     the Council of 11 March 1996 on the legal protection of databases,\n     as amended and/or succeeded, as well as other essentially\n     equivalent rights anywhere in the world.\n\n  n. You means the individual or entity exercising the Licensed Rights\n     under this Public License. Your has a corresponding meaning.\n\n\nSection 2 -- Scope.\n\n  a. License grant.\n\n       1. Subject to the terms and conditions of this Public License,\n          the Licensor hereby grants You a worldwide, royalty-free,\n          non-sublicensable, non-exclusive, irrevocable license to\n          exercise the Licensed Rights in the Licensed Material to:\n\n            a. reproduce and Share the Licensed Material, in whole or\n               in part, for NonCommercial purposes only; and\n\n            b. produce, reproduce, and Share Adapted Material for\n               NonCommercial purposes only.\n\n       2. Exceptions and Limitations. For the avoidance of doubt, where\n          Exceptions and Limitations apply to Your use, this Public\n          License does not apply, and You do not need to comply with\n          its terms and conditions.\n\n       3. Term. The term of this Public License is specified in Section\n          6(a).\n\n       4. Media and formats; technical modifications allowed. The\n          Licensor authorizes You to exercise the Licensed Rights in\n          all media and formats whether now known or hereafter created,\n          and to make technical modifications necessary to do so. The\n          Licensor waives and/or agrees not to assert any right or\n          authority to forbid You from making technical modifications\n          necessary to exercise the Licensed Rights, including\n          technical modifications necessary to circumvent Effective\n          Technological Measures. For purposes of this Public License,\n          simply making modifications authorized by this Section 2(a)\n          (4) never produces Adapted Material.\n\n       5. Downstream recipients.\n\n            a. Offer from the Licensor -- Licensed Material. Every\n               recipient of the Licensed Material automatically\n               receives an offer from the Licensor to exercise the\n               Licensed Rights under the terms and conditions of this\n               Public License.\n\n            b. Additional offer from the Licensor -- Adapted Material.\n               Every recipient of Adapted Material from You\n               automatically receives an offer from the Licensor to\n               exercise the Licensed Rights in the Adapted Material\n               under the conditions of the Adapter's License You apply.\n\n            c. No downstream restrictions. You may not offer or impose\n               any additional or different terms or conditions on, or\n               apply any Effective Technological Measures to, the\n               Licensed Material if doing so restricts exercise of the\n               Licensed Rights by any recipient of the Licensed\n               Material.\n\n       6. No endorsement. Nothing in this Public License constitutes or\n          may be construed as permission to assert or imply that You\n          are, or that Your use of the Licensed Material is, connected\n          with, or sponsored, endorsed, or granted official status by,\n          the Licensor or others designated to receive attribution as\n          provided in Section 3(a)(1)(A)(i).\n\n  b. Other rights.\n\n       1. Moral rights, such as the right of integrity, are not\n          licensed under this Public License, nor are publicity,\n          privacy, and/or other similar personality rights; however, to\n          the extent possible, the Licensor waives and/or agrees not to\n          assert any such rights held by the Licensor to the limited\n          extent necessary to allow You to exercise the Licensed\n          Rights, but not otherwise.\n\n       2. Patent and trademark rights are not licensed under this\n          Public License.\n\n       3. To the extent possible, the Licensor waives any right to\n          collect royalties from You for the exercise of the Licensed\n          Rights, whether directly or through a collecting society\n          under any voluntary or waivable statutory or compulsory\n          licensing scheme. In all other cases the Licensor expressly\n          reserves any right to collect such royalties, including when\n          the Licensed Material is used other than for NonCommercial\n          purposes.\n\n\nSection 3 -- License Conditions.\n\nYour exercise of the Licensed Rights is expressly made subject to the\nfollowing conditions.\n\n  a. Attribution.\n\n       1. If You Share the Licensed Material (including in modified\n          form), You must:\n\n            a. retain the following if it is supplied by the Licensor\n               with the Licensed Material:\n\n                 i. identification of the creator(s) of the Licensed\n                    Material and any others designated to receive\n                    attribution, in any reasonable manner requested by\n                    the Licensor (including by pseudonym if\n                    designated);\n\n                ii. a copyright notice;\n\n               iii. a notice that refers to this Public License;\n\n                iv. a notice that refers to the disclaimer of\n                    warranties;\n\n                 v. a URI or hyperlink to the Licensed Material to the\n                    extent reasonably practicable;\n\n            b. indicate if You modified the Licensed Material and\n               retain an indication of any previous modifications; and\n\n            c. indicate the Licensed Material is licensed under this\n               Public License, and include the text of, or the URI or\n               hyperlink to, this Public License.\n\n       2. You may satisfy the conditions in Section 3(a)(1) in any\n          reasonable manner based on the medium, means, and context in\n          which You Share the Licensed Material. For example, it may be\n          reasonable to satisfy the conditions by providing a URI or\n          hyperlink to a resource that includes the required\n          information.\n       3. If requested by the Licensor, You must remove any of the\n          information required by Section 3(a)(1)(A) to the extent\n          reasonably practicable.\n\n  b. ShareAlike.\n\n     In addition to the conditions in Section 3(a), if You Share\n     Adapted Material You produce, the following conditions also apply.\n\n       1. The Adapter's License You apply must be a Creative Commons\n          license with the same License Elements, this version or\n          later, or a BY-NC-SA Compatible License.\n\n       2. You must include the text of, or the URI or hyperlink to, the\n          Adapter's License You apply. You may satisfy this condition\n          in any reasonable manner based on the medium, means, and\n          context in which You Share Adapted Material.\n\n       3. You may not offer or impose any additional or different terms\n          or conditions on, or apply any Effective Technological\n          Measures to, Adapted Material that restrict exercise of the\n          rights granted under the Adapter's License You apply.\n\n\nSection 4 -- Sui Generis Database Rights.\n\nWhere the Licensed Rights include Sui Generis Database Rights that\napply to Your use of the Licensed Material:\n\n  a. for the avoidance of doubt, Section 2(a)(1) grants You the right\n     to extract, reuse, reproduce, and Share all or a substantial\n     portion of the contents of the database for NonCommercial purposes\n     only;\n\n  b. if You include all or a substantial portion of the database\n     contents in a database in which You have Sui Generis Database\n     Rights, then the database in which You have Sui Generis Database\n     Rights (but not its individual contents) is Adapted Material,\n     including for purposes of Section 3(b); and\n\n  c. You must comply with the conditions in Section 3(a) if You Share\n     all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not\nreplace Your obligations under this Public License where the Licensed\nRights include other Copyright and Similar Rights.\n\n\nSection 5 -- Disclaimer of Warranties and Limitation of Liability.\n\n  a. UNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE\n     EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS\n     AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF\n     ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS,\n     IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION,\n     WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR\n     PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS,\n     ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT\n     KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT\n     ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.\n\n  b. TO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE\n     TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION,\n     NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT,\n     INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES,\n     COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR\n     USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN\n     ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR\n     DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR\n     IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.\n\n  c. The disclaimer of warranties and limitation of liability provided\n     above shall be interpreted in a manner that, to the extent\n     possible, most closely approximates an absolute disclaimer and\n     waiver of all liability.\n\n\nSection 6 -- Term and Termination.\n\n  a. This Public License applies for the term of the Copyright and\n     Similar Rights licensed here. However, if You fail to comply with\n     this Public License, then Your rights under this Public License\n     terminate automatically.\n\n  b. Where Your right to use the Licensed Material has terminated under\n     Section 6(a), it reinstates:\n\n       1. automatically as of the date the violation is cured, provided\n          it is cured within 30 days of Your discovery of the\n          violation; or\n\n       2. upon express reinstatement by the Licensor.\n\n     For the avoidance of doubt, this Section 6(b) does not affect any\n     right the Licensor may have to seek remedies for Your violations\n     of this Public License.\n\n  c. For the avoidance of doubt, the Licensor may also offer the\n     Licensed Material under separate terms or conditions or stop\n     distributing the Licensed Material at any time; however, doing so\n     will not terminate this Public License.\n\n  d. Sections 1, 5, 6, 7, and 8 survive termination of this Public\n     License.\n\n\nSection 7 -- Other Terms and Conditions.\n\n  a. The Licensor shall not be bound by any additional or different\n     terms or conditions communicated by You unless expressly agreed.\n\n  b. Any arrangements, understandings, or agreements regarding the\n     Licensed Material not stated herein are separate from and\n     independent of the terms and conditions of this Public License.\n\n\nSection 8 -- Interpretation.\n\n  a. For the avoidance of doubt, this Public License does not, and\n     shall not be interpreted to, reduce, limit, restrict, or impose\n     conditions on any use of the Licensed Material that could lawfully\n     be made without permission under this Public License.\n\n  b. To the extent possible, if any provision of this Public License is\n     deemed unenforceable, it shall be automatically reformed to the\n     minimum extent necessary to make it enforceable. If the provision\n     cannot be reformed, it shall be severed from this Public License\n     without affecting the enforceability of the remaining terms and\n     conditions.\n\n  c. No term or condition of this Public License will be waived and no\n     failure to comply consented to unless expressly agreed to by the\n     Licensor.\n\n  d. Nothing in this Public License constitutes or may be interpreted\n     as a limitation upon, or waiver of, any privileges and immunities\n     that apply to the Licensor or You, including from the legal\n     processes of any jurisdiction or authority.\n\n=======================================================================\n\nCreative Commons is not a party to its public\nlicenses. Notwithstanding, Creative Commons may elect to apply one of\nits public licenses to material it publishes and in those instances\nwill be considered the \u201cLicensor.\u201d The text of the Creative Commons\npublic licenses is dedicated to the public domain under the CC0 Public\nDomain Dedication. Except for the limited purpose of indicating that\nmaterial is shared under a Creative Commons public license or as\notherwise permitted by the Creative Commons policies published at\ncreativecommons.org/policies, Creative Commons does not authorize the\nuse of the trademark \"Creative Commons\" or any other trademark or logo\nof Creative Commons without its prior written consent including,\nwithout limitation, in connection with any unauthorized modifications\nto any of its public licenses or any other arrangements,\nunderstandings, or agreements concerning use of licensed material. For\nthe avoidance of doubt, this paragraph does not form part of the\npublic licenses.\n\nCreative Commons may be contacted at creativecommons.org.\n</code></pre>"},{"location":"MonoDenseLayer/","title":"Monotonic dense layer","text":""},{"location":"MonoDenseLayer/#imports","title":"Imports","text":"<pre><code>from os import environ\nfrom pathlib import Path\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport pytest\nimport seaborn as sns\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Input\n</code></pre> <pre><code>environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\"\n</code></pre>"},{"location":"MonoDenseLayer/#monotonic-dense-layer_1","title":"Monotonic Dense Layer","text":""},{"location":"MonoDenseLayer/#actvation-functions","title":"Actvation Functions","text":"<p>We use \\(\\breve{\\mathcal{A}}\\) to denote the set of all zero-centred, monotonically increasing, convex, lower-bounded functions.</p> <p>Let \\(\\breve{\\rho} \\in \\breve{\\mathcal{A}}\\). Then</p> <p>In the code below, the following names are used for denotation of the above functions:</p> <ul> <li> <p><code>convex_activation</code> denotes \\(\\breve{\\rho}\\),</p> </li> <li> <p><code>concave_activation</code> denotes \\(\\hat{\\rho}\\), and</p> </li> <li> <p><code>saturated_activation</code> denotes \\(\\tilde{\\rho}\\).</p> </li> </ul> <p>source</p>"},{"location":"MonoDenseLayer/#get_activation_functions","title":"get_activation_functions","text":"<pre><code> get_activation_functions (activation:Union[str,Callable[[Union[tensorflow\n                           .python.types.core.Tensor,tensorflow.python.typ\n                           es.core.TensorProtocol,int,float,bool,str,bytes\n                           ,complex,tuple,list,numpy.ndarray,numpy.generic\n                           ]],Union[tensorflow.python.types.core.Tensor,te\n                           nsorflow.python.types.core.TensorProtocol,int,f\n                           loat,bool,str,bytes,complex,tuple,list,numpy.nd\n                           array,numpy.generic]],NoneType]=None)\n</code></pre> <p>source</p>"},{"location":"MonoDenseLayer/#get_saturated_activation","title":"get_saturated_activation","text":"<pre><code> get_saturated_activation (convex_activation:Callable[[Union[tensorflow.py\n                           thon.types.core.Tensor,tensorflow.python.types.\n                           core.TensorProtocol,int,float,bool,str,bytes,co\n                           mplex,tuple,list,numpy.ndarray,numpy.generic]],\n                           Union[tensorflow.python.types.core.Tensor,tenso\n                           rflow.python.types.core.TensorProtocol,int,floa\n                           t,bool,str,bytes,complex,tuple,list,numpy.ndarr\n                           ay,numpy.generic]], concave_activation:Callable\n                           [[Union[tensorflow.python.types.core.Tensor,ten\n                           sorflow.python.types.core.TensorProtocol,int,fl\n                           oat,bool,str,bytes,complex,tuple,list,numpy.nda\n                           rray,numpy.generic]],Union[tensorflow.python.ty\n                           pes.core.Tensor,tensorflow.python.types.core.Te\n                           nsorProtocol,int,float,bool,str,bytes,complex,t\n                           uple,list,numpy.ndarray,numpy.generic]],\n                           a:float=1.0, c:float=1.0)\n</code></pre> <p>source</p>"},{"location":"MonoDenseLayer/#apply_activations","title":"apply_activations","text":"<pre><code> apply_activations (x:Union[tensorflow.python.types.core.Tensor,tensorflow\n                    .python.types.core.TensorProtocol,int,float,bool,str,b\n                    ytes,complex,tuple,list,numpy.ndarray,numpy.generic],\n                    units:int, convex_activation:Callable[[Union[tensorflo\n                    w.python.types.core.Tensor,tensorflow.python.types.cor\n                    e.TensorProtocol,int,float,bool,str,bytes,complex,tupl\n                    e,list,numpy.ndarray,numpy.generic]],Union[tensorflow.\n                    python.types.core.Tensor,tensorflow.python.types.core.\n                    TensorProtocol,int,float,bool,str,bytes,complex,tuple,\n                    list,numpy.ndarray,numpy.generic]], concave_activation\n                    :Callable[[Union[tensorflow.python.types.core.Tensor,t\n                    ensorflow.python.types.core.TensorProtocol,int,float,b\n                    ool,str,bytes,complex,tuple,list,numpy.ndarray,numpy.g\n                    eneric]],Union[tensorflow.python.types.core.Tensor,ten\n                    sorflow.python.types.core.TensorProtocol,int,float,boo\n                    l,str,bytes,complex,tuple,list,numpy.ndarray,numpy.gen\n                    eric]], saturated_activation:Callable[[Union[tensorflo\n                    w.python.types.core.Tensor,tensorflow.python.types.cor\n                    e.TensorProtocol,int,float,bool,str,bytes,complex,tupl\n                    e,list,numpy.ndarray,numpy.generic]],Union[tensorflow.\n                    python.types.core.Tensor,tensorflow.python.types.core.\n                    TensorProtocol,int,float,bool,str,bytes,complex,tuple,\n                    list,numpy.ndarray,numpy.generic]],\n                    is_convex:bool=False, is_concave:bool=False,\n                    activation_weights:Tuple[float,float,float]=(7.0, 7.0,\n                    2.0))\n</code></pre> <pre><code>def plot_applied_activation(\n    activation: str = \"relu\",\n    *,\n    save_pdf: bool = False,\n    save_path: Union[Path, str] = \"plots\",\n    font_size: int = 20,\n    linestyle=\"--\",\n    alpha=0.7,\n    linewidth=2.0,\n):\n    font = {\"size\": font_size}\n    matplotlib.rc(\"font\", **font)\n    plt.rcParams[\"figure.figsize\"] = (18, 3)\n\n    x = np.arange(-1.5, 1.5, step=3 / 256)\n    h = 3 * np.sin(2 * np.pi * x)\n\n    (\n        convex_activation,\n        concave_activation,\n        saturated_activation,\n    ) = get_activation_functions(activation)\n\n    y = apply_activations(\n        h,\n        convex_activation=convex_activation,\n        concave_activation=concave_activation,\n        saturated_activation=saturated_activation,\n        units=x.shape[0],\n        activation_weights=(1.0, 1.0, 1.0),\n    )\n\n    plot_kwargs = dict(linestyle=linestyle, alpha=alpha, linewidth=linewidth)\n\n    plt.plot(np.arange(x.shape[0]), h, label=\"$h$\", **plot_kwargs)\n    plt.plot(np.arange(x.shape[0]), y, label=r\"${\\rho}(h)$\", **plot_kwargs)\n    title = (\n        \"Applying \"\n        + (activation.__name__ if hasattr(activation, \"__name__\") else activation)\n        + f\"-based activations to {x.shape[0]}-dimensional vector\"\n        + r\" $h$\"\n    )\n    plt.title(title)\n\n    plt.legend()\n\n    if save_pdf:\n        path = Path(save_path) / (title.replace(\" \", \"_\") + \".pdf\")\n        path.parent.mkdir(exist_ok=True, parents=True)\n        plt.savefig(path, format=\"pdf\")\n    #         print(f\"Saved figure to: {path}\")\n\n    plt.show()\n</code></pre> <pre><code>for activation in [\"linear\", \"ReLU\", \"ELU\", \"SELU\"]:\n    plot_applied_activation(activation, save_pdf=True)\n</code></pre>"},{"location":"MonoDenseLayer/#monotonicity-indicator","title":"Monotonicity indicator","text":"<p>source</p>"},{"location":"MonoDenseLayer/#get_monotonicity_indicator","title":"get_monotonicity_indicator","text":"<pre><code> get_monotonicity_indicator (monotonicity_indicator:Union[numpy.__array_li\n                             ke._SupportsArray[numpy.dtype],numpy.__nested\n                             _sequence._NestedSequence[numpy.__array_like.\n                             _SupportsArray[numpy.dtype]],bool,int,float,c\n                             omplex,str,bytes,numpy.__nested_sequence._Nes\n                             tedSequence[Union[bool,int,float,complex,str,\n                             bytes]]], input_shape:Tuple[int,...],\n                             units:int)\n</code></pre> <pre><code>input_shape = (13, 2)\nunits = 3\n\nlayer = Dense(units=units)\nlayer.build(input_shape=input_shape)\n\nfor monotonicity_indicator in [\n    1,\n    [1],\n    [1, 1],\n    np.ones((2,)),\n    np.ones((2, 1)),\n    np.ones((2, 3)),\n]:\n    expected = np.ones((2, 3))\n    actual = get_monotonicity_indicator(\n        monotonicity_indicator, input_shape=(13, 2), units=3\n    )\n\n    # rank is 2\n    assert len(actual.shape) == 2\n    # it is broadcastable to the kernel shape of (input_shape[-1], units)\n    np.testing.assert_array_equal(np.broadcast_to(actual, (2, 3)), expected)\n</code></pre> <pre><code>expected = [[1], [0], [-1]]\nactual = get_monotonicity_indicator([1, 0, -1], input_shape=(13, 3), units=4)\nnp.testing.assert_array_equal(actual, expected)\n</code></pre> <pre><code>with pytest.raises(ValueError) as e:\n    get_monotonicity_indicator([0, 1, -1], input_shape=(13, 2), units=3)\nassert e.value.args == (\n    \"operands could not be broadcast together with remapped shapes [original-&gt;remapped]: (3,1)  and requested shape (2,3)\",\n)\n</code></pre> <p>source</p>"},{"location":"MonoDenseLayer/#replace_kernel_using_monotonicity_indicator","title":"replace_kernel_using_monotonicity_indicator","text":"<pre><code> replace_kernel_using_monotonicity_indicator\n                                              (layer:keras.layers.core.den\n                                              se.Dense, monotonicity_indic\n                                              ator:Union[tensorflow.python\n                                              .types.core.Tensor,tensorflo\n                                              w.python.types.core.TensorPr\n                                              otocol,int,float,bool,str,by\n                                              tes,complex,tuple,list,numpy\n                                              .ndarray,numpy.generic])\n</code></pre> <p>source</p>"},{"location":"MonoDenseLayer/#apply_monotonicity_indicator_to_kernel","title":"apply_monotonicity_indicator_to_kernel","text":"<pre><code> apply_monotonicity_indicator_to_kernel\n                                         (kernel:tensorflow.python.ops.var\n                                         iables.Variable, monotonicity_ind\n                                         icator:Union[numpy.__array_like._\n                                         SupportsArray[numpy.dtype],numpy.\n                                         __nested_sequence._NestedSequence\n                                         [numpy.__array_like._SupportsArra\n                                         y[numpy.dtype]],bool,int,float,co\n                                         mplex,str,bytes,numpy.__nested_se\n                                         quence._NestedSequence[Union[bool\n                                         ,int,float,complex,str,bytes]]])\n</code></pre> <pre><code>def display_kernel(kernel: Union[tf.Variable, np.typing.NDArray[float]]) -&gt; None:\n    cm = sns.color_palette(\"coolwarm_r\", as_cmap=True)\n\n    df = pd.DataFrame(kernel)\n\n    display(\n        df.style.format(\"{:.2f}\").background_gradient(cmap=cm, vmin=-1e-8, vmax=1e-8)\n    )\n</code></pre> <pre><code>tf.keras.utils.set_random_seed(42)\n\nunits = 18\ninput_len = 7\n\nlayer = tf.keras.layers.Dense(units=units)\n\ninput_shape = (input_len,)\nlayer.build(input_shape=input_shape)\n\nprint(\"Original kernel:\")\ndisplay_kernel(layer.kernel)\n\nprint(\"Kernel after applying monotocity indicator 1 for all values:\")\nmonotonicity_indicator = get_monotonicity_indicator(\n    1, input_shape=input_shape, units=units\n)\nwith replace_kernel_using_monotonicity_indicator(layer, monotonicity_indicator):\n    display_kernel(layer.kernel)\n</code></pre> <pre><code>Original kernel:\nKernel after applying monotocity indicator 1 for all values:\n</code></pre> 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 0.35 0.16 -0.14 0.44 -0.41 0.15 0.46 -0.33 0.02 0.13 -0.41 -0.05 0.46 -0.03 0.00 0.26 -0.47 -0.30 1 0.01 -0.42 -0.45 0.34 0.41 -0.23 0.35 -0.36 -0.04 0.06 0.07 -0.29 -0.28 0.48 -0.38 -0.06 -0.23 -0.37 2 0.23 -0.31 0.18 0.15 -0.45 0.06 -0.16 -0.11 0.45 -0.09 0.03 -0.24 -0.37 0.21 0.11 0.01 -0.46 -0.37 3 0.29 0.36 -0.07 -0.18 -0.46 -0.45 0.25 0.32 -0.12 0.22 -0.18 0.27 -0.18 -0.07 0.35 0.32 0.18 0.39 4 0.35 -0.27 0.13 -0.40 0.44 0.21 0.06 -0.31 -0.30 0.46 -0.44 -0.18 -0.26 -0.34 0.36 0.33 0.12 0.04 5 0.04 0.21 -0.02 -0.36 0.39 -0.13 0.30 0.35 -0.12 -0.43 0.44 0.32 0.06 -0.30 -0.29 0.24 -0.44 -0.13 6 0.38 -0.04 -0.30 0.17 -0.03 0.37 -0.03 -0.18 0.42 -0.39 -0.33 -0.19 0.02 -0.41 -0.44 0.42 0.38 -0.21 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 0.35 0.16 0.14 0.44 0.41 0.15 0.46 0.33 0.02 0.13 0.41 0.05 0.46 0.03 0.00 0.26 0.47 0.30 1 0.01 0.42 0.45 0.34 0.41 0.23 0.35 0.36 0.04 0.06 0.07 0.29 0.28 0.48 0.38 0.06 0.23 0.37 2 0.23 0.31 0.18 0.15 0.45 0.06 0.16 0.11 0.45 0.09 0.03 0.24 0.37 0.21 0.11 0.01 0.46 0.37 3 0.29 0.36 0.07 0.18 0.46 0.45 0.25 0.32 0.12 0.22 0.18 0.27 0.18 0.07 0.35 0.32 0.18 0.39 4 0.35 0.27 0.13 0.40 0.44 0.21 0.06 0.31 0.30 0.46 0.44 0.18 0.26 0.34 0.36 0.33 0.12 0.04 5 0.04 0.21 0.02 0.36 0.39 0.13 0.30 0.35 0.12 0.43 0.44 0.32 0.06 0.30 0.29 0.24 0.44 0.13 6 0.38 0.04 0.30 0.17 0.03 0.37 0.03 0.18 0.42 0.39 0.33 0.19 0.02 0.41 0.44 0.42 0.38 0.21 <pre><code>monotonicity_indicator = [1] * 2 + [-1] * 2 + [0] * (input_shape[0] - 4)\nmonotonicity_indicator = get_monotonicity_indicator(\n    monotonicity_indicator, input_shape=input_shape, units=units\n)\n\nprint(\"Monotocity indicator:\")\ndisplay_kernel(monotonicity_indicator)\n\nprint(\"Kernel after applying the monotocity indicator:\")\nwith replace_kernel_using_monotonicity_indicator(layer, monotonicity_indicator):\n    display_kernel(layer.kernel)\n</code></pre> <pre><code>Monotocity indicator:\nKernel after applying the monotocity indicator:\n</code></pre> 0 0 1.00 1 1.00 2 -1.00 3 -1.00 4 0.00 5 0.00 6 0.00 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 0.35 0.16 0.14 0.44 0.41 0.15 0.46 0.33 0.02 0.13 0.41 0.05 0.46 0.03 0.00 0.26 0.47 0.30 1 0.01 0.42 0.45 0.34 0.41 0.23 0.35 0.36 0.04 0.06 0.07 0.29 0.28 0.48 0.38 0.06 0.23 0.37 2 -0.23 -0.31 -0.18 -0.15 -0.45 -0.06 -0.16 -0.11 -0.45 -0.09 -0.03 -0.24 -0.37 -0.21 -0.11 -0.01 -0.46 -0.37 3 -0.29 -0.36 -0.07 -0.18 -0.46 -0.45 -0.25 -0.32 -0.12 -0.22 -0.18 -0.27 -0.18 -0.07 -0.35 -0.32 -0.18 -0.39 4 0.35 -0.27 0.13 -0.40 0.44 0.21 0.06 -0.31 -0.30 0.46 -0.44 -0.18 -0.26 -0.34 0.36 0.33 0.12 0.04 5 0.04 0.21 -0.02 -0.36 0.39 -0.13 0.30 0.35 -0.12 -0.43 0.44 0.32 0.06 -0.30 -0.29 0.24 -0.44 -0.13 6 0.38 -0.04 -0.30 0.17 -0.03 0.37 -0.03 -0.18 0.42 -0.39 -0.33 -0.19 0.02 -0.41 -0.44 0.42 0.38 -0.21"},{"location":"MonoDenseLayer/#monotonic-dense-layer_2","title":"Monotonic Dense Layer","text":"<p>This is an implementation of our Monotonic Dense Unit or Constrained Monotone Fully Connected Layer. The below is the figure from the paper for reference.</p> <p>In the code, the variable <code>monotonicity_indicator</code> corresponds to t in the figure and the variable <code>activation_selector</code> corresponds to s.</p> <p>Parameters <code>convexity_indicator</code> and <code>epsilon</code> are used to calculate <code>activation_selector</code> as follows: - if <code>convexity_indicator</code> is -1 or 1, then <code>activation_selector</code> will have all elements 0 or 1, respecively. - if <code>convexity_indicator</code> is <code>None</code>, then <code>epsilon</code> must have a value between 0 and 1 and corresponds to the percentage of elements of <code>activation_selector</code> set to 1.</p> <p></p>"},{"location":"MonoDenseLayer/#monodense","title":"MonoDense","text":"<pre><code> MonoDense (units:int, activation:Union[str,Callable[[Union[tensorflow.pyt\n            hon.types.core.Tensor,tensorflow.python.types.core.TensorProto\n            col,int,float,bool,str,bytes,complex,tuple,list,numpy.ndarray,\n            numpy.generic]],Union[tensorflow.python.types.core.Tensor,tens\n            orflow.python.types.core.TensorProtocol,int,float,bool,str,byt\n            es,complex,tuple,list,numpy.ndarray,numpy.generic]],NoneType]=\n            None, monotonicity_indicator:Union[numpy.__array_like._Support\n            sArray[numpy.dtype],numpy.__nested_sequence._NestedSequence[nu\n            mpy.__array_like._SupportsArray[numpy.dtype]],bool,int,float,c\n            omplex,str,bytes,numpy.__nested_sequence._NestedSequence[Union\n            [bool,int,float,complex,str,bytes]]]=1, is_convex:bool=False,\n            is_concave:bool=False,\n            activation_weights:Tuple[float,float,float]=(7.0, 7.0, 2.0),\n            **kwargs:Any)\n</code></pre> <p>Monotonic counterpart of the regular Dense Layer of tf.keras</p> <p>This is an implementation of our Monotonic Dense Unit or Constrained Monotone Fully Connected Layer. The below is the figure from the paper for reference.</p> <ul> <li> <p>the parameter <code>monotonicity_indicator</code> corresponds to t in the   figure below, and</p> </li> <li> <p>parameters <code>is_convex</code>, <code>is_concave</code> and <code>activation_weights</code> are used   to calculate the activation selector s as follows:</p> </li> <li> <p>if <code>is_convex</code> or <code>is_concave</code> is True, then the activation     selector s will be (<code>units</code>, 0, 0) and (0, <code>units</code>, 0),     respecively.</p> </li> <li> <p>if both <code>is_convex</code> or <code>is_concave</code> is False, then the     <code>activation_weights</code> represent ratios between \\(\\breve{s}\\), \\(\\hat{s}\\)     and \\(\\tilde{s}\\), respecively. E.g. if     <code>activation_weights = (2, 2, 1)</code> and <code>units = 10</code>, then</p> </li> </ul> \\[ (\\breve{s}, \\hat{s}, \\tilde{s}) = (4, 4, 2) \\] <p></p> <pre><code>units = 18\nactivation = \"relu\"\nbatch_size = 9\nx_len = 11\n\nx = np.random.default_rng(42).normal(size=(batch_size, x_len))\n\ntf.keras.utils.set_random_seed(42)\n\nfor monotonicity_indicator in [\n    [1] * 4 + [0] * 4 + [-1] * 3,\n    1,\n    np.ones((x_len,)),\n    -1,\n    -np.ones((x_len,)),\n]:\n    print(\"*\" * 120)\n    mono_layer = MonoDense(\n        units=units,\n        activation=activation,\n        monotonicity_indicator=monotonicity_indicator,\n        activation_weights=(7, 7, 4),\n    )\n    print(\"input:\")\n    display_kernel(x)\n\n    y = mono_layer(x)\n    print(f\"monotonicity_indicator = {monotonicity_indicator}\")\n    display_kernel(mono_layer.monotonicity_indicator)\n\n    print(\"kernel:\")\n    with replace_kernel_using_monotonicity_indicator(\n        mono_layer, mono_layer.monotonicity_indicator\n    ):\n        display_kernel(mono_layer.kernel)\n\n    print(\"output:\")\n    display_kernel(y)\nprint(\"ok\")\n</code></pre> <pre><code>************************************************************************************************************************\ninput:\nWARNING:tensorflow:5 out of the last 5 calls to &lt;function apply_activations&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\nmonotonicity_indicator = [1, 1, 1, 1, 0, 0, 0, 0, -1, -1, -1]\nkernel:\noutput:\n************************************************************************************************************************\ninput:\nmonotonicity_indicator = 1\nkernel:\noutput:\n************************************************************************************************************************\ninput:\nmonotonicity_indicator = [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\nkernel:\noutput:\n************************************************************************************************************************\ninput:\nmonotonicity_indicator = -1\nkernel:\noutput:\n************************************************************************************************************************\ninput:\nmonotonicity_indicator = [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\nkernel:\noutput:\nok\n</code></pre> 0 1 2 3 4 5 6 7 8 9 10 0 0.30 -1.04 0.75 0.94 -1.95 -1.30 0.13 -0.32 -0.02 -0.85 0.88 1 0.78 0.07 1.13 0.47 -0.86 0.37 -0.96 0.88 -0.05 -0.18 -0.68 2 1.22 -0.15 -0.43 -0.35 0.53 0.37 0.41 0.43 2.14 -0.41 -0.51 3 -0.81 0.62 1.13 -0.11 -0.84 -0.82 0.65 0.74 0.54 -0.67 0.23 4 0.12 0.22 0.87 0.22 0.68 0.07 0.29 0.63 -1.46 -0.32 -0.47 5 -0.64 -0.28 1.49 -0.87 0.97 -1.68 -0.33 0.16 0.59 0.71 0.79 6 -0.35 -0.46 0.86 -0.19 -1.28 -1.13 -0.92 0.50 0.14 0.69 -0.43 7 0.16 0.63 -0.31 0.46 -0.66 -0.36 -0.38 -1.20 0.49 -0.47 0.01 8 0.48 0.45 0.67 -0.10 -0.42 -0.08 -1.69 -1.45 -1.32 -1.00 0.40 0 0 1.00 1 1.00 2 1.00 3 1.00 4 0.00 5 0.00 6 0.00 7 0.00 8 -1.00 9 -1.00 10 -1.00 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 0.33 0.15 0.13 0.41 0.38 0.14 0.43 0.30 0.02 0.12 0.38 0.05 0.42 0.03 0.00 0.24 0.44 0.28 1 0.01 0.39 0.42 0.32 0.38 0.22 0.33 0.34 0.03 0.06 0.06 0.27 0.26 0.45 0.35 0.05 0.21 0.34 2 0.21 0.29 0.16 0.14 0.42 0.06 0.15 0.10 0.41 0.08 0.03 0.22 0.34 0.20 0.11 0.01 0.43 0.35 3 0.27 0.33 0.06 0.17 0.42 0.42 0.24 0.30 0.11 0.20 0.17 0.25 0.17 0.07 0.32 0.30 0.17 0.36 4 0.32 -0.25 0.12 -0.37 0.41 0.20 0.06 -0.28 -0.27 0.43 -0.41 -0.17 -0.24 -0.31 0.33 0.31 0.11 0.03 5 0.04 0.19 -0.02 -0.34 0.36 -0.12 0.28 0.32 -0.11 -0.40 0.41 0.30 0.06 -0.28 -0.27 0.23 -0.41 -0.12 6 0.35 -0.04 -0.28 0.16 -0.03 0.35 -0.03 -0.16 0.39 -0.36 -0.31 -0.18 0.02 -0.38 -0.40 0.39 0.35 -0.19 7 0.33 -0.34 0.11 -0.29 0.25 -0.21 0.11 0.08 -0.19 -0.39 0.01 0.10 0.39 -0.25 -0.37 -0.27 0.04 0.34 8 -0.27 -0.09 -0.02 -0.45 -0.16 -0.12 -0.09 -0.43 -0.36 -0.09 -0.23 -0.42 -0.28 -0.24 -0.30 -0.31 -0.07 -0.07 9 -0.38 -0.34 -0.44 -0.42 -0.32 -0.06 -0.27 -0.28 -0.22 -0.05 -0.08 -0.07 -0.21 -0.39 -0.01 -0.26 -0.24 -0.42 10 -0.09 -0.45 -0.41 -0.36 -0.19 -0.09 -0.00 -0.34 -0.17 -0.18 -0.05 -0.39 -0.06 -0.20 -0.40 -0.33 -0.18 -0.01 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 0.01 0.40 0.00 1.38 0.00 0.10 0.00 -0.00 -0.00 -0.13 -0.00 -0.26 -0.00 -0.00 -0.55 -0.52 0.79 0.64 1 0.45 1.02 0.96 0.71 1.22 0.00 0.86 -0.00 -0.00 -0.09 -0.00 -0.00 -0.00 -0.00 0.26 -0.17 0.54 1.00 2 0.30 0.00 0.33 0.00 0.41 0.00 0.42 -0.53 -0.89 -0.29 -0.23 -0.84 -0.16 -0.93 -0.90 0.08 0.37 0.08 3 0.21 0.26 0.33 0.42 0.00 0.00 0.00 -0.16 -0.00 -0.61 -0.53 -0.07 -0.00 -0.00 -0.55 -0.66 0.83 0.78 4 1.38 0.49 0.70 0.82 1.47 0.54 0.63 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 0.73 0.97 0.94 0.91 5 0.00 0.00 0.00 0.00 0.00 0.00 0.00 -1.86 -0.25 -0.00 -1.57 -1.19 -0.61 -0.23 0.13 -1.00 0.50 -0.06 6 0.00 0.00 0.00 0.17 0.00 0.00 0.00 -0.15 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 0.06 -1.00 0.00 0.12 7 0.00 0.96 0.35 0.93 0.00 0.32 0.17 -0.00 -0.00 -0.00 -0.00 -0.00 -0.17 -0.00 0.67 0.06 0.12 0.17 8 0.00 1.33 0.92 1.63 0.52 0.00 0.66 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 1.00 0.23 0.18 0.81 0 1 2 3 4 5 6 7 8 9 10 0 0.30 -1.04 0.75 0.94 -1.95 -1.30 0.13 -0.32 -0.02 -0.85 0.88 1 0.78 0.07 1.13 0.47 -0.86 0.37 -0.96 0.88 -0.05 -0.18 -0.68 2 1.22 -0.15 -0.43 -0.35 0.53 0.37 0.41 0.43 2.14 -0.41 -0.51 3 -0.81 0.62 1.13 -0.11 -0.84 -0.82 0.65 0.74 0.54 -0.67 0.23 4 0.12 0.22 0.87 0.22 0.68 0.07 0.29 0.63 -1.46 -0.32 -0.47 5 -0.64 -0.28 1.49 -0.87 0.97 -1.68 -0.33 0.16 0.59 0.71 0.79 6 -0.35 -0.46 0.86 -0.19 -1.28 -1.13 -0.92 0.50 0.14 0.69 -0.43 7 0.16 0.63 -0.31 0.46 -0.66 -0.36 -0.38 -1.20 0.49 -0.47 0.01 8 0.48 0.45 0.67 -0.10 -0.42 -0.08 -1.69 -1.45 -1.32 -1.00 0.40 0 0 1.00 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 0.44 0.02 0.24 0.22 0.29 0.35 0.18 0.03 0.39 0.17 0.25 0.02 0.10 0.13 0.00 0.42 0.21 0.31 1 0.35 0.06 0.26 0.42 0.05 0.41 0.16 0.33 0.03 0.26 0.11 0.03 0.23 0.04 0.37 0.27 0.32 0.40 2 0.37 0.30 0.36 0.14 0.21 0.40 0.01 0.28 0.16 0.44 0.43 0.23 0.27 0.22 0.23 0.25 0.43 0.05 3 0.32 0.25 0.05 0.45 0.08 0.18 0.26 0.24 0.34 0.07 0.07 0.14 0.04 0.19 0.29 0.23 0.43 0.09 4 0.36 0.05 0.20 0.41 0.38 0.29 0.01 0.44 0.17 0.04 0.31 0.34 0.29 0.16 0.25 0.18 0.01 0.28 5 0.34 0.31 0.38 0.34 0.08 0.40 0.15 0.16 0.14 0.25 0.15 0.20 0.10 0.06 0.44 0.19 0.42 0.21 6 0.01 0.38 0.43 0.18 0.00 0.43 0.45 0.28 0.25 0.18 0.03 0.26 0.22 0.26 0.08 0.23 0.45 0.42 7 0.04 0.12 0.28 0.17 0.11 0.00 0.15 0.24 0.05 0.05 0.27 0.32 0.33 0.11 0.09 0.40 0.19 0.06 8 0.30 0.17 0.21 0.42 0.21 0.29 0.19 0.38 0.03 0.34 0.32 0.30 0.34 0.15 0.28 0.11 0.44 0.19 9 0.10 0.10 0.35 0.32 0.24 0.28 0.30 0.28 0.10 0.12 0.30 0.41 0.15 0.00 0.10 0.40 0.18 0.24 10 0.00 0.22 0.21 0.09 0.10 0.13 0.18 0.37 0.24 0.29 0.25 0.23 0.32 0.14 0.27 0.34 0.25 0.10 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 0.00 0.01 0.00 0.00 0.00 0.00 0.00 -0.93 -0.00 -0.07 -0.58 -0.88 -0.58 -0.00 -0.87 -0.49 -0.05 -1.00 1 0.73 0.10 0.22 0.18 0.18 0.16 0.00 -0.23 -0.00 -0.00 -0.00 -0.09 -0.00 -0.00 0.16 0.47 0.53 -0.27 2 1.15 0.36 0.82 1.20 0.80 1.06 0.61 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 0.53 0.61 1.00 0.94 3 0.00 0.45 0.28 0.00 0.00 0.11 0.14 -0.00 -0.21 -0.00 -0.00 -0.00 -0.00 -0.00 0.15 0.08 0.72 -0.08 4 0.34 0.19 0.36 0.05 0.15 0.30 0.00 -0.00 -0.00 -0.08 -0.00 -0.00 -0.00 -0.00 0.06 0.38 0.04 0.14 5 0.00 0.00 0.26 0.00 0.67 0.05 0.00 -0.00 -0.16 -0.00 -0.00 -0.00 -0.00 -0.00 -0.08 0.30 -0.17 -0.17 6 0.00 0.00 0.00 0.00 0.00 0.00 0.00 -0.76 -0.68 -0.28 -0.11 -0.37 -0.42 -0.40 -0.88 -0.41 -0.67 -1.00 7 0.01 0.00 0.00 0.00 0.00 0.00 0.00 -0.45 -0.17 -0.04 -0.57 -0.82 -0.50 -0.22 -0.07 -0.62 -0.13 -0.18 8 0.00 0.00 0.00 0.00 0.00 0.00 0.00 -1.32 -0.35 -0.39 -0.77 -1.63 -1.12 -0.60 -0.47 -0.99 -1.00 -1.00 0 1 2 3 4 5 6 7 8 9 10 0 0.30 -1.04 0.75 0.94 -1.95 -1.30 0.13 -0.32 -0.02 -0.85 0.88 1 0.78 0.07 1.13 0.47 -0.86 0.37 -0.96 0.88 -0.05 -0.18 -0.68 2 1.22 -0.15 -0.43 -0.35 0.53 0.37 0.41 0.43 2.14 -0.41 -0.51 3 -0.81 0.62 1.13 -0.11 -0.84 -0.82 0.65 0.74 0.54 -0.67 0.23 4 0.12 0.22 0.87 0.22 0.68 0.07 0.29 0.63 -1.46 -0.32 -0.47 5 -0.64 -0.28 1.49 -0.87 0.97 -1.68 -0.33 0.16 0.59 0.71 0.79 6 -0.35 -0.46 0.86 -0.19 -1.28 -1.13 -0.92 0.50 0.14 0.69 -0.43 7 0.16 0.63 -0.31 0.46 -0.66 -0.36 -0.38 -1.20 0.49 -0.47 0.01 8 0.48 0.45 0.67 -0.10 -0.42 -0.08 -1.69 -1.45 -1.32 -1.00 0.40 0 0 1.00 1 1.00 2 1.00 3 1.00 4 1.00 5 1.00 6 1.00 7 1.00 8 1.00 9 1.00 10 1.00 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 0.31 0.02 0.11 0.29 0.10 0.33 0.37 0.06 0.39 0.35 0.15 0.13 0.15 0.45 0.07 0.19 0.03 0.06 1 0.12 0.02 0.06 0.41 0.32 0.24 0.34 0.28 0.22 0.06 0.33 0.27 0.25 0.23 0.43 0.09 0.45 0.27 2 0.19 0.11 0.19 0.25 0.07 0.42 0.32 0.35 0.15 0.05 0.00 0.24 0.22 0.39 0.44 0.11 0.19 0.10 3 0.15 0.37 0.21 0.41 0.25 0.04 0.37 0.04 0.05 0.22 0.31 0.35 0.35 0.08 0.38 0.01 0.25 0.29 4 0.17 0.45 0.24 0.32 0.01 0.00 0.19 0.34 0.17 0.19 0.18 0.34 0.02 0.24 0.03 0.41 0.26 0.00 5 0.29 0.10 0.07 0.34 0.04 0.30 0.39 0.27 0.39 0.16 0.33 0.45 0.06 0.19 0.23 0.04 0.36 0.04 6 0.13 0.15 0.22 0.40 0.14 0.30 0.11 0.45 0.14 0.17 0.26 0.16 0.36 0.10 0.17 0.32 0.14 0.08 7 0.25 0.25 0.24 0.45 0.17 0.45 0.30 0.35 0.41 0.40 0.11 0.26 0.32 0.08 0.22 0.34 0.05 0.09 8 0.16 0.27 0.10 0.23 0.08 0.21 0.19 0.16 0.06 0.04 0.17 0.05 0.39 0.11 0.26 0.25 0.13 0.05 9 0.17 0.17 0.00 0.13 0.12 0.03 0.39 0.11 0.01 0.29 0.43 0.20 0.21 0.43 0.39 0.18 0.19 0.27 10 0.26 0.23 0.43 0.04 0.25 0.36 0.21 0.36 0.37 0.36 0.08 0.14 0.25 0.24 0.30 0.33 0.04 0.07 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 0.00 0.00 0.08 0.00 0.00 0.00 0.00 -0.82 -0.58 -0.32 -1.07 -1.09 -0.00 -0.63 -0.21 -0.74 -1.00 -0.15 1 0.36 0.00 0.00 0.51 0.11 0.72 0.76 -0.12 -0.00 -0.00 -0.05 -0.00 -0.00 -0.00 0.56 -0.34 0.13 0.22 2 0.72 0.68 0.32 1.10 0.10 0.84 0.68 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 0.20 0.97 0.33 -0.07 3 0.00 0.00 0.36 0.35 0.36 0.82 0.00 -0.00 -0.00 -0.19 -0.29 -0.13 -0.00 -0.20 0.67 0.20 -0.00 0.14 4 0.18 0.14 0.26 0.68 0.09 0.38 0.36 -0.00 -0.00 -0.00 -0.00 -0.00 -0.07 -0.00 0.14 0.15 0.33 0.10 5 0.01 0.55 0.50 0.00 0.00 0.21 0.00 -0.00 -0.27 -0.00 -0.44 -0.25 -0.00 -0.00 0.44 0.83 -0.24 -0.01 6 0.00 0.00 0.00 0.00 0.00 0.00 0.00 -0.89 -0.85 -0.48 -0.77 -0.90 -0.21 -0.30 -0.09 -0.69 -0.83 -0.03 7 0.00 0.00 0.00 0.00 0.01 0.00 0.00 -0.78 -0.59 -0.65 -0.21 -0.55 -0.19 -0.37 -0.17 -0.71 -0.10 0.03 8 0.00 0.00 0.00 0.00 0.00 0.00 0.00 -1.24 -0.48 -0.95 -1.13 -0.71 -1.40 -0.30 -0.76 -1.00 -0.47 -0.39 0 1 2 3 4 5 6 7 8 9 10 0 0.30 -1.04 0.75 0.94 -1.95 -1.30 0.13 -0.32 -0.02 -0.85 0.88 1 0.78 0.07 1.13 0.47 -0.86 0.37 -0.96 0.88 -0.05 -0.18 -0.68 2 1.22 -0.15 -0.43 -0.35 0.53 0.37 0.41 0.43 2.14 -0.41 -0.51 3 -0.81 0.62 1.13 -0.11 -0.84 -0.82 0.65 0.74 0.54 -0.67 0.23 4 0.12 0.22 0.87 0.22 0.68 0.07 0.29 0.63 -1.46 -0.32 -0.47 5 -0.64 -0.28 1.49 -0.87 0.97 -1.68 -0.33 0.16 0.59 0.71 0.79 6 -0.35 -0.46 0.86 -0.19 -1.28 -1.13 -0.92 0.50 0.14 0.69 -0.43 7 0.16 0.63 -0.31 0.46 -0.66 -0.36 -0.38 -1.20 0.49 -0.47 0.01 8 0.48 0.45 0.67 -0.10 -0.42 -0.08 -1.69 -1.45 -1.32 -1.00 0.40 0 0 -1.00 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 -0.29 -0.12 -0.00 -0.17 -0.33 -0.17 -0.33 -0.36 -0.28 -0.16 -0.24 -0.22 -0.10 -0.13 -0.02 -0.38 -0.23 -0.02 1 -0.36 -0.13 -0.05 -0.07 -0.41 -0.30 -0.38 -0.06 -0.40 -0.42 -0.44 -0.03 -0.27 -0.03 -0.32 -0.31 -0.35 -0.40 2 -0.30 -0.07 -0.40 -0.06 -0.10 -0.21 -0.16 -0.22 -0.06 -0.36 -0.40 -0.42 -0.23 -0.22 -0.20 -0.33 -0.45 -0.06 3 -0.05 -0.08 -0.07 -0.30 -0.44 -0.23 -0.40 -0.25 -0.13 -0.31 -0.11 -0.13 -0.13 -0.34 -0.15 -0.05 -0.36 -0.13 4 -0.45 -0.34 -0.41 -0.39 -0.15 -0.10 -0.40 -0.32 -0.19 -0.13 -0.29 -0.39 -0.43 -0.29 -0.13 -0.05 -0.39 -0.01 5 -0.09 -0.38 -0.00 -0.12 -0.07 -0.42 -0.01 -0.12 -0.26 -0.28 -0.16 -0.06 -0.08 -0.43 -0.23 -0.28 -0.28 -0.07 6 -0.34 -0.38 -0.15 -0.44 -0.41 -0.19 -0.25 -0.41 -0.34 -0.22 -0.43 -0.36 -0.25 -0.28 -0.06 -0.12 -0.15 -0.16 7 -0.17 -0.39 -0.40 -0.26 -0.40 -0.20 -0.10 -0.14 -0.42 -0.21 -0.18 -0.25 -0.15 -0.21 -0.13 -0.41 -0.14 -0.14 8 -0.38 -0.03 -0.10 -0.21 -0.13 -0.04 -0.19 -0.00 -0.09 -0.38 -0.01 -0.27 -0.24 -0.24 -0.13 -0.18 -0.37 -0.21 9 -0.43 -0.08 -0.20 -0.29 -0.10 -0.27 -0.08 -0.43 -0.22 -0.37 -0.27 -0.24 -0.15 -0.22 -0.01 -0.45 -0.35 -0.31 10 -0.38 -0.44 -0.20 -0.31 -0.42 -0.23 -0.03 -0.31 -0.11 -0.35 -0.01 -0.00 -0.00 -0.39 -0.45 -0.14 -0.03 -0.10 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 1.05 0.88 0.59 0.61 0.00 0.70 0.64 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 0.24 0.74 1.00 0.55 1 0.27 0.26 0.00 0.41 0.00 0.00 0.00 -0.00 -0.23 -0.34 -0.21 -0.20 -0.00 -0.02 -0.04 -0.82 -0.52 -0.02 2 0.00 0.00 0.00 0.00 0.00 0.00 0.00 -0.36 -0.77 -0.71 -0.39 -1.00 -0.82 -0.67 -0.11 -0.74 -0.97 -0.31 3 0.00 0.00 0.00 0.00 0.00 0.01 0.00 -0.00 -0.16 -0.50 -0.38 -0.33 -0.20 -0.00 -0.39 -0.20 -0.12 -0.36 4 0.00 0.00 0.00 0.00 0.00 0.00 0.00 -0.45 -0.46 -0.00 -0.84 -0.48 -0.36 -0.13 -0.08 -0.28 -0.33 0.13 5 0.00 0.02 0.00 0.00 0.12 0.33 0.00 -0.41 -0.00 -0.44 -0.33 -0.90 -0.56 -0.04 -0.24 -0.27 -0.48 -0.16 6 0.74 1.20 0.11 0.90 0.84 0.65 0.87 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 0.60 0.01 0.53 0.12 7 0.47 0.89 0.91 0.62 0.26 0.37 0.01 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 0.07 0.61 0.29 0.01 8 1.30 1.17 0.98 1.61 1.09 0.59 0.65 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 0.09 0.93 0.95 0.81 0 1 2 3 4 5 6 7 8 9 10 0 0.30 -1.04 0.75 0.94 -1.95 -1.30 0.13 -0.32 -0.02 -0.85 0.88 1 0.78 0.07 1.13 0.47 -0.86 0.37 -0.96 0.88 -0.05 -0.18 -0.68 2 1.22 -0.15 -0.43 -0.35 0.53 0.37 0.41 0.43 2.14 -0.41 -0.51 3 -0.81 0.62 1.13 -0.11 -0.84 -0.82 0.65 0.74 0.54 -0.67 0.23 4 0.12 0.22 0.87 0.22 0.68 0.07 0.29 0.63 -1.46 -0.32 -0.47 5 -0.64 -0.28 1.49 -0.87 0.97 -1.68 -0.33 0.16 0.59 0.71 0.79 6 -0.35 -0.46 0.86 -0.19 -1.28 -1.13 -0.92 0.50 0.14 0.69 -0.43 7 0.16 0.63 -0.31 0.46 -0.66 -0.36 -0.38 -1.20 0.49 -0.47 0.01 8 0.48 0.45 0.67 -0.10 -0.42 -0.08 -1.69 -1.45 -1.32 -1.00 0.40 0 0 -1.00 1 -1.00 2 -1.00 3 -1.00 4 -1.00 5 -1.00 6 -1.00 7 -1.00 8 -1.00 9 -1.00 10 -1.00 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 -0.45 -0.28 -0.30 -0.41 -0.17 -0.39 -0.22 -0.45 -0.28 -0.40 -0.18 -0.20 -0.16 -0.18 -0.10 -0.13 -0.14 -0.35 1 -0.09 -0.27 -0.09 -0.14 -0.02 -0.36 -0.21 -0.05 -0.05 -0.01 -0.02 -0.45 -0.03 -0.09 -0.01 -0.05 -0.39 -0.05 2 -0.17 -0.15 -0.37 -0.35 -0.32 -0.03 -0.24 -0.31 -0.35 -0.41 -0.00 -0.37 -0.18 -0.26 -0.09 -0.44 -0.09 -0.17 3 -0.42 -0.17 -0.11 -0.31 -0.32 -0.11 -0.20 -0.10 -0.34 -0.15 -0.24 -0.22 -0.22 -0.08 -0.40 -0.02 -0.23 -0.38 4 -0.13 -0.17 -0.06 -0.13 -0.32 -0.42 -0.28 -0.44 -0.03 -0.26 -0.38 -0.45 -0.08 -0.06 -0.04 -0.33 -0.27 -0.38 5 -0.32 -0.38 -0.19 -0.19 -0.33 -0.01 -0.15 -0.08 -0.31 -0.27 -0.07 -0.11 -0.21 -0.22 -0.18 -0.27 -0.19 -0.15 6 -0.30 -0.16 -0.09 -0.25 -0.23 -0.44 -0.25 -0.16 -0.05 -0.13 -0.20 -0.09 -0.14 -0.18 -0.15 -0.22 -0.37 -0.38 7 -0.20 -0.14 -0.12 -0.10 -0.42 -0.42 -0.14 -0.04 -0.44 -0.11 -0.10 -0.17 -0.06 -0.29 -0.22 -0.24 -0.01 -0.45 8 -0.31 -0.11 -0.16 -0.21 -0.16 -0.39 -0.12 -0.36 -0.36 -0.29 -0.24 -0.24 -0.20 -0.18 -0.33 -0.39 -0.20 -0.02 9 -0.41 -0.14 -0.12 -0.21 -0.01 -0.37 -0.03 -0.22 -0.38 -0.22 -0.09 -0.22 -0.19 -0.17 -0.13 -0.32 -0.30 -0.21 10 -0.31 -0.05 -0.02 -0.36 -0.04 -0.15 -0.03 -0.12 -0.36 -0.21 -0.40 -0.03 -0.04 -0.03 -0.23 -0.01 -0.02 -0.41 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 0 0.20 0.84 0.11 0.00 0.55 1.24 0.55 -0.00 -0.02 -0.00 -0.00 -0.00 -0.00 -0.00 -0.20 0.98 1.00 0.30 1 0.00 0.00 0.00 0.00 0.00 0.19 0.00 -0.14 -0.87 -0.50 -0.00 -0.34 -0.28 -0.53 -0.24 -0.34 0.23 -0.09 2 0.00 0.00 0.00 0.00 0.00 0.00 0.00 -1.34 -0.82 -1.02 -0.75 -0.74 -0.56 -0.68 -0.71 -1.00 -0.65 -0.56 3 0.23 0.18 0.00 0.00 0.00 0.00 0.00 -0.00 -0.27 -0.00 -0.00 -0.21 -0.00 -0.28 -0.21 -0.25 0.02 0.00 4 0.09 0.00 0.00 0.00 0.00 0.00 0.00 -0.08 -0.00 -0.14 -0.00 -0.50 -0.01 -0.25 0.23 -0.20 -0.14 -0.66 5 0.18 0.49 0.00 0.00 0.03 0.00 0.00 -0.79 -0.36 -0.49 -0.39 -0.69 -0.00 -0.09 0.08 -0.84 0.10 -0.25 6 0.64 0.77 0.08 0.50 0.62 0.79 0.68 -0.00 -0.06 -0.00 -0.00 -0.00 -0.00 -0.00 0.28 0.24 0.86 0.87 7 0.32 0.24 0.23 0.18 0.76 0.62 0.28 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 0.13 0.73 0.09 0.87 8 1.23 0.50 0.27 0.51 1.08 2.00 0.60 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 -0.00 1.00 1.00 1.00 1.00 <pre><code>x = Input(shape=(5, 7, 8))\n\nlayer = MonoDense(\n    units=12,\n    activation=activation,\n    monotonicity_indicator=[1] * 3 + [-1] * 3 + [0] * 2,\n    is_convex=False,\n    is_concave=False,\n)\n\ny = layer(x)\n\nmodel = Model(inputs=x, outputs=y)\n\nmodel.summary()\n\ndisplay_kernel(layer.monotonicity_indicator)\n</code></pre> <pre><code>Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 5, 7, 8)]         0\n\n mono_dense_5 (MonoDense)    (None, 5, 7, 12)          108\n\n=================================================================\nTotal params: 108\nTrainable params: 108\nNon-trainable params: 0\n_________________________________________________________________\n</code></pre> 0 0 1.00 1 1.00 2 1.00 3 -1.00 4 -1.00 5 -1.00 6 0.00 7 0.00"},{"location":"MonoDenseLayer/#mono-blocks","title":"Mono blocks","text":"<pre><code>x = Input(shape=(5, 7, 8))\n\n# monotonicity indicator must be broadcastable to input shape, so we use the vector of length 8\nmonotonicity_indicator = [1] * 3 + [0] * 2 + [-1] * 3\n\n# this mono block has 4 layers with the final one having the shape\nmono_block = _create_mono_block(\n    units=[16] * 3 + [3],\n    monotonicity_indicator=monotonicity_indicator,\n    activation=\"elu\",\n    dropout=0.1,\n)\ny = mono_block(x)\nmodel = Model(inputs=x, outputs=y)\nmodel.summary()\n\nmono_layers = [layer for layer in model.layers if isinstance(layer, MonoDense)]\nassert not (mono_layers[0].monotonicity_indicator == 1).all()\nfor mono_layer in mono_layers[1:]:\n    assert (mono_layer.monotonicity_indicator == 1).all()\n\nfor mono_layer in mono_layers[:-1]:\n    assert mono_layer.org_activation == \"elu\"\nassert mono_layers[-1].org_activation == None\n</code></pre> <pre><code>Model: \"model_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_2 (InputLayer)        [(None, 5, 7, 8)]         0\n\n mono_dense_0 (MonoDense)    (None, 5, 7, 16)          144\n\n dropout (Dropout)           (None, 5, 7, 16)          0\n\n mono_dense_1_increasing (Mo  (None, 5, 7, 16)         272       \n noDense)\n\n dropout_1 (Dropout)         (None, 5, 7, 16)          0\n\n mono_dense_2_increasing (Mo  (None, 5, 7, 16)         272       \n noDense)\n\n dropout_2 (Dropout)         (None, 5, 7, 16)          0\n\n mono_dense_3_increasing (Mo  (None, 5, 7, 3)          51        \n noDense)\n\n=================================================================\nTotal params: 739\nTrainable params: 739\nNon-trainable params: 0\n_________________________________________________________________\n</code></pre> <pre><code>inputs = Input(name=\"a\", shape=(1,))\nparam = 0\n\nactual = _prepare_mono_input_n_param(inputs, param)\nexpected = [inputs], [0], [\"inputs\"]\nassert actual == expected, actual\n</code></pre> <pre><code>inputs = Input(name=\"a\", shape=(1,))\nparam = {\"a\": 1}\n\nwith pytest.raises(ValueError) as e:\n    actual = _prepare_mono_input_n_param(inputs, param)\n\ne\n</code></pre> <pre><code>&lt;ExceptionInfo ValueError(\"Uncompatible types: type(inputs)=&lt;class 'keras.engine.keras_tensor.KerasTensor'&gt;, type(param)=&lt;class 'dict'&gt;\") tblen=2&gt;\n</code></pre> <pre><code>a = Input(name=\"a\", shape=(1,))\nactual = _prepare_mono_input_n_param({\"a\": a}, -1)\nassert actual == ([a], [-1], [\"a\"])\n</code></pre> <pre><code>a = Input(name=\"a\", shape=(1,))\nb = Input(name=\"b\", shape=(1,))\n\nactual = _prepare_mono_input_n_param({\"a\": a, \"b\": b}, {\"a\": -1, \"b\": 1})\nassert actual == ([a, b], [-1, 1], [\"a\", \"b\"])\n</code></pre> <pre><code>with pytest.raises(ValueError) as e:\n    actual = _prepare_mono_input_n_param(\n        {\"a\": Input(name=\"a\", shape=(1,)), \"b\": Input(name=\"b\", shape=(1,))}, {\"a\": -1}\n    )\ne\n</code></pre> <pre><code>&lt;ExceptionInfo ValueError(\"{'a'} != {'b', 'a'}\") tblen=2&gt;\n</code></pre> <pre><code>a = Input(name=\"a\", shape=(1,))\nb = Input(name=\"b\", shape=(1,))\n\nactual = _prepare_mono_input_n_param([a, b], [1, -1])\nassert actual == ([a, b], [1, -1], [\"0\", \"1\"])\n</code></pre> <pre><code>a = Input(name=\"a\", shape=(1,))\nb = Input(name=\"b\", shape=(1,))\n\nactual = _prepare_mono_input_n_param([a, b], -1)\nassert actual == ([a, b], [-1, -1], [\"0\", \"1\"])\n</code></pre> <pre><code>monotonicity_indicator = [-1, 0, 1]\nis_convex = [True] * 3\nis_concave = [False] * 3\nnames = list(\"abc\")\nhas_convex, has_concave = _check_convexity_params(\n    monotonicity_indicator, is_convex, is_concave, names\n)\nassert (has_convex, has_concave) == (True, False)\n</code></pre>"},{"location":"MonoDenseLayer/#type-1-architecture","title":"Type-1 architecture","text":"<pre><code>n_layers = 4\n\ninputs = {name: Input(name=name, shape=(1,)) for name in list(\"abcd\")}\noutputs = _create_type_1(\n    inputs=inputs,\n    units=64,\n    final_units=10,\n    activation=\"elu\",\n    n_layers=n_layers,\n    final_activation=\"softmax\",\n    monotonicity_indicator=dict(a=1, b=0, c=-1, d=0),\n    is_convex=True,\n    dropout=0.1,\n)\n\nmodel = Model(inputs=inputs, outputs=outputs)\nmodel.summary()\n\nmono_layers = [layer for layer in model.layers if isinstance(layer, MonoDense)]\nassert len(mono_layers) == n_layers\n\n# check monotonicity indicator\nnp.testing.assert_array_equal(\n    mono_layers[0].monotonicity_indicator, np.array([1, 0, -1, 0]).reshape((-1, 1))\n)\nfor i in range(1, n_layers):\n    assert mono_layers[i].monotonicity_indicator == 1\n\n# check convexity and concavity\nfor i in range(n_layers):\n    assert mono_layers[i].is_convex\n    assert not mono_layers[i].is_concave\n</code></pre> <pre><code>Model: \"model_2\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n a (InputLayer)                 [(None, 1)]          0           []\n\n b (InputLayer)                 [(None, 1)]          0           []\n\n c (InputLayer)                 [(None, 1)]          0           []\n\n d (InputLayer)                 [(None, 1)]          0           []\n\n concatenate (Concatenate)      (None, 4)            0           ['a[0][0]',                      \n                                                                  'b[0][0]',                      \n                                                                  'c[0][0]',                      \n                                                                  'd[0][0]']\n\n mono_dense_0_convex (MonoDense  (None, 64)          320         ['concatenate[0][0]']            \n )\n\n dropout_3 (Dropout)            (None, 64)           0           ['mono_dense_0_convex[0][0]']\n\n mono_dense_1_increasing_convex  (None, 64)          4160        ['dropout_3[0][0]']              \n  (MonoDense)\n\n dropout_4 (Dropout)            (None, 64)           0           ['mono_dense_1_increasing_convex[\n                                                                 0][0]']\n\n mono_dense_2_increasing_convex  (None, 64)          4160        ['dropout_4[0][0]']              \n  (MonoDense)\n\n dropout_5 (Dropout)            (None, 64)           0           ['mono_dense_2_increasing_convex[\n                                                                 0][0]']\n\n mono_dense_3_increasing_convex  (None, 10)          650         ['dropout_5[0][0]']              \n  (MonoDense)\n\n tf.nn.softmax (TFOpLambda)     (None, 10)           0           ['mono_dense_3_increasing_convex[\n                                                                 0][0]']\n\n==================================================================================================\nTotal params: 9,290\nTrainable params: 9,290\nNon-trainable params: 0\n__________________________________________________________________________________________________\n</code></pre>"},{"location":"MonoDenseLayer/#type-2-architecture","title":"Type-2 architecture","text":"<pre><code>monotonicity_indicator = [1, 0, -1]\ninput_units = 2\nmonotonicity_indicator = sum(\n    [[abs(x)] * input_units for x in monotonicity_indicator], []\n)\nmonotonicity_indicator\n</code></pre> <pre><code>[1, 1, 0, 0, 1, 1]\n</code></pre> <pre><code>for dropout in [False, True]:\n    print(\"*\" * 120)\n    print()\n    print(f\"{dropout=}\")\n    print()\n    inputs = {name: Input(name=name, shape=(1,)) for name in list(\"abcd\")}\n    outputs = _create_type_2(\n        inputs,\n        units=32,\n        final_units=10,\n        activation=\"elu\",\n        final_activation=\"softmax\",\n        n_layers=3,\n        dropout=dropout,\n        monotonicity_indicator=dict(a=1, b=0, c=-1, d=0),\n        is_convex=dict(a=True, b=False, c=False, d=False),\n        is_concave=False,\n    )\n    model = Model(inputs=inputs, outputs=outputs)\n    model.summary()\n</code></pre> <pre><code>************************************************************************************************************************\n\ndropout=False\n\nModel: \"model_3\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n a (InputLayer)                 [(None, 1)]          0           []\n\n b (InputLayer)                 [(None, 1)]          0           []\n\n c (InputLayer)                 [(None, 1)]          0           []\n\n d (InputLayer)                 [(None, 1)]          0           []\n\n mono_dense_a_increasing_convex  (None, 8)           16          ['a[0][0]']                      \n  (MonoDense)\n\n dense_b (Dense)                (None, 8)            16          ['b[0][0]']\n\n mono_dense_c_decreasing (MonoD  (None, 8)           16          ['c[0][0]']                      \n ense)\n\n dense_d (Dense)                (None, 8)            16          ['d[0][0]']\n\n preprocessed_features (Concate  (None, 32)          0           ['mono_dense_a_increasing_convex[\n nate)                                                           0][0]',                          \n                                                                  'dense_b[0][0]',                \n                                                                  'mono_dense_c_decreasing[0][0]',\n                                                                  'dense_d[0][0]']\n\n mono_dense_0_convex (MonoDense  (None, 32)          1056        ['preprocessed_features[0][0]']  \n )\n\n mono_dense_1_increasing_convex  (None, 32)          1056        ['mono_dense_0_convex[0][0]']    \n  (MonoDense)\n\n mono_dense_2_increasing_convex  (None, 10)          330         ['mono_dense_1_increasing_convex[\n  (MonoDense)                                                    0][0]']\n\n tf.nn.softmax_1 (TFOpLambda)   (None, 10)           0           ['mono_dense_2_increasing_convex[\n                                                                 0][0]']\n\n==================================================================================================\nTotal params: 2,506\nTrainable params: 2,506\nNon-trainable params: 0\n__________________________________________________________________________________________________\n************************************************************************************************************************\n\ndropout=True\n\nModel: \"model_4\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n a (InputLayer)                 [(None, 1)]          0           []\n\n b (InputLayer)                 [(None, 1)]          0           []\n\n c (InputLayer)                 [(None, 1)]          0           []\n\n d (InputLayer)                 [(None, 1)]          0           []\n\n mono_dense_a_increasing_convex  (None, 8)           16          ['a[0][0]']                      \n  (MonoDense)\n\n dense_b (Dense)                (None, 8)            16          ['b[0][0]']\n\n mono_dense_c_decreasing (MonoD  (None, 8)           16          ['c[0][0]']                      \n ense)\n\n dense_d (Dense)                (None, 8)            16          ['d[0][0]']\n\n preprocessed_features (Concate  (None, 32)          0           ['mono_dense_a_increasing_convex[\n nate)                                                           0][0]',                          \n                                                                  'dense_b[0][0]',                \n                                                                  'mono_dense_c_decreasing[0][0]',\n                                                                  'dense_d[0][0]']\n\n mono_dense_0_convex (MonoDense  (None, 32)          1056        ['preprocessed_features[0][0]']  \n )\n\n dropout_6 (Dropout)            (None, 32)           0           ['mono_dense_0_convex[0][0]']\n\n mono_dense_1_increasing_convex  (None, 32)          1056        ['dropout_6[0][0]']              \n  (MonoDense)\n\n dropout_7 (Dropout)            (None, 32)           0           ['mono_dense_1_increasing_convex[\n                                                                 0][0]']\n\n mono_dense_2_increasing_convex  (None, 10)          330         ['dropout_7[0][0]']              \n  (MonoDense)\n\n tf.nn.softmax_2 (TFOpLambda)   (None, 10)           0           ['mono_dense_2_increasing_convex[\n                                                                 0][0]']\n\n==================================================================================================\nTotal params: 2,506\nTrainable params: 2,506\nNon-trainable params: 0\n__________________________________________________________________________________________________\n</code></pre>"},{"location":"SUMMARY/","title":"SUMMARY","text":"<ul> <li>Introduction</li> <li>In-depth explanation</li> <li>Experiments<ul> <li>Auto MPG</li> <li>Heart disease</li> <li>COMPAS</li> <li>Blog</li> <li>Loan</li> </ul> </li> <li>License</li> <li>API<ul> <li>airt<ul> <li>keras<ul> <li>experiments<ul> <li>create_tuner_stats</li> <li>df2ds</li> <li>find_hyperparameters</li> <li>get_train_n_test_data</li> <li>peek</li> </ul> </li> <li>layers<ul> <li>MonoDense</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li>Releases</li> </ul>"},{"location":"TopLevel/","title":"TopLevel","text":""},{"location":"TopLevel/#dummy","title":"dummy","text":"<pre><code> dummy ()\n</code></pre>"},{"location":"cli_commands_not_found/","title":"No CLI commands found in console_scripts in settings.ini file.","text":"<p>For documenting CLI commands, please add command line executables in <code>console_scripts</code> in <code>settings.ini</code> file. </p> <p>If you do not want this page to be rendered as part of the documentation, please remove the following lines from the mkdocs/summary_template.txt file and build the docs again.</p> <pre><code>- CLI\n{cli}\n</code></pre>"},{"location":"api/airt/keras/experiments/create_tuner_stats/","title":"create_tuner_stats","text":""},{"location":"api/airt/keras/experiments/create_tuner_stats/#airt.keras.experiments.create_tuner_stats","title":"<code>airt.keras.experiments.create_tuner_stats(tuner: Tuner, *, num_models: int = 10, max_epochs: int = 50, batch_size: int = 8, patience: int = 10, verbose: int = 0) -&gt; pd.DataFrame</code>","text":"<p>Calculates statistics for the best models found by Keras Tuner</p> <p>Parameters:</p> Name Type Description Default <code>tuner</code> <code>Tuner</code> <p>an instance of Keras Tuner</p> required <code>num_models</code> <code>int</code> <p>number of best models to use for calculating statistics</p> <code>10</code> <code>max_epochs</code> <code>int</code> <p>maximum number of epochs used in runs</p> <code>50</code> <code>batch_size</code> <code>int</code> <p>batch_size</p> <code>8</code> <code>patience</code> <code>int</code> <p>maximum number of epochs with worse objective before stopping trial early</p> <code>10</code> <code>verbose</code> <code>int</code> <p>verbosity level of <code>Model.fit</code> function</p> <code>0</code> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>A dataframe with statistics</p> Source code in <code>airt/keras/experiments.py</code> <pre><code>def create_tuner_stats(\n    tuner: Tuner,\n    *,\n    num_models: int = 10,\n    max_epochs: int = 50,\n    batch_size: int = 8,\n    patience: int = 10,\n    verbose: int = 0,\n) -&gt; pd.DataFrame:\n\"\"\"Calculates statistics for the best models found by Keras Tuner\n\n    Args:\n        tuner: an instance of Keras Tuner\n        num_models: number of best models to use for calculating statistics\n        max_epochs: maximum number of epochs used in runs\n        batch_size: batch_size\n        patience: maximum number of epochs with worse objective before stopping trial early\n        verbose: verbosity level of `Model.fit` function\n\n    Returns:\n        A dataframe with statistics\n    \"\"\"\n    stats = None\n\n    train_df, test_df = get_train_n_test_data(tuner.project_name)\n    train_ds, test_ds = df2ds(train_df), df2ds(test_df)\n\n    for hp in tuner.get_best_hyperparameters(num_trials=num_models):\n        new_entry = _create_model_stats(\n            tuner,\n            hp,\n            stats=stats,\n            max_epochs=max_epochs,\n            num_runs=10,\n            top_runs=5,\n            batch_size=batch_size,\n            patience=patience,\n            verbose=verbose,\n            train_ds=train_ds,\n            test_ds=test_ds,\n        )\n        if stats is None:\n            stats = new_entry\n        else:\n            stats = pd.concat([stats, new_entry]).reset_index(drop=True)\n\n        try:\n            display(stats.sort_values(f\"{tuner.oracle.objective.name}_mean\"))  # type: ignore\n        # nosemgrep\n        except Exception as e:  # nosec\n            pass\n\n    return stats.sort_values(f\"{tuner.oracle.objective.name}_mean\")  # type: ignore\n</code></pre>"},{"location":"api/airt/keras/experiments/df2ds/","title":"df2ds","text":""},{"location":"api/airt/keras/experiments/df2ds/#airt.keras.experiments.df2ds","title":"<code>airt.keras.experiments.df2ds(df: pd.DataFrame) -&gt; tf.data.Dataset</code>","text":"<p>Converts DataFrame to Dataset</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>pd.DataFrame</code> <p>input DataFrame</p> required <p>Returns:</p> Type Description <code>tf.data.Dataset</code> <p>dataset</p> Source code in <code>airt/keras/experiments.py</code> <pre><code>def df2ds(df: pd.DataFrame) -&gt; tf.data.Dataset:\n\"\"\"Converts DataFrame to Dataset\n\n    Args:\n        df: input DataFrame\n\n    Returns:\n        dataset\n    \"\"\"\n    x = df.to_dict(\"list\")\n    y = x.pop(\"ground_truth\")\n\n    ds = tf.data.Dataset.from_tensor_slices((x, y))\n\n    return ds\n</code></pre>"},{"location":"api/airt/keras/experiments/find_hyperparameters/","title":"find_hyperparameters","text":""},{"location":"api/airt/keras/experiments/find_hyperparameters/#airt.keras.experiments.find_hyperparameters","title":"<code>airt.keras.experiments.find_hyperparameters(dataset_name: str, *, monotonicity_indicator: Dict[str, int], final_activation: Union[str, Callable[[TensorLike, TensorLike], TensorLike]], loss: Union[str, Callable[[TensorLike, TensorLike], TensorLike]], metrics: Union[str, Callable[[TensorLike, TensorLike], TensorLike]], hp_params_f: Optional[Callable[[HyperParameters], Dict[str, Any]]] = None, max_trials: int = 100, max_epochs: int = 50, batch_size: int = 8, objective: Union[str, Objective], direction: str, dir_root: Union[Path, str] = 'tuner', seed: int = 42, executions_per_trial: int = 3, max_consecutive_failed_trials: int = 5, patience: int = 10) -&gt; Tuner</code>","text":"<p>Search for optimal hyperparameters</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>name of the dataset, one of \"auto\", \"heart\", compas\", \"blog\", \"loan\"</p> required <code>monotonicity_indicator</code> <code>Dict[str, int]</code> <p>monotonicity indicator as used in <code>MonoDense.__init__</code></p> required <code>final_activation</code> <code>Union[str, Callable[[TensorLike, TensorLike], TensorLike]]</code> <p>final activation of the neural network</p> required <code>loss</code> <code>Union[str, Callable[[TensorLike, TensorLike], TensorLike]]</code> <p>Tensorflow loss function</p> required <code>metrics</code> <code>Union[str, Callable[[TensorLike, TensorLike], TensorLike]]</code> <p>Tensorflow metrics function</p> required <code>hp_params_f</code> <code>Optional[Callable[[HyperParameters], Dict[str, Any]]]</code> <p>a function constructing sampling hyperparameters using Keras Tuner</p> <code>None</code> <code>max_trials</code> <code>int</code> <p>maximum number of trials</p> <code>100</code> <code>max_epochs</code> <code>int</code> <p>maximum number of epochs in each trial</p> <code>50</code> <code>batch_size</code> <code>int</code> <p>batch size</p> <code>8</code> <code>objective</code> <code>Union[str, Objective]</code> <p>objective, typically f\"val_{metrics}\"</p> required <code>direction</code> <code>str</code> <p>direction of the objective, either \"min\" or \"max\"</p> required <code>dir_root</code> <code>Union[Path, str]</code> <p>root directory for storing Keras Tuner data</p> <code>'tuner'</code> <code>seed</code> <code>int</code> <p>random seed used to guarantee reproducibility of results</p> <code>42</code> <code>executions_per_trial</code> <code>int</code> <p>number of executions per trial. Set it to number higher than zero for small datasets</p> <code>3</code> <code>max_consecutive_failed_trials</code> <code>int</code> <p>maximum number of failed trials as used in Keras Tuner</p> <code>5</code> <code>patience</code> <code>int</code> <p>number of epoch with worse objective before stopping trial early</p> <code>10</code> <p>Returns:</p> Type Description <code>Tuner</code> <p>An instance of Keras Tuner</p> Source code in <code>airt/keras/experiments.py</code> <pre><code>def find_hyperparameters(\n    dataset_name: str,\n    *,\n    monotonicity_indicator: Dict[str, int],\n    final_activation: Union[str, Callable[[TensorLike, TensorLike], TensorLike]],\n    loss: Union[str, Callable[[TensorLike, TensorLike], TensorLike]],\n    metrics: Union[str, Callable[[TensorLike, TensorLike], TensorLike]],\n    hp_params_f: Optional[Callable[[HyperParameters], Dict[str, Any]]] = None,\n    max_trials: int = 100,\n    max_epochs: int = 50,\n    batch_size: int = 8,\n    objective: Union[str, Objective],\n    direction: str,\n    dir_root: Union[Path, str] = \"tuner\",\n    seed: int = 42,\n    executions_per_trial: int = 3,\n    max_consecutive_failed_trials: int = 5,\n    patience: int = 10,\n) -&gt; Tuner:\n\"\"\"Search for optimal hyperparameters\n\n    Args:\n        dataset_name: name of the dataset, one of \"auto\", \"heart\", compas\", \"blog\", \"loan\"\n        monotonicity_indicator: monotonicity indicator as used in `MonoDense.__init__`\n        final_activation:  final activation of the neural network\n        loss: Tensorflow loss function\n        metrics: Tensorflow metrics function\n        hp_params_f: a function constructing sampling hyperparameters using Keras Tuner\n        max_trials: maximum number of trials\n        max_epochs: maximum number of epochs in each trial\n        batch_size: batch size\n        objective: objective, typically f\"val_{metrics}\"\n        direction: direction of the objective, either \"min\" or \"max\"\n        dir_root: root directory for storing Keras Tuner data\n        seed: random seed used to guarantee reproducibility of results\n        executions_per_trial: number of executions per trial. Set it to number higher than zero for small datasets\n        max_consecutive_failed_trials: maximum number of failed trials as used in Keras Tuner\n        patience: number of epoch with worse objective before stopping trial early\n\n    Returns:\n        An instance of Keras Tuner\n\n    \"\"\"\n    tf.keras.utils.set_random_seed(seed)\n\n    train_df, test_df = get_train_n_test_data(dataset_name)\n    train_ds, test_ds = df2ds(train_df), df2ds(test_df)\n\n    oracle = _TestHyperModel(\n        monotonicity_indicator=monotonicity_indicator,\n        hp_params_f=hp_params_f,\n        final_activation=final_activation,\n        loss=loss,\n        metrics=metrics,\n        train_ds=train_ds,\n        batch_size=batch_size,\n    )\n\n    tuner = BayesianOptimization(\n        oracle,\n        objective=Objective(objective, direction),\n        max_trials=max_trials,\n        seed=seed,\n        directory=Path(dir_root),\n        project_name=dataset_name,\n        executions_per_trial=executions_per_trial,\n        max_consecutive_failed_trials=max_consecutive_failed_trials,\n    )\n\n    stop_early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=patience)\n\n    tuner.search(\n        train_ds.shuffle(len(train_ds)).batch(batch_size).prefetch(2),\n        validation_data=test_ds.batch(256),\n        callbacks=[stop_early],\n        epochs=max_epochs,\n    )\n\n    return tuner\n</code></pre>"},{"location":"api/airt/keras/experiments/get_train_n_test_data/","title":"get_train_n_test_data","text":""},{"location":"api/airt/keras/experiments/get_train_n_test_data/#airt.keras.experiments.get_train_n_test_data","title":"<code>airt.keras.experiments.get_train_n_test_data(dataset_name: str, *, data_path: Optional[Union[Path, str]] = './data') -&gt; Tuple[pd.DataFrame, pd.DataFrame]</code>","text":"<p>Download data</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>name of the dataset, one of \"auto\", \"heart\", compas\", \"blog\", \"loan\"</p> required <code>data_path</code> <code>Optional[Union[Path, str]]</code> <p>root directory where to download data to</p> <code>'./data'</code> Source code in <code>airt/keras/experiments.py</code> <pre><code>def get_train_n_test_data(\n    dataset_name: str,\n    *,\n    data_path: Optional[Union[Path, str]] = \"./data\",\n) -&gt; Tuple[pd.DataFrame, pd.DataFrame]:\n\"\"\"Download data\n\n    Args:\n        dataset_name: name of the dataset, one of \"auto\", \"heart\", compas\", \"blog\", \"loan\"\n        data_path: root directory where to download data to\n    \"\"\"\n    data_path = _get_data_path(data_path)\n    _download_data(dataset_name=dataset_name, data_path=data_path)\n\n    dfx = [\n        pd.read_csv(data_path / f\"{prefix}_{dataset_name}.csv\")\n        for prefix in [\"train\", \"test\"]\n    ]\n    dfx = [_sanitize_col_names(df) for df in dfx]\n    return dfx[0], dfx[1]\n</code></pre>"},{"location":"api/airt/keras/experiments/peek/","title":"peek","text":""},{"location":"api/airt/keras/experiments/peek/#airt.keras.experiments.peek","title":"<code>airt.keras.experiments.peek(ds: tf.data.Dataset) -&gt; tf.Tensor</code>","text":"<p>Returns the first element of the dataset</p> <p>Parameters:</p> Name Type Description Default <code>ds</code> <code>tf.data.Dataset</code> <p>dataset</p> required <p>Returns:</p> Type Description <code>tf.Tensor</code> <p>the first element of the dataset</p> Source code in <code>airt/keras/experiments.py</code> <pre><code>def peek(ds: tf.data.Dataset) -&gt; tf.Tensor:\n\"\"\"Returns the first element of the dataset\n\n    Args:\n        ds: dataset\n\n    Returns:\n        the first element of the dataset\n    \"\"\"\n    for x in ds:\n        return x\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/","title":"MonoDense","text":""},{"location":"api/airt/keras/layers/MonoDense/#airt.keras.layers.MonoDense","title":"<code>airt.keras.layers.MonoDense</code>","text":"<p>         Bases: <code>Dense</code></p> <p>Monotonic counterpart of the regular Dense Layer of tf.keras</p> <p>This is an implementation of our Monotonic Dense Unit or Constrained Monotone Fully Connected Layer. The below is the figure from the paper for reference.</p> <ul> <li> <p>the parameter <code>monotonicity_indicator</code> corresponds to t in the figure below, and</p> </li> <li> <p>parameters <code>is_convex</code>, <code>is_concave</code> and <code>activation_weights</code> are used to calculate the activation selector s as follows:</p> <ul> <li> <p>if <code>is_convex</code> or <code>is_concave</code> is True, then the activation selector s will be (<code>units</code>, 0, 0) and (0, <code>units</code>, 0), respecively.</p> </li> <li> <p>if both  <code>is_convex</code> or <code>is_concave</code> is False, then the <code>activation_weights</code> represent ratios between \\(\\breve{s}\\), \\(\\hat{s}\\) and \\(\\tilde{s}\\),   respecively. E.g. if <code>activation_weights = (2, 2, 1)</code> and <code>units = 10</code>, then</p> </li> </ul> </li> </ul> \\[ (\\breve{s}, \\hat{s}, \\tilde{s}) = (4, 4, 2) \\] <p></p> Source code in <code>airt/_components/mono_dense_layer.py</code> <pre><code>@export\nclass MonoDense(Dense):\n\"\"\"Monotonic counterpart of the regular Dense Layer of tf.keras\n\n    This is an implementation of our Monotonic Dense Unit or Constrained Monotone Fully Connected Layer. The below is the figure from the paper for reference.\n\n    - the parameter `monotonicity_indicator` corresponds to **t** in the figure below, and\n\n    - parameters `is_convex`, `is_concave` and `activation_weights` are used to calculate the activation selector **s** as follows:\n\n        - if `is_convex` or `is_concave` is **True**, then the activation selector **s** will be (`units`, 0, 0) and (0, `units`, 0), respecively.\n\n        - if both  `is_convex` or `is_concave` is **False**, then the `activation_weights` represent ratios between $\\\\breve{s}$, $\\\\hat{s}$ and $\\\\tilde{s}$,\n          respecively. E.g. if `activation_weights = (2, 2, 1)` and `units = 10`, then\n\n    $$\n    (\\\\breve{s}, \\\\hat{s}, \\\\tilde{s}) = (4, 4, 2)\n    $$\n\n    ![mono-dense-layer-diagram.png](../../../../../images/nbs/images/mono-dense-layer-diagram.png)\n\n    \"\"\"\n\n    def __init__(\n        self,\n        units: int,\n        *,\n        activation: Optional[Union[str, Callable[[TensorLike], TensorLike]]] = None,\n        monotonicity_indicator: ArrayLike = 1,\n        is_convex: bool = False,\n        is_concave: bool = False,\n        activation_weights: Tuple[float, float, float] = (7.0, 7.0, 2.0),\n        **kwargs: Any,\n    ):\n\"\"\"Constructs a new MonoDense instance.\n\n        Params:\n            units: Positive integer, dimensionality of the output space.\n            activation: Activation function to use, it is assumed to be convex monotonically\n                increasing function such as \"relu\" or \"elu\"\n            monotonicity_indicator: Vector to indicate which of the inputs are monotonically increasing or\n                monotonically decreasing or non-monotonic. Has value 1 for monotonically increasing,\n                -1 for monotonically decreasing and 0 for non-monotonic.\n            is_convex: convex if set to True\n            is_concave: concave if set to True\n            activation_weights: relative weights for each type of activation, the default is (1.0, 1.0, 1.0).\n                Ignored if is_convex or is_concave is set to True\n            **kwargs: passed as kwargs to the constructor of `Dense`\n\n        Raise:\n            ValueError:\n                - if both **is_concave** and **is_convex** are set to **True**, or\n                - if any component of activation_weights is negative or there is not exactly three components\n        \"\"\"\n        if is_convex and is_concave:\n            raise ValueError(\n                \"The model cannot be set to be both convex and concave (only linear functions are both).\"\n            )\n\n        if len(activation_weights) != 3:\n            raise ValueError(\n                f\"There must be exactly three components of activation_weights, but we have this instead: {activation_weights}.\"\n            )\n\n        if (np.array(activation_weights) &lt; 0).any():\n            raise ValueError(\n                f\"Values of activation_weights must be non-negative, but we have this instead: {activation_weights}.\"\n            )\n\n        super(MonoDense, self).__init__(units=units, activation=None, **kwargs)\n\n        self.units = units\n        self.org_activation = activation\n        self.monotonicity_indicator = monotonicity_indicator\n        self.is_convex = is_convex\n        self.is_concave = is_concave\n        self.activation_weights = activation_weights\n\n        (\n            self.convex_activation,\n            self.concave_activation,\n            self.saturated_activation,\n        ) = get_activation_functions(self.org_activation)\n\n    def get_config(self) -&gt; Dict[str, Any]:\n\"\"\"Get config is used for saving the model\"\"\"\n        return dict(\n            units=self.units,\n            activation=self.org_activation,\n            monotonicity_indicator=self.monotonicity_indicator,\n            is_convex=self.is_convex,\n            is_concave=self.is_concave,\n            activation_weights=self.activation_weights,\n        )\n\n    def build(self, input_shape: Tuple, *args: List[Any], **kwargs: Any) -&gt; None:\n\"\"\"Build\n\n        Args:\n            input_shape: input tensor\n            args: positional arguments passed to Dense.build()\n            kwargs: keyword arguments passed to Dense.build()\n        \"\"\"\n        super(MonoDense, self).build(input_shape, *args, **kwargs)\n        self.monotonicity_indicator = get_monotonicity_indicator(\n            monotonicity_indicator=self.monotonicity_indicator,\n            input_shape=input_shape,\n            units=self.units,\n        )\n\n    def call(self, inputs: TensorLike) -&gt; TensorLike:\n\"\"\"Call\n\n        Args:\n            inputs: input tensor of shape (batch_size, ..., x_length)\n\n        Returns:\n            N-D tensor with shape: `(batch_size, ..., units)`.\n\n        \"\"\"\n        # calculate W'*x+y after we replace the kernal according to monotonicity vector\n        with replace_kernel_using_monotonicity_indicator(\n            self, monotonicity_indicator=self.monotonicity_indicator\n        ):\n            h = super(MonoDense, self).call(inputs)\n\n        y = apply_activations(\n            h,\n            units=self.units,\n            convex_activation=self.convex_activation,\n            concave_activation=self.concave_activation,\n            saturated_activation=self.saturated_activation,\n            is_convex=self.is_convex,\n            is_concave=self.is_concave,\n            activation_weights=self.activation_weights,\n        )\n\n        return y\n\n    @classmethod\n    def create_type_1(\n        cls,\n        inputs: Union[TensorLike, Dict[str, TensorLike], List[TensorLike]],\n        *,\n        units: int,\n        final_units: int,\n        activation: Union[str, Callable[[TensorLike], TensorLike]],\n        n_layers: int,\n        final_activation: Optional[\n            Union[str, Callable[[TensorLike], TensorLike]]\n        ] = None,\n        monotonicity_indicator: Union[int, Dict[str, int], List[int]] = 1,\n        is_convex: Union[bool, Dict[str, bool], List[bool]] = False,\n        is_concave: Union[bool, Dict[str, bool], List[bool]] = False,\n        dropout: Optional[float] = None,\n    ) -&gt; TensorLike:\n\"\"\"Builds Type-1 monotonic network\n\n        Type-1 architecture corresponds to the standard MLP type of neural network architecture used in general, where each\n        of the input features is concatenated to form one single input feature vector $\\mathbf{x}$ and fed into the network,\n        with the only difference being that instead of standard fully connected or dense layers, we employ monotonic dense units\n        throughout. For the first (or input layer) layer, the indicator vector $\\mathbf{t}$, is used to identify the monotonicity\n        property of the input feature with respect to the output. Specifically, $\\mathbf{t}$ is set to $1$ for those components\n        in the input feature vector that are monotonically increasing and is set to $-1$ for those components that are monotonically\n        decreasing and set to $0$ if the feature is non-monotonic. For the subsequent hidden layers, monotonic dense units with the\n        indicator vector $\\mathbf{t}$ always being set to $1$ are used in order to preserve monotonicity. Finally, depending on\n        whether the problem at hand is a regression problem or a classification problem (or even a multi-task problem), an appropriate\n        activation function (such as linear activation or sigmoid or softmax) to obtain the final output.\n\n        ![mono-dense-layer-diagram.png](../../../images/nbs/images/type-1.png)\n\n        Args:\n            inputs: input tensor or a dictionary of tensors\n            units: number of units in hidden layers\n            final_units: number of units in the output layer\n            activation: the base activation function\n            n_layers: total number of layers (hidden layers plus the output layer)\n            final_activation: the activation function of the final layer (typicall softmax, sigmoid or linear).\n                If set to None (default value), then the linear activation is used.\n            monotonicity_indicator: if an instance of dictionary, then maps names of input feature to their monotonicity\n                indicator (-1 for monotonically decreasing, 1 for monotonically increasing and 0 otherwise). If int,\n                then all input features are set to the same monotinicity indicator.\n            is_convex: set to True if a particular input feature is convex\n            is_concave: set to True if a particular inputs feature is concave\n            dropout: dropout rate. If set to float greater than 0, Dropout layers are inserted after hidden layers.\n\n        Returns:\n            Output tensor\n\n        \"\"\"\n        return _create_type_1(\n            inputs,\n            units=units,\n            final_units=final_units,\n            activation=activation,\n            n_layers=n_layers,\n            final_activation=final_activation,\n            monotonicity_indicator=monotonicity_indicator,\n            is_convex=is_convex,\n            is_concave=is_concave,\n            dropout=dropout,\n        )\n\n    @classmethod\n    def create_type_2(\n        cls,\n        inputs: Union[TensorLike, Dict[str, TensorLike], List[TensorLike]],\n        *,\n        input_units: Optional[int] = None,\n        units: int,\n        final_units: int,\n        activation: Union[str, Callable[[TensorLike], TensorLike]],\n        n_layers: int,\n        final_activation: Optional[\n            Union[str, Callable[[TensorLike], TensorLike]]\n        ] = None,\n        monotonicity_indicator: Union[int, Dict[str, int], List[int]] = 1,\n        is_convex: Union[bool, Dict[str, bool], List[bool]] = False,\n        is_concave: Union[bool, Dict[str, bool], List[bool]] = False,\n        dropout: Optional[float] = None,\n    ) -&gt; TensorLike:\n\"\"\"Builds Type-2 monotonic network\n\n        Type-2 architecture is another example of a neural network architecture that can be built employing proposed\n        monotonic dense blocks. The difference when compared to the architecture described above lies in the way input\n        features are fed into the hidden layers of neural network architecture. Instead of concatenating the features\n        directly, this architecture provides flexibility to employ any form of complex feature extractors for the\n        non-monotonic features and use the extracted feature vectors as inputs. Another difference is that each monotonic\n        input is passed through separate monotonic dense units. This provides an advantage since depending on whether the\n        input is completely concave or convex or both, we can adjust the activation selection vector $\\mathbf{s}$ appropriately\n        along with an appropriate value for the indicator vector $\\mathbf{t}$. Thus, each of the monotonic input features has\n        a separate monotonic dense layer associated with it. Thus as the major difference to the above-mentioned architecture,\n        we concatenate the feature vectors instead of concatenating the inputs directly. The subsequent parts of the network are\n        similar to the architecture described above wherein for the rest of the hidden monotonic dense units, the indicator vector\n        $\\mathbf{t}$ is always set to $1$ to preserve monotonicity.\n\n        ![mono-dense-layer-diagram.png](../../../images/nbs/images/type-2.png)\n\n        Args:\n            inputs: input tensor or a dictionary of tensors\n            input_units: used to preprocess features before entering the common mono block\n            units: number of units in hidden layers\n            final_units: number of units in the output layer\n            activation: the base activation function\n            n_layers: total number of layers (hidden layers plus the output layer)\n            final_activation: the activation function of the final layer (typicall softmax, sigmoid or linear).\n                If set to None (default value), then the linear activation is used.\n            monotonicity_indicator: if an instance of dictionary, then maps names of input feature to their monotonicity\n                indicator (-1 for monotonically decreasing, 1 for monotonically increasing and 0 otherwise). If int,\n                then all input features are set to the same monotinicity indicator.\n            is_convex: set to True if a particular input feature is convex\n            is_concave: set to True if a particular inputs feature is concave\n            dropout: dropout rate. If set to float greater than 0, Dropout layers are inserted after hidden layers.\n\n        Returns:\n            Output tensor\n\n        \"\"\"\n        return _create_type_2(\n            inputs,\n            input_units=input_units,\n            units=units,\n            final_units=final_units,\n            activation=activation,\n            n_layers=n_layers,\n            final_activation=final_activation,\n            monotonicity_indicator=monotonicity_indicator,\n            is_convex=is_convex,\n            is_concave=is_concave,\n            dropout=dropout,\n        )\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#airt.keras.layers.MonoDense-attributes","title":"Attributes","text":""},{"location":"api/airt/keras/layers/MonoDense/#airt._components.mono_dense_layer.MonoDense.activation_weights","title":"<code>activation_weights = activation_weights</code>  <code>instance-attribute</code>","text":""},{"location":"api/airt/keras/layers/MonoDense/#airt._components.mono_dense_layer.MonoDense.is_concave","title":"<code>is_concave = is_concave</code>  <code>instance-attribute</code>","text":""},{"location":"api/airt/keras/layers/MonoDense/#airt._components.mono_dense_layer.MonoDense.is_convex","title":"<code>is_convex = is_convex</code>  <code>instance-attribute</code>","text":""},{"location":"api/airt/keras/layers/MonoDense/#airt._components.mono_dense_layer.MonoDense.monotonicity_indicator","title":"<code>monotonicity_indicator = monotonicity_indicator</code>  <code>instance-attribute</code>","text":""},{"location":"api/airt/keras/layers/MonoDense/#airt._components.mono_dense_layer.MonoDense.org_activation","title":"<code>org_activation = activation</code>  <code>instance-attribute</code>","text":""},{"location":"api/airt/keras/layers/MonoDense/#airt._components.mono_dense_layer.MonoDense.units","title":"<code>units = units</code>  <code>instance-attribute</code>","text":""},{"location":"api/airt/keras/layers/MonoDense/#airt.keras.layers.MonoDense-functions","title":"Functions","text":""},{"location":"api/airt/keras/layers/MonoDense/#airt._components.mono_dense_layer.MonoDense.__init__","title":"<code>__init__(units: int, *, activation: Optional[Union[str, Callable[[TensorLike], TensorLike]]] = None, monotonicity_indicator: ArrayLike = 1, is_convex: bool = False, is_concave: bool = False, activation_weights: Tuple[float, float, float] = (7.0, 7.0, 2.0), **kwargs: Any)</code>","text":"<p>Constructs a new MonoDense instance.</p> <p>Parameters:</p> Name Type Description Default <code>units</code> <code>int</code> <p>Positive integer, dimensionality of the output space.</p> required <code>activation</code> <code>Optional[Union[str, Callable[[TensorLike], TensorLike]]]</code> <p>Activation function to use, it is assumed to be convex monotonically increasing function such as \"relu\" or \"elu\"</p> <code>None</code> <code>monotonicity_indicator</code> <code>ArrayLike</code> <p>Vector to indicate which of the inputs are monotonically increasing or monotonically decreasing or non-monotonic. Has value 1 for monotonically increasing, -1 for monotonically decreasing and 0 for non-monotonic.</p> <code>1</code> <code>is_convex</code> <code>bool</code> <p>convex if set to True</p> <code>False</code> <code>is_concave</code> <code>bool</code> <p>concave if set to True</p> <code>False</code> <code>activation_weights</code> <code>Tuple[float, float, float]</code> <p>relative weights for each type of activation, the default is (1.0, 1.0, 1.0). Ignored if is_convex or is_concave is set to True</p> <code>(7.0, 7.0, 2.0)</code> <code>**kwargs</code> <code>Any</code> <p>passed as kwargs to the constructor of <code>Dense</code></p> <code>{}</code> Raise <p>ValueError:     - if both is_concave and is_convex are set to True, or     - if any component of activation_weights is negative or there is not exactly three components</p> Source code in <code>airt/_components/mono_dense_layer.py</code> <pre><code>def __init__(\n    self,\n    units: int,\n    *,\n    activation: Optional[Union[str, Callable[[TensorLike], TensorLike]]] = None,\n    monotonicity_indicator: ArrayLike = 1,\n    is_convex: bool = False,\n    is_concave: bool = False,\n    activation_weights: Tuple[float, float, float] = (7.0, 7.0, 2.0),\n    **kwargs: Any,\n):\n\"\"\"Constructs a new MonoDense instance.\n\n    Params:\n        units: Positive integer, dimensionality of the output space.\n        activation: Activation function to use, it is assumed to be convex monotonically\n            increasing function such as \"relu\" or \"elu\"\n        monotonicity_indicator: Vector to indicate which of the inputs are monotonically increasing or\n            monotonically decreasing or non-monotonic. Has value 1 for monotonically increasing,\n            -1 for monotonically decreasing and 0 for non-monotonic.\n        is_convex: convex if set to True\n        is_concave: concave if set to True\n        activation_weights: relative weights for each type of activation, the default is (1.0, 1.0, 1.0).\n            Ignored if is_convex or is_concave is set to True\n        **kwargs: passed as kwargs to the constructor of `Dense`\n\n    Raise:\n        ValueError:\n            - if both **is_concave** and **is_convex** are set to **True**, or\n            - if any component of activation_weights is negative or there is not exactly three components\n    \"\"\"\n    if is_convex and is_concave:\n        raise ValueError(\n            \"The model cannot be set to be both convex and concave (only linear functions are both).\"\n        )\n\n    if len(activation_weights) != 3:\n        raise ValueError(\n            f\"There must be exactly three components of activation_weights, but we have this instead: {activation_weights}.\"\n        )\n\n    if (np.array(activation_weights) &lt; 0).any():\n        raise ValueError(\n            f\"Values of activation_weights must be non-negative, but we have this instead: {activation_weights}.\"\n        )\n\n    super(MonoDense, self).__init__(units=units, activation=None, **kwargs)\n\n    self.units = units\n    self.org_activation = activation\n    self.monotonicity_indicator = monotonicity_indicator\n    self.is_convex = is_convex\n    self.is_concave = is_concave\n    self.activation_weights = activation_weights\n\n    (\n        self.convex_activation,\n        self.concave_activation,\n        self.saturated_activation,\n    ) = get_activation_functions(self.org_activation)\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#keras.engine.base_layer.Layer.add_loss","title":"<code>add_loss(losses, **kwargs)</code>","text":"<p>Add loss tensor(s), potentially dependent on layer inputs.</p> <p>Some losses (for instance, activity regularization losses) may be dependent on the inputs passed when calling a layer. Hence, when reusing the same layer on different inputs <code>a</code> and <code>b</code>, some entries in <code>layer.losses</code> may be dependent on <code>a</code> and some on <code>b</code>. This method automatically keeps track of dependencies.</p> <p>This method can be used inside a subclassed layer or model's <code>call</code> function, in which case <code>losses</code> should be a Tensor or list of Tensors.</p> <p>Example:</p> <pre><code>class MyLayer(tf.keras.layers.Layer):\n  def call(self, inputs):\n    self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n    return inputs\n</code></pre> <p>The same code works in distributed training: the input to <code>add_loss()</code> is treated like a regularization loss and averaged across replicas by the training loop (both built-in <code>Model.fit()</code> and compliant custom training loops).</p> <p>The <code>add_loss</code> method can also be called directly on a Functional Model during construction. In this case, any loss Tensors passed to this Model must be symbolic and be able to be traced back to the model's <code>Input</code>s. These losses become part of the model's topology and are tracked in <code>get_config</code>.</p> <p>Example:</p> <pre><code>inputs = tf.keras.Input(shape=(10,))\nx = tf.keras.layers.Dense(10)(inputs)\noutputs = tf.keras.layers.Dense(1)(x)\nmodel = tf.keras.Model(inputs, outputs)\n# Activity regularization.\nmodel.add_loss(tf.abs(tf.reduce_mean(x)))\n</code></pre> <p>If this is not the case for your loss (if, for example, your loss references a <code>Variable</code> of one of the model's layers), you can wrap your loss in a zero-argument lambda. These losses are not tracked as part of the model's topology since they can't be serialized.</p> <p>Example:</p> <pre><code>inputs = tf.keras.Input(shape=(10,))\nd = tf.keras.layers.Dense(10)\nx = d(inputs)\noutputs = tf.keras.layers.Dense(1)(x)\nmodel = tf.keras.Model(inputs, outputs)\n# Weight regularization.\nmodel.add_loss(lambda: tf.reduce_mean(d.kernel))\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>losses</code> <p>Loss tensor, or list/tuple of tensors. Rather than tensors, losses may also be zero-argument callables which create a loss tensor.</p> required <code>**kwargs</code> <p>Used for backwards compatibility only.</p> <code>{}</code> Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code> <pre><code>def add_loss(self, losses, **kwargs):\n\"\"\"Add loss tensor(s), potentially dependent on layer inputs.\n\n    Some losses (for instance, activity regularization losses) may be\n    dependent on the inputs passed when calling a layer. Hence, when reusing\n    the same layer on different inputs `a` and `b`, some entries in\n    `layer.losses` may be dependent on `a` and some on `b`. This method\n    automatically keeps track of dependencies.\n\n    This method can be used inside a subclassed layer or model's `call`\n    function, in which case `losses` should be a Tensor or list of Tensors.\n\n    Example:\n\n    ```python\n    class MyLayer(tf.keras.layers.Layer):\n      def call(self, inputs):\n        self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n        return inputs\n    ```\n\n    The same code works in distributed training: the input to `add_loss()`\n    is treated like a regularization loss and averaged across replicas\n    by the training loop (both built-in `Model.fit()` and compliant custom\n    training loops).\n\n    The `add_loss` method can also be called directly on a Functional Model\n    during construction. In this case, any loss Tensors passed to this Model\n    must be symbolic and be able to be traced back to the model's `Input`s.\n    These losses become part of the model's topology and are tracked in\n    `get_config`.\n\n    Example:\n\n    ```python\n    inputs = tf.keras.Input(shape=(10,))\n    x = tf.keras.layers.Dense(10)(inputs)\n    outputs = tf.keras.layers.Dense(1)(x)\n    model = tf.keras.Model(inputs, outputs)\n    # Activity regularization.\n    model.add_loss(tf.abs(tf.reduce_mean(x)))\n    ```\n\n    If this is not the case for your loss (if, for example, your loss\n    references a `Variable` of one of the model's layers), you can wrap your\n    loss in a zero-argument lambda. These losses are not tracked as part of\n    the model's topology since they can't be serialized.\n\n    Example:\n\n    ```python\n    inputs = tf.keras.Input(shape=(10,))\n    d = tf.keras.layers.Dense(10)\n    x = d(inputs)\n    outputs = tf.keras.layers.Dense(1)(x)\n    model = tf.keras.Model(inputs, outputs)\n    # Weight regularization.\n    model.add_loss(lambda: tf.reduce_mean(d.kernel))\n    ```\n\n    Args:\n      losses: Loss tensor, or list/tuple of tensors. Rather than tensors,\n        losses may also be zero-argument callables which create a loss\n        tensor.\n      **kwargs: Used for backwards compatibility only.\n    \"\"\"\n    kwargs.pop(\"inputs\", None)\n    if kwargs:\n        raise TypeError(f\"Unknown keyword arguments: {kwargs.keys()}\")\n\n    def _tag_callable(loss):\n\"\"\"Tags callable loss tensor as `_unconditional_loss`.\"\"\"\n        if callable(loss):\n            # We run the loss without autocasting, as regularizers are often\n            # numerically unstable in float16.\n            with autocast_variable.enable_auto_cast_variables(None):\n                loss = loss()\n        if loss is None:\n            # Will be filtered out when computing the .losses property\n            return None\n        if not tf.is_tensor(loss):\n            loss = tf.convert_to_tensor(loss, dtype=backend.floatx())\n        loss._unconditional_loss = True\n        return loss\n\n    losses = tf.nest.flatten(losses)\n\n    callable_losses = []\n    eager_losses = []\n    symbolic_losses = []\n    for loss in losses:\n        if callable(loss):\n            callable_losses.append(functools.partial(_tag_callable, loss))\n            continue\n        if loss is None:\n            continue\n        if not tf.is_tensor(loss) and not isinstance(\n            loss, keras_tensor.KerasTensor\n        ):\n            loss = tf.convert_to_tensor(loss, dtype=backend.floatx())\n        # TF Functions should take the eager path.\n        if (\n            tf_utils.is_symbolic_tensor(loss)\n            or isinstance(loss, keras_tensor.KerasTensor)\n        ) and not base_layer_utils.is_in_tf_function():\n            symbolic_losses.append(loss)\n        elif tf.is_tensor(loss):\n            eager_losses.append(loss)\n\n    self._callable_losses.extend(callable_losses)\n\n    in_call_context = base_layer_utils.call_context().in_call\n    if eager_losses and not in_call_context:\n        raise ValueError(\n            \"Expected a symbolic Tensors or a callable for the loss value. \"\n            \"Please wrap your loss computation in a zero argument `lambda`.\"\n        )\n\n    self._eager_losses.extend(eager_losses)\n\n    for symbolic_loss in symbolic_losses:\n        if getattr(self, \"_is_graph_network\", False):\n            self._graph_network_add_loss(symbolic_loss)\n        else:\n            # Possible a loss was added in a Layer's `build`.\n            self._losses.append(symbolic_loss)\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#keras.engine.base_layer.Layer.add_metric","title":"<code>add_metric(value, name = None, **kwargs)</code>","text":"<p>Adds metric tensor to the layer.</p> <p>This method can be used inside the <code>call()</code> method of a subclassed layer or model.</p> <pre><code>class MyMetricLayer(tf.keras.layers.Layer):\n  def __init__(self):\n    super(MyMetricLayer, self).__init__(name='my_metric_layer')\n    self.mean = tf.keras.metrics.Mean(name='metric_1')\n\n  def call(self, inputs):\n    self.add_metric(self.mean(inputs))\n    self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n    return inputs\n</code></pre> <p>This method can also be called directly on a Functional Model during construction. In this case, any tensor passed to this Model must be symbolic and be able to be traced back to the model's <code>Input</code>s. These metrics become part of the model's topology and are tracked when you save the model via <code>save()</code>.</p> <pre><code>inputs = tf.keras.Input(shape=(10,))\nx = tf.keras.layers.Dense(10)(inputs)\noutputs = tf.keras.layers.Dense(1)(x)\nmodel = tf.keras.Model(inputs, outputs)\nmodel.add_metric(math_ops.reduce_sum(x), name='metric_1')\n</code></pre> <p>Note: Calling <code>add_metric()</code> with the result of a metric object on a Functional Model, as shown in the example below, is not supported. This is because we cannot trace the metric result tensor back to the model's inputs.</p> <pre><code>inputs = tf.keras.Input(shape=(10,))\nx = tf.keras.layers.Dense(10)(inputs)\noutputs = tf.keras.layers.Dense(1)(x)\nmodel = tf.keras.Model(inputs, outputs)\nmodel.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>value</code> <p>Metric tensor.</p> required <code>name</code> <p>String metric name.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments for backward compatibility. Accepted values: <code>aggregation</code> - When the <code>value</code> tensor provided is not the result of calling a <code>keras.Metric</code> instance, it will be aggregated by default using a <code>keras.Metric.Mean</code>.</p> <code>{}</code> Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code> <pre><code>def add_metric(self, value, name=None, **kwargs):\n\"\"\"Adds metric tensor to the layer.\n\n    This method can be used inside the `call()` method of a subclassed layer\n    or model.\n\n    ```python\n    class MyMetricLayer(tf.keras.layers.Layer):\n      def __init__(self):\n        super(MyMetricLayer, self).__init__(name='my_metric_layer')\n        self.mean = tf.keras.metrics.Mean(name='metric_1')\n\n      def call(self, inputs):\n        self.add_metric(self.mean(inputs))\n        self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n        return inputs\n    ```\n\n    This method can also be called directly on a Functional Model during\n    construction. In this case, any tensor passed to this Model must\n    be symbolic and be able to be traced back to the model's `Input`s. These\n    metrics become part of the model's topology and are tracked when you\n    save the model via `save()`.\n\n    ```python\n    inputs = tf.keras.Input(shape=(10,))\n    x = tf.keras.layers.Dense(10)(inputs)\n    outputs = tf.keras.layers.Dense(1)(x)\n    model = tf.keras.Model(inputs, outputs)\n    model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n    ```\n\n    Note: Calling `add_metric()` with the result of a metric object on a\n    Functional Model, as shown in the example below, is not supported. This\n    is because we cannot trace the metric result tensor back to the model's\n    inputs.\n\n    ```python\n    inputs = tf.keras.Input(shape=(10,))\n    x = tf.keras.layers.Dense(10)(inputs)\n    outputs = tf.keras.layers.Dense(1)(x)\n    model = tf.keras.Model(inputs, outputs)\n    model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n    ```\n\n    Args:\n      value: Metric tensor.\n      name: String metric name.\n      **kwargs: Additional keyword arguments for backward compatibility.\n        Accepted values:\n        `aggregation` - When the `value` tensor provided is not the result\n        of calling a `keras.Metric` instance, it will be aggregated by\n        default using a `keras.Metric.Mean`.\n    \"\"\"\n    kwargs_keys = list(kwargs.keys())\n    if len(kwargs_keys) &gt; 1 or (\n        len(kwargs_keys) == 1 and kwargs_keys[0] != \"aggregation\"\n    ):\n        raise TypeError(\n            f\"Unknown keyword arguments: {kwargs.keys()}. \"\n            \"Expected `aggregation`.\"\n        )\n\n    from_metric_obj = hasattr(value, \"_metric_obj\")\n    is_symbolic = isinstance(value, keras_tensor.KerasTensor)\n    in_call_context = base_layer_utils.call_context().in_call\n\n    if name is None and not from_metric_obj:\n        # Eg. `self.add_metric(math_ops.reduce_sum(x))` In eager mode, we\n        # use metric name to lookup a metric. Without a name, a new Mean\n        # metric wrapper will be created on every model/layer call. So, we\n        # raise an error when no name is provided. We will do the same for\n        # symbolic mode for consistency although a name will be generated if\n        # no name is provided.\n\n        # We will not raise this error in the foll use case for the sake of\n        # consistency as name in provided in the metric constructor.\n        # mean = metrics.Mean(name='my_metric')\n        # model.add_metric(mean(outputs))\n        raise ValueError(\n            \"Please provide a name for your metric like \"\n            \"`self.add_metric(tf.reduce_sum(inputs), \"\n            \"name='mean_activation')`\"\n        )\n    elif from_metric_obj:\n        name = value._metric_obj.name\n\n    if not in_call_context and not is_symbolic:\n        raise ValueError(\n            \"Expected a symbolic Tensor for the metric value, received: \"\n            + str(value)\n        )\n\n    # If a metric was added in a Layer's `call` or `build`.\n    if in_call_context or not getattr(self, \"_is_graph_network\", False):\n        # TF Function path should take the eager path.\n\n        # If the given metric is available in `metrics` list we just update\n        # state on it, otherwise we create a new metric instance and\n        # add it to the `metrics` list.\n        metric_obj = getattr(value, \"_metric_obj\", None)\n        # Tensors that come from a Metric object already updated the Metric\n        # state.\n        should_update_state = not metric_obj\n        name = metric_obj.name if metric_obj else name\n\n        with self._metrics_lock:\n            match = self._get_existing_metric(name)\n            if match:\n                metric_obj = match\n            elif metric_obj:\n                self._metrics.append(metric_obj)\n            else:\n                # Build the metric object with the value's dtype if it\n                # defines one\n                metric_obj = metrics_mod.Mean(\n                    name=name, dtype=getattr(value, \"dtype\", None)\n                )\n                self._metrics.append(metric_obj)\n\n        if should_update_state:\n            metric_obj(value)\n    else:\n        if from_metric_obj:\n            raise ValueError(\n                \"Using the result of calling a `Metric` object \"\n                \"when calling `add_metric` on a Functional \"\n                \"Model is not supported. Please pass the \"\n                \"Tensor to monitor directly.\"\n            )\n\n        # Insert layers into the Keras Graph Network.\n        aggregation = None if from_metric_obj else \"mean\"\n        self._graph_network_add_metric(value, aggregation, name)\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#keras.engine.base_layer.Layer.add_update","title":"<code>add_update(updates)</code>","text":"<p>Add update op(s), potentially dependent on layer inputs.</p> <p>Weight updates (for instance, the updates of the moving mean and variance in a BatchNormalization layer) may be dependent on the inputs passed when calling a layer. Hence, when reusing the same layer on different inputs <code>a</code> and <code>b</code>, some entries in <code>layer.updates</code> may be dependent on <code>a</code> and some on <code>b</code>. This method automatically keeps track of dependencies.</p> <p>This call is ignored when eager execution is enabled (in that case, variable updates are run on the fly and thus do not need to be tracked for later execution).</p> <p>Parameters:</p> Name Type Description Default <code>updates</code> <p>Update op, or list/tuple of update ops, or zero-arg callable that returns an update op. A zero-arg callable should be passed in order to disable running the updates by setting <code>trainable=False</code> on this Layer, when executing in Eager mode.</p> required Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code> <pre><code>@doc_controls.do_not_doc_inheritable\ndef add_update(self, updates):\n\"\"\"Add update op(s), potentially dependent on layer inputs.\n\n    Weight updates (for instance, the updates of the moving mean and\n    variance in a BatchNormalization layer) may be dependent on the inputs\n    passed when calling a layer. Hence, when reusing the same layer on\n    different inputs `a` and `b`, some entries in `layer.updates` may be\n    dependent on `a` and some on `b`. This method automatically keeps track\n    of dependencies.\n\n    This call is ignored when eager execution is enabled (in that case,\n    variable updates are run on the fly and thus do not need to be tracked\n    for later execution).\n\n    Args:\n      updates: Update op, or list/tuple of update ops, or zero-arg callable\n        that returns an update op. A zero-arg callable should be passed in\n        order to disable running the updates by setting `trainable=False`\n        on this Layer, when executing in Eager mode.\n    \"\"\"\n    call_context = base_layer_utils.call_context()\n    # No need to run updates during Functional API construction.\n    if call_context.in_keras_graph:\n        return\n\n    # Callable updates are disabled by setting `trainable=False`.\n    if not call_context.frozen:\n        for update in tf.nest.flatten(updates):\n            if callable(update):\n                update()\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#keras.engine.base_layer.Layer.add_variable","title":"<code>add_variable(*args, **kwargs)</code>","text":"<p>Deprecated, do NOT use! Alias for <code>add_weight</code>.</p> Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code> <pre><code>@doc_controls.do_not_doc_inheritable\ndef add_variable(self, *args, **kwargs):\n\"\"\"Deprecated, do NOT use! Alias for `add_weight`.\"\"\"\n    warnings.warn(\n        \"`layer.add_variable` is deprecated and \"\n        \"will be removed in a future version. \"\n        \"Please use the `layer.add_weight()` method instead.\",\n        stacklevel=2,\n    )\n    return self.add_weight(*args, **kwargs)\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#keras.engine.base_layer.Layer.add_weight","title":"<code>add_weight(name = None, shape = None, dtype = None, initializer = None, regularizer = None, trainable = None, constraint = None, use_resource = None, synchronization = tf.VariableSynchronization.AUTO, aggregation = tf.VariableAggregation.NONE, **kwargs)</code>","text":"<p>Adds a new variable to the layer.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>Variable name.</p> <code>None</code> <code>shape</code> <p>Variable shape. Defaults to scalar if unspecified.</p> <code>None</code> <code>dtype</code> <p>The type of the variable. Defaults to <code>self.dtype</code>.</p> <code>None</code> <code>initializer</code> <p>Initializer instance (callable).</p> <code>None</code> <code>regularizer</code> <p>Regularizer instance (callable).</p> <code>None</code> <code>trainable</code> <p>Boolean, whether the variable should be part of the layer's \"trainable_variables\" (e.g. variables, biases) or \"non_trainable_variables\" (e.g. BatchNorm mean and variance). Note that <code>trainable</code> cannot be <code>True</code> if <code>synchronization</code> is set to <code>ON_READ</code>.</p> <code>None</code> <code>constraint</code> <p>Constraint instance (callable).</p> <code>None</code> <code>use_resource</code> <p>Whether to use a <code>ResourceVariable</code> or not. See this guide  for more information.</p> <code>None</code> <code>synchronization</code> <p>Indicates when a distributed a variable will be aggregated. Accepted values are constants defined in the class <code>tf.VariableSynchronization</code>. By default the synchronization is set to <code>AUTO</code> and the current <code>DistributionStrategy</code> chooses when to synchronize. If <code>synchronization</code> is set to <code>ON_READ</code>, <code>trainable</code> must not be set to <code>True</code>.</p> <code>tf.VariableSynchronization.AUTO</code> <code>aggregation</code> <p>Indicates how a distributed variable will be aggregated. Accepted values are constants defined in the class <code>tf.VariableAggregation</code>.</p> <code>tf.VariableAggregation.NONE</code> <code>**kwargs</code> <p>Additional keyword arguments. Accepted values are <code>getter</code>, <code>collections</code>, <code>experimental_autocast</code> and <code>caching_device</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <p>The variable created.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>When giving unsupported dtype and no initializer or when trainable has been set to True with synchronization set as <code>ON_READ</code>.</p> Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code> <pre><code>@doc_controls.for_subclass_implementers\ndef add_weight(\n    self,\n    name=None,\n    shape=None,\n    dtype=None,\n    initializer=None,\n    regularizer=None,\n    trainable=None,\n    constraint=None,\n    use_resource=None,\n    synchronization=tf.VariableSynchronization.AUTO,\n    aggregation=tf.VariableAggregation.NONE,\n    **kwargs,\n):\n\"\"\"Adds a new variable to the layer.\n\n    Args:\n      name: Variable name.\n      shape: Variable shape. Defaults to scalar if unspecified.\n      dtype: The type of the variable. Defaults to `self.dtype`.\n      initializer: Initializer instance (callable).\n      regularizer: Regularizer instance (callable).\n      trainable: Boolean, whether the variable should be part of the layer's\n        \"trainable_variables\" (e.g. variables, biases)\n        or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n        Note that `trainable` cannot be `True` if `synchronization`\n        is set to `ON_READ`.\n      constraint: Constraint instance (callable).\n      use_resource: Whether to use a `ResourceVariable` or not.\n        See [this guide](\n        https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables)\n         for more information.\n      synchronization: Indicates when a distributed a variable will be\n        aggregated. Accepted values are constants defined in the class\n        `tf.VariableSynchronization`. By default the synchronization is set\n        to `AUTO` and the current `DistributionStrategy` chooses when to\n        synchronize. If `synchronization` is set to `ON_READ`, `trainable`\n        must not be set to `True`.\n      aggregation: Indicates how a distributed variable will be aggregated.\n        Accepted values are constants defined in the class\n        `tf.VariableAggregation`.\n      **kwargs: Additional keyword arguments. Accepted values are `getter`,\n        `collections`, `experimental_autocast` and `caching_device`.\n\n    Returns:\n      The variable created.\n\n    Raises:\n      ValueError: When giving unsupported dtype and no initializer or when\n        trainable has been set to True with synchronization set as\n        `ON_READ`.\n    \"\"\"\n    if shape is None:\n        shape = ()\n    kwargs.pop(\"partitioner\", None)  # Ignored.\n    # Validate optional keyword arguments.\n    for kwarg in kwargs:\n        if kwarg not in [\n            \"collections\",\n            \"experimental_autocast\",\n            \"caching_device\",\n            \"getter\",\n            \"layout\",\n        ]:\n            raise TypeError(\"Unknown keyword argument:\", kwarg)\n    collections_arg = kwargs.pop(\"collections\", None)\n    # 'experimental_autocast' can be set to False by the caller to indicate\n    # an AutoCastVariable should never be created.\n    autocast = kwargs.pop(\"experimental_autocast\", True)\n    # See the docstring for tf.Variable about the details for\n    # caching_device.\n    caching_device = kwargs.pop(\"caching_device\", None)\n\n    layout = kwargs.pop(\"layout\", None)\n    # Specially handling of auto layout fetch, based on the variable name\n    # and attribute name. For built-in keras layers, usually the variable\n    # name, eg 'kernel', will match with a 'kernel_layout' attribute name on\n    # the instance. We will try to do this auto fetch if layout is not\n    # explicitly specified. This is mainly a quick workaround for not\n    # applying too many interface change to built-in layers, until DTensor\n    # is a public API.  Also see dtensor.utils.allow_initializer_layout for\n    # more details.\n    # TODO(scottzhu): Remove this once dtensor is public to end user.\n    if not layout and name:\n        layout = getattr(self, name + \"_layout\", None)\n\n    if dtype is None:\n        dtype = self.dtype or backend.floatx()\n    dtype = tf.as_dtype(dtype)\n    if self._dtype_policy.variable_dtype is None:\n        # The policy is \"_infer\", so we infer the policy from the variable\n        # dtype.\n        self._set_dtype_policy(policy.Policy(dtype.base_dtype.name))\n    initializer = initializers.get(initializer)\n    regularizer = regularizers.get(regularizer)\n    constraint = constraints.get(constraint)\n\n    if synchronization == tf.VariableSynchronization.ON_READ:\n        if trainable:\n            raise ValueError(\n                \"Synchronization value can be set to \"\n                \"VariableSynchronization.ON_READ only for non-trainable \"\n                \"variables. You have specified trainable=True and \"\n                \"synchronization=VariableSynchronization.ON_READ.\"\n            )\n        else:\n            # Set trainable to be false when variable is to be synced on\n            # read.\n            trainable = False\n    elif trainable is None:\n        trainable = True\n\n    # Initialize variable when no initializer provided\n    if initializer is None:\n        # If dtype is DT_FLOAT, provide a uniform unit scaling initializer\n        if dtype.is_floating:\n            initializer = initializers.get(\"glorot_uniform\")\n        # If dtype is DT_INT/DT_UINT, provide a default value `zero`\n        # If dtype is DT_BOOL, provide a default value `FALSE`\n        elif dtype.is_integer or dtype.is_unsigned or dtype.is_bool:\n            initializer = initializers.get(\"zeros\")\n        # NOTES:Do we need to support for handling DT_STRING and DT_COMPLEX\n        # here?\n        elif \"getter\" not in kwargs:\n            # When `getter` is specified, it's possibly fine for\n            # `initializer` to be None since it's up to the custom `getter`\n            # to raise error in case it indeed needs `initializer`.\n            raise ValueError(\n                f\"An initializer for variable {name} of type \"\n                f\"{dtype.base_dtype} is required for layer \"\n                f\"{self.name}. Received: {initializer}.\"\n            )\n\n    getter = kwargs.pop(\"getter\", base_layer_utils.make_variable)\n    if (\n        autocast\n        and self._dtype_policy.compute_dtype\n        != self._dtype_policy.variable_dtype\n        and dtype.is_floating\n    ):\n        old_getter = getter\n\n        # Wrap variable constructor to return an AutoCastVariable.\n        def getter(*args, **kwargs):\n            variable = old_getter(*args, **kwargs)\n            return autocast_variable.create_autocast_variable(variable)\n\n        # Also the caching_device does not work with the mixed precision\n        # API, disable it if it is specified.\n        # TODO(b/142020079): Re-enable it once the bug is fixed.\n        if caching_device is not None:\n            tf_logging.warning(\n                \"`caching_device` does not work with mixed precision API. \"\n                \"Ignoring user specified `caching_device`.\"\n            )\n            caching_device = None\n    if layout:\n        getter = functools.partial(getter, layout=layout)\n\n    variable = self._add_variable_with_custom_getter(\n        name=name,\n        shape=shape,\n        # TODO(allenl): a `make_variable` equivalent should be added as a\n        # `Trackable` method.\n        getter=getter,\n        # Manage errors in Layer rather than Trackable.\n        overwrite=True,\n        initializer=initializer,\n        dtype=dtype,\n        constraint=constraint,\n        trainable=trainable,\n        use_resource=use_resource,\n        collections=collections_arg,\n        synchronization=synchronization,\n        aggregation=aggregation,\n        caching_device=caching_device,\n    )\n    if regularizer is not None:\n        # TODO(fchollet): in the future, this should be handled at the\n        # level of variable creation, and weight regularization losses\n        # should be variable attributes.\n        name_in_scope = variable.name[: variable.name.find(\":\")]\n        self._handle_weight_regularization(\n            name_in_scope, variable, regularizer\n        )\n    if base_layer_utils.is_split_variable(variable):\n        for v in variable:\n            backend.track_variable(v)\n            if trainable:\n                self._trainable_weights.append(v)\n            else:\n                self._non_trainable_weights.append(v)\n    else:\n        backend.track_variable(variable)\n        if trainable:\n            self._trainable_weights.append(variable)\n        else:\n            self._non_trainable_weights.append(variable)\n    return variable\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#airt._components.mono_dense_layer.MonoDense.build","title":"<code>build(input_shape: Tuple, *args: List[Any], **kwargs: Any) -&gt; None</code>","text":"<p>Build</p> <p>Parameters:</p> Name Type Description Default <code>input_shape</code> <code>Tuple</code> <p>input tensor</p> required <code>args</code> <code>List[Any]</code> <p>positional arguments passed to Dense.build()</p> <code>()</code> <code>kwargs</code> <code>Any</code> <p>keyword arguments passed to Dense.build()</p> <code>{}</code> Source code in <code>airt/_components/mono_dense_layer.py</code> <pre><code>def build(self, input_shape: Tuple, *args: List[Any], **kwargs: Any) -&gt; None:\n\"\"\"Build\n\n    Args:\n        input_shape: input tensor\n        args: positional arguments passed to Dense.build()\n        kwargs: keyword arguments passed to Dense.build()\n    \"\"\"\n    super(MonoDense, self).build(input_shape, *args, **kwargs)\n    self.monotonicity_indicator = get_monotonicity_indicator(\n        monotonicity_indicator=self.monotonicity_indicator,\n        input_shape=input_shape,\n        units=self.units,\n    )\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#airt._components.mono_dense_layer.MonoDense.call","title":"<code>call(inputs: TensorLike) -&gt; TensorLike</code>","text":"<p>Call</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <code>TensorLike</code> <p>input tensor of shape (batch_size, ..., x_length)</p> required <p>Returns:</p> Type Description <code>TensorLike</code> <p>N-D tensor with shape: <code>(batch_size, ..., units)</code>.</p> Source code in <code>airt/_components/mono_dense_layer.py</code> <pre><code>def call(self, inputs: TensorLike) -&gt; TensorLike:\n\"\"\"Call\n\n    Args:\n        inputs: input tensor of shape (batch_size, ..., x_length)\n\n    Returns:\n        N-D tensor with shape: `(batch_size, ..., units)`.\n\n    \"\"\"\n    # calculate W'*x+y after we replace the kernal according to monotonicity vector\n    with replace_kernel_using_monotonicity_indicator(\n        self, monotonicity_indicator=self.monotonicity_indicator\n    ):\n        h = super(MonoDense, self).call(inputs)\n\n    y = apply_activations(\n        h,\n        units=self.units,\n        convex_activation=self.convex_activation,\n        concave_activation=self.concave_activation,\n        saturated_activation=self.saturated_activation,\n        is_convex=self.is_convex,\n        is_concave=self.is_concave,\n        activation_weights=self.activation_weights,\n    )\n\n    return y\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#keras.engine.base_layer.Layer.compute_mask","title":"<code>compute_mask(inputs, mask = None)</code>","text":"<p>Computes an output mask tensor.</p> <p>Parameters:</p> Name Type Description Default <code>inputs</code> <p>Tensor or list of tensors.</p> required <code>mask</code> <p>Tensor or list of tensors.</p> <code>None</code> <p>Returns:</p> Type Description <p>None or a tensor (or list of tensors, one per output tensor of the layer).</p> Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code> <pre><code>@generic_utils.default\ndef compute_mask(self, inputs, mask=None):\n\"\"\"Computes an output mask tensor.\n\n    Args:\n        inputs: Tensor or list of tensors.\n        mask: Tensor or list of tensors.\n\n    Returns:\n        None or a tensor (or list of tensors,\n            one per output tensor of the layer).\n    \"\"\"\n    if not self._supports_masking:\n        if any(m is not None for m in tf.nest.flatten(mask)):\n            raise TypeError(\n                \"Layer \" + self.name + \" does not support masking, \"\n                \"but was passed an input_mask: \" + str(mask)\n            )\n        # masking not explicitly supported: return None as mask.\n        return None\n    # if masking is explicitly supported, by default\n    # carry over the input mask\n    return mask\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#keras.engine.base_layer.Layer.compute_output_signature","title":"<code>compute_output_signature(input_signature)</code>","text":"<p>Compute the output tensor signature of the layer based on the inputs.</p> <p>Unlike a TensorShape object, a TensorSpec object contains both shape and dtype information for a tensor. This method allows layers to provide output dtype information if it is different from the input dtype. For any layer that doesn't implement this function, the framework will fall back to use <code>compute_output_shape</code>, and will assume that the output dtype matches the input dtype.</p> <p>Parameters:</p> Name Type Description Default <code>input_signature</code> <p>Single TensorSpec or nested structure of TensorSpec objects, describing a candidate input for the layer.</p> required <p>Returns:</p> Type Description <p>Single TensorSpec or nested structure of TensorSpec objects, describing how the layer would transform the provided input.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If input_signature contains a non-TensorSpec object.</p> Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code> <pre><code>@doc_controls.for_subclass_implementers\ndef compute_output_signature(self, input_signature):\n\"\"\"Compute the output tensor signature of the layer based on the inputs.\n\n    Unlike a TensorShape object, a TensorSpec object contains both shape\n    and dtype information for a tensor. This method allows layers to provide\n    output dtype information if it is different from the input dtype.\n    For any layer that doesn't implement this function,\n    the framework will fall back to use `compute_output_shape`, and will\n    assume that the output dtype matches the input dtype.\n\n    Args:\n      input_signature: Single TensorSpec or nested structure of TensorSpec\n        objects, describing a candidate input for the layer.\n\n    Returns:\n      Single TensorSpec or nested structure of TensorSpec objects,\n        describing how the layer would transform the provided input.\n\n    Raises:\n      TypeError: If input_signature contains a non-TensorSpec object.\n    \"\"\"\n\n    def check_type_return_shape(s):\n        if not isinstance(s, tf.TensorSpec):\n            raise TypeError(\n                \"Only TensorSpec signature types are supported. \"\n                f\"Received: {s}.\"\n            )\n        return s.shape\n\n    input_shape = tf.nest.map_structure(\n        check_type_return_shape, input_signature\n    )\n    output_shape = self.compute_output_shape(input_shape)\n    dtype = self._compute_dtype\n    if dtype is None:\n        input_dtypes = [s.dtype for s in tf.nest.flatten(input_signature)]\n        # Default behavior when self.dtype is None, is to use the first\n        # input's dtype.\n        dtype = input_dtypes[0]\n    return tf.nest.map_structure(\n        lambda s: tf.TensorSpec(dtype=dtype, shape=s), output_shape\n    )\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#keras.engine.base_layer.Layer.count_params","title":"<code>count_params()</code>","text":"<p>Count the total number of scalars composing the weights.</p> <p>Returns:</p> Type Description <p>An integer count.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the layer isn't yet built (in which case its weights aren't yet defined).</p> Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code> <pre><code>def count_params(self):\n\"\"\"Count the total number of scalars composing the weights.\n\n    Returns:\n        An integer count.\n\n    Raises:\n        ValueError: if the layer isn't yet built\n          (in which case its weights aren't yet defined).\n    \"\"\"\n    if not self.built:\n        if getattr(self, \"_is_graph_network\", False):\n            with tf_utils.maybe_init_scope(self):\n                self._maybe_build(self.inputs)\n        else:\n            raise ValueError(\n                \"You tried to call `count_params` \"\n                f\"on layer {self.name}\"\n                \", but the layer isn't built. \"\n                \"You can build it manually via: \"\n                f\"`{self.name}.build(batch_input_shape)`.\"\n            )\n    return layer_utils.count_params(self.weights)\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#keras.engine.base_layer.Layer.finalize_state","title":"<code>finalize_state()</code>","text":"<p>Finalizes the layers state after updating layer weights.</p> <p>This function can be subclassed in a layer and will be called after updating a layer weights. It can be overridden to finalize any additional layer state after a weight update.</p> <p>This function will be called after weights of a layer have been restored from a loaded model.</p> Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code> <pre><code>@doc_controls.do_not_generate_docs\ndef finalize_state(self):\n\"\"\"Finalizes the layers state after updating layer weights.\n\n    This function can be subclassed in a layer and will be called after\n    updating a layer weights. It can be overridden to finalize any\n    additional layer state after a weight update.\n\n    This function will be called after weights of a layer have been restored\n    from a loaded model.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#airt._components.mono_dense_layer.MonoDense.get_config","title":"<code>get_config() -&gt; Dict[str, Any]</code>","text":"<p>Get config is used for saving the model</p> Source code in <code>airt/_components/mono_dense_layer.py</code> <pre><code>def get_config(self) -&gt; Dict[str, Any]:\n\"\"\"Get config is used for saving the model\"\"\"\n    return dict(\n        units=self.units,\n        activation=self.org_activation,\n        monotonicity_indicator=self.monotonicity_indicator,\n        is_convex=self.is_convex,\n        is_concave=self.is_concave,\n        activation_weights=self.activation_weights,\n    )\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#keras.engine.base_layer.Layer.get_input_at","title":"<code>get_input_at(node_index)</code>","text":"<p>Retrieves the input tensor(s) of a layer at a given node.</p> <p>Parameters:</p> Name Type Description Default <code>node_index</code> <p>Integer, index of the node from which to retrieve the attribute. E.g. <code>node_index=0</code> will correspond to the first input node of the layer.</p> required <p>Returns:</p> Type Description <p>A tensor (or list of tensors if the layer has multiple inputs).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called in Eager mode.</p> Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code> <pre><code>@doc_controls.do_not_doc_inheritable\ndef get_input_at(self, node_index):\n\"\"\"Retrieves the input tensor(s) of a layer at a given node.\n\n    Args:\n        node_index: Integer, index of the node\n            from which to retrieve the attribute.\n            E.g. `node_index=0` will correspond to the\n            first input node of the layer.\n\n    Returns:\n        A tensor (or list of tensors if the layer has multiple inputs).\n\n    Raises:\n      RuntimeError: If called in Eager mode.\n    \"\"\"\n    return self._get_node_attribute_at_index(\n        node_index, \"input_tensors\", \"input\"\n    )\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#keras.engine.base_layer.Layer.get_input_mask_at","title":"<code>get_input_mask_at(node_index)</code>","text":"<p>Retrieves the input mask tensor(s) of a layer at a given node.</p> <p>Parameters:</p> Name Type Description Default <code>node_index</code> <p>Integer, index of the node from which to retrieve the attribute. E.g. <code>node_index=0</code> will correspond to the first time the layer was called.</p> required <p>Returns:</p> Type Description <p>A mask tensor</p> <p>(or list of tensors if the layer has multiple inputs).</p> Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code> <pre><code>@doc_controls.do_not_doc_inheritable\ndef get_input_mask_at(self, node_index):\n\"\"\"Retrieves the input mask tensor(s) of a layer at a given node.\n\n    Args:\n        node_index: Integer, index of the node\n            from which to retrieve the attribute.\n            E.g. `node_index=0` will correspond to the\n            first time the layer was called.\n\n    Returns:\n        A mask tensor\n        (or list of tensors if the layer has multiple inputs).\n    \"\"\"\n    inputs = self.get_input_at(node_index)\n    if isinstance(inputs, list):\n        return [getattr(x, \"_keras_mask\", None) for x in inputs]\n    else:\n        return getattr(inputs, \"_keras_mask\", None)\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#keras.engine.base_layer.Layer.get_input_shape_at","title":"<code>get_input_shape_at(node_index)</code>","text":"<p>Retrieves the input shape(s) of a layer at a given node.</p> <p>Parameters:</p> Name Type Description Default <code>node_index</code> <p>Integer, index of the node from which to retrieve the attribute. E.g. <code>node_index=0</code> will correspond to the first time the layer was called.</p> required <p>Returns:</p> Type Description <p>A shape tuple</p> <p>(or list of shape tuples if the layer has multiple inputs).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called in Eager mode.</p> Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code> <pre><code>@doc_controls.do_not_doc_inheritable\ndef get_input_shape_at(self, node_index):\n\"\"\"Retrieves the input shape(s) of a layer at a given node.\n\n    Args:\n        node_index: Integer, index of the node\n            from which to retrieve the attribute.\n            E.g. `node_index=0` will correspond to the\n            first time the layer was called.\n\n    Returns:\n        A shape tuple\n        (or list of shape tuples if the layer has multiple inputs).\n\n    Raises:\n      RuntimeError: If called in Eager mode.\n    \"\"\"\n    return self._get_node_attribute_at_index(\n        node_index, \"input_shapes\", \"input shape\"\n    )\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#keras.engine.base_layer.Layer.get_output_at","title":"<code>get_output_at(node_index)</code>","text":"<p>Retrieves the output tensor(s) of a layer at a given node.</p> <p>Parameters:</p> Name Type Description Default <code>node_index</code> <p>Integer, index of the node from which to retrieve the attribute. E.g. <code>node_index=0</code> will correspond to the first output node of the layer.</p> required <p>Returns:</p> Type Description <p>A tensor (or list of tensors if the layer has multiple outputs).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called in Eager mode.</p> Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code> <pre><code>@doc_controls.do_not_doc_inheritable\ndef get_output_at(self, node_index):\n\"\"\"Retrieves the output tensor(s) of a layer at a given node.\n\n    Args:\n        node_index: Integer, index of the node\n            from which to retrieve the attribute.\n            E.g. `node_index=0` will correspond to the\n            first output node of the layer.\n\n    Returns:\n        A tensor (or list of tensors if the layer has multiple outputs).\n\n    Raises:\n      RuntimeError: If called in Eager mode.\n    \"\"\"\n    return self._get_node_attribute_at_index(\n        node_index, \"output_tensors\", \"output\"\n    )\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#keras.engine.base_layer.Layer.get_output_mask_at","title":"<code>get_output_mask_at(node_index)</code>","text":"<p>Retrieves the output mask tensor(s) of a layer at a given node.</p> <p>Parameters:</p> Name Type Description Default <code>node_index</code> <p>Integer, index of the node from which to retrieve the attribute. E.g. <code>node_index=0</code> will correspond to the first time the layer was called.</p> required <p>Returns:</p> Type Description <p>A mask tensor</p> <p>(or list of tensors if the layer has multiple outputs).</p> Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code> <pre><code>@doc_controls.do_not_doc_inheritable\ndef get_output_mask_at(self, node_index):\n\"\"\"Retrieves the output mask tensor(s) of a layer at a given node.\n\n    Args:\n        node_index: Integer, index of the node\n            from which to retrieve the attribute.\n            E.g. `node_index=0` will correspond to the\n            first time the layer was called.\n\n    Returns:\n        A mask tensor\n        (or list of tensors if the layer has multiple outputs).\n    \"\"\"\n    output = self.get_output_at(node_index)\n    if isinstance(output, list):\n        return [getattr(x, \"_keras_mask\", None) for x in output]\n    else:\n        return getattr(output, \"_keras_mask\", None)\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#keras.engine.base_layer.Layer.get_output_shape_at","title":"<code>get_output_shape_at(node_index)</code>","text":"<p>Retrieves the output shape(s) of a layer at a given node.</p> <p>Parameters:</p> Name Type Description Default <code>node_index</code> <p>Integer, index of the node from which to retrieve the attribute. E.g. <code>node_index=0</code> will correspond to the first time the layer was called.</p> required <p>Returns:</p> Type Description <p>A shape tuple</p> <p>(or list of shape tuples if the layer has multiple outputs).</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If called in Eager mode.</p> Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code> <pre><code>@doc_controls.do_not_doc_inheritable\ndef get_output_shape_at(self, node_index):\n\"\"\"Retrieves the output shape(s) of a layer at a given node.\n\n    Args:\n        node_index: Integer, index of the node\n            from which to retrieve the attribute.\n            E.g. `node_index=0` will correspond to the\n            first time the layer was called.\n\n    Returns:\n        A shape tuple\n        (or list of shape tuples if the layer has multiple outputs).\n\n    Raises:\n      RuntimeError: If called in Eager mode.\n    \"\"\"\n    return self._get_node_attribute_at_index(\n        node_index, \"output_shapes\", \"output shape\"\n    )\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#keras.engine.base_layer.Layer.get_weights","title":"<code>get_weights()</code>","text":"<p>Returns the current weights of the layer, as NumPy arrays.</p> <p>The weights of a layer represent the state of the layer. This function returns both trainable and non-trainable weight values associated with this layer as a list of NumPy arrays, which can in turn be used to load state into similarly parameterized layers.</p> <p>For example, a <code>Dense</code> layer returns a list of two values: the kernel matrix and the bias vector. These can be used to set the weights of another <code>Dense</code> layer:</p> <p>layer_a = tf.keras.layers.Dense(1, ...   kernel_initializer=tf.constant_initializer(1.)) a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]])) layer_a.get_weights() [array([[1.],        [1.],        [1.]], dtype=float32), array([0.], dtype=float32)] layer_b = tf.keras.layers.Dense(1, ...   kernel_initializer=tf.constant_initializer(2.)) b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]])) layer_b.get_weights() [array([[2.],        [2.],        [2.]], dtype=float32), array([0.], dtype=float32)] layer_b.set_weights(layer_a.get_weights()) layer_b.get_weights() [array([[1.],        [1.],        [1.]], dtype=float32), array([0.], dtype=float32)]</p> <p>Returns:</p> Type Description <p>Weights values as a list of NumPy arrays.</p> Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code> <pre><code>def get_weights(self):\n\"\"\"Returns the current weights of the layer, as NumPy arrays.\n\n    The weights of a layer represent the state of the layer. This function\n    returns both trainable and non-trainable weight values associated with\n    this layer as a list of NumPy arrays, which can in turn be used to load\n    state into similarly parameterized layers.\n\n    For example, a `Dense` layer returns a list of two values: the kernel\n    matrix and the bias vector. These can be used to set the weights of\n    another `Dense` layer:\n\n    &gt;&gt;&gt; layer_a = tf.keras.layers.Dense(1,\n    ...   kernel_initializer=tf.constant_initializer(1.))\n    &gt;&gt;&gt; a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n    &gt;&gt;&gt; layer_a.get_weights()\n    [array([[1.],\n           [1.],\n           [1.]], dtype=float32), array([0.], dtype=float32)]\n    &gt;&gt;&gt; layer_b = tf.keras.layers.Dense(1,\n    ...   kernel_initializer=tf.constant_initializer(2.))\n    &gt;&gt;&gt; b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n    &gt;&gt;&gt; layer_b.get_weights()\n    [array([[2.],\n           [2.],\n           [2.]], dtype=float32), array([0.], dtype=float32)]\n    &gt;&gt;&gt; layer_b.set_weights(layer_a.get_weights())\n    &gt;&gt;&gt; layer_b.get_weights()\n    [array([[1.],\n           [1.],\n           [1.]], dtype=float32), array([0.], dtype=float32)]\n\n    Returns:\n        Weights values as a list of NumPy arrays.\n    \"\"\"\n    weights = self.weights\n    output_weights = []\n    for weight in weights:\n        if isinstance(weight, base_layer_utils.TrackableWeightHandler):\n            output_weights.extend(weight.get_tensors())\n        else:\n            output_weights.append(weight)\n    return backend.batch_get_value(output_weights)\n</code></pre>"},{"location":"api/airt/keras/layers/MonoDense/#keras.engine.base_layer.Layer.set_weights","title":"<code>set_weights(weights)</code>","text":"<p>Sets the weights of the layer, from NumPy arrays.</p> <p>The weights of a layer represent the state of the layer. This function sets the weight values from numpy arrays. The weight values should be passed in the order they are created by the layer. Note that the layer's weights must be instantiated before calling this function, by calling the layer.</p> <p>For example, a <code>Dense</code> layer returns a list of two values: the kernel matrix and the bias vector. These can be used to set the weights of another <code>Dense</code> layer:</p> <p>layer_a = tf.keras.layers.Dense(1, ...   kernel_initializer=tf.constant_initializer(1.)) a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]])) layer_a.get_weights() [array([[1.],        [1.],        [1.]], dtype=float32), array([0.], dtype=float32)] layer_b = tf.keras.layers.Dense(1, ...   kernel_initializer=tf.constant_initializer(2.)) b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]])) layer_b.get_weights() [array([[2.],        [2.],        [2.]], dtype=float32), array([0.], dtype=float32)] layer_b.set_weights(layer_a.get_weights()) layer_b.get_weights() [array([[1.],        [1.],        [1.]], dtype=float32), array([0.], dtype=float32)]</p> <p>Parameters:</p> Name Type Description Default <code>weights</code> <p>a list of NumPy arrays. The number of arrays and their shape must match number of the dimensions of the weights of the layer (i.e. it should match the output of <code>get_weights</code>).</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provided weights list does not match the layer's specifications.</p> Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code> <pre><code>def set_weights(self, weights):\n\"\"\"Sets the weights of the layer, from NumPy arrays.\n\n    The weights of a layer represent the state of the layer. This function\n    sets the weight values from numpy arrays. The weight values should be\n    passed in the order they are created by the layer. Note that the layer's\n    weights must be instantiated before calling this function, by calling\n    the layer.\n\n    For example, a `Dense` layer returns a list of two values: the kernel\n    matrix and the bias vector. These can be used to set the weights of\n    another `Dense` layer:\n\n    &gt;&gt;&gt; layer_a = tf.keras.layers.Dense(1,\n    ...   kernel_initializer=tf.constant_initializer(1.))\n    &gt;&gt;&gt; a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n    &gt;&gt;&gt; layer_a.get_weights()\n    [array([[1.],\n           [1.],\n           [1.]], dtype=float32), array([0.], dtype=float32)]\n    &gt;&gt;&gt; layer_b = tf.keras.layers.Dense(1,\n    ...   kernel_initializer=tf.constant_initializer(2.))\n    &gt;&gt;&gt; b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n    &gt;&gt;&gt; layer_b.get_weights()\n    [array([[2.],\n           [2.],\n           [2.]], dtype=float32), array([0.], dtype=float32)]\n    &gt;&gt;&gt; layer_b.set_weights(layer_a.get_weights())\n    &gt;&gt;&gt; layer_b.get_weights()\n    [array([[1.],\n           [1.],\n           [1.]], dtype=float32), array([0.], dtype=float32)]\n\n    Args:\n      weights: a list of NumPy arrays. The number\n        of arrays and their shape must match\n        number of the dimensions of the weights\n        of the layer (i.e. it should match the\n        output of `get_weights`).\n\n    Raises:\n      ValueError: If the provided weights list does not match the\n        layer's specifications.\n    \"\"\"\n    params = self.weights\n\n    expected_num_weights = 0\n    for param in params:\n        if isinstance(param, base_layer_utils.TrackableWeightHandler):\n            expected_num_weights += param.num_tensors\n        else:\n            expected_num_weights += 1\n\n    if expected_num_weights != len(weights):\n        raise ValueError(\n            'You called `set_weights(weights)` on layer \"%s\" '\n            \"with a weight list of length %s, but the layer was \"\n            \"expecting %s weights. Provided weights: %s...\"\n            % (\n                self.name,\n                len(weights),\n                expected_num_weights,\n                str(weights)[:50],\n            )\n        )\n\n    weight_index = 0\n    weight_value_tuples = []\n    for param in params:\n        if isinstance(param, base_layer_utils.TrackableWeightHandler):\n            num_tensors = param.num_tensors\n            tensors = weights[weight_index : weight_index + num_tensors]\n            param.set_weights(tensors)\n            weight_index += num_tensors\n        else:\n            weight = weights[weight_index]\n            weight_shape = weight.shape if hasattr(weight, \"shape\") else ()\n            ref_shape = param.shape\n            if not ref_shape.is_compatible_with(weight_shape):\n                raise ValueError(\n                    f\"Layer {self.name} weight shape {ref_shape} \"\n                    \"is not compatible with provided weight \"\n                    f\"shape {weight_shape}.\"\n                )\n            weight_value_tuples.append((param, weight))\n            weight_index += 1\n\n    backend.batch_set_value(weight_value_tuples)\n\n    # Perform any layer defined finalization of the layer state.\n    for layer in self._flatten_layers():\n        layer.finalize_state()\n</code></pre>"},{"location":"experiments/AutoMPG/","title":"Auto MPG","text":""},{"location":"experiments/AutoMPG/#running-in-google-colab","title":"Running in Google Colab","text":"<p>You can run this experiment in Google Colab by clicking the button below:</p> <p> </p>"},{"location":"experiments/AutoMPG/#dataset","title":"Dataset","text":"<p>The Auto MPG Dataset is a regression dataset [1] with 7 features:</p> <ul> <li> <p>Cylinders</p> </li> <li> <p>Displacement</p> </li> <li> <p>Horsepower</p> </li> <li> <p>Weight</p> </li> <li> <p>Acceleration</p> </li> <li> <p>Model Year</p> </li> <li> <p>Origin.</p> </li> </ul> <p>The dependant variable MPG is monotonically decreasing with respect to features Weigh, Displacement, and Horsepower. The <code>monotonicity_indicator</code> corrsponding to these features are set to -1, since the relationship is a monotonically decreasing one with respect to the dependant variable.</p> <p>This is a part of comparison with methods and datasets from COMET [2].</p> <p>References:</p> <ol> <li> <p>Ross Quinlan. Combining Instance-Based and Model-Based Learning. In     Proceedings on the Tenth International Conference of Machine     Learning, 236-243, University of Massachusetts, Amherst. Morgan     Kaufmann, 1993.</p> <p>https://archive.ics.uci.edu/ml/datasets/auto+mpg</p> </li> <li> <p>Aishwarya Sivaraman, Golnoosh Farnadi, Todd Millstein, and Guy Van     den Broeck. Counterexample-guided learning of monotonic neural     networks. Advances in Neural Information Processing Systems,     33:11936\u201311948, 2020.</p> <p>Github repo: https://github.com/AishwaryaSivaraman/COMET</p> </li> </ol> <pre><code>monotonicity_indicator = {\n    \"Cylinders\": 0,\n    \"Displacement\": -1,\n    \"Horsepower\": -1,\n    \"Weight\": -1,\n    \"Acceleration\": 0,\n    \"Model_Year\": 0,\n    \"Origin\": 0,\n}\n</code></pre> <p>These are a few examples of the dataset:</p> 0 1 2 3 4 Cylinders 1.482807 1.482807 1.482807 1.482807 1.482807 Displacement 1.073028 1.482902 1.044432 1.025368 2.235927 Horsepower 0.650564 1.548993 1.163952 0.907258 2.396084 Weight 0.606625 0.828131 0.523413 0.542165 1.587581 Acceleration -1.275546 -1.452517 -1.275546 -1.806460 -1.983431 Model_Year -1.631803 -1.631803 -1.631803 -1.631803 -1.631803 Origin -0.701669 -0.701669 -0.701669 -0.701669 -0.701669 ground_truth 18.000000 15.000000 16.000000 17.000000 15.000000"},{"location":"experiments/AutoMPG/#hyperparameter-search","title":"Hyperparameter search","text":"<p>The choice of the batch size and the maximum number of epochs depends on the dataset size. For this dataset, we use the following values:</p> <pre><code>batch_size = 16\nmax_epochs = 50\n</code></pre> <p>We use the Type-2 architecture built using <code>MonoDense</code> layer with the following set of hyperparameters ranges:</p> <pre><code>def hp_params_f(hp):\n    return dict(\n        units=hp.Int(\"units\", min_value=16, max_value=24, step=1),\n        n_layers=hp.Int(\"n_layers\", min_value=2, max_value=2),\n        activation=hp.Choice(\"activation\", values=[\"elu\"]),\n        learning_rate=hp.Float(\n            \"learning_rate\", min_value=1e-2, max_value=0.3, sampling=\"log\"\n        ),\n        weight_decay=hp.Float(\n            \"weight_decay\", min_value=1e-2, max_value=0.3, sampling=\"log\"\n        ),\n        dropout=hp.Float(\"dropout\", min_value=0.0, max_value=0.5, sampling=\"linear\"),\n        decay_rate=hp.Float(\n            \"decay_rate\", min_value=0.8, max_value=1.0, sampling=\"reverse_log\"\n        ),\n    )\n</code></pre> <p>The following fixed parameters are used to build the Type-2 architecture for this dataset:</p> <ul> <li> <p><code>final_activation</code> is used to build the final layer for regression   problem (set to <code>None</code>) or for the classification problem   (<code>\"sigmoid\"</code>),</p> </li> <li> <p><code>loss</code> is used for training regression (<code>\"mse\"</code>) or classification   (<code>\"binary_crossentropy\"</code>) problem, and</p> </li> <li> <p><code>metrics</code> denotes metrics used to compare with previosly published   results: <code>\"accuracy\"</code> for classification and \u201c<code>mse</code>\u201d or \u201c<code>rmse</code>\u201d for   regression.</p> </li> </ul> <p>Parameters <code>objective</code> and <code>direction</code> are used by the tuner such that <code>objective=f\"val_{metrics}\"</code> and direction is either <code>\"min</code> or <code>\"max\"</code>.</p> <p>Parameters <code>max_trials</code> denotes the number of trial performed buy the tuner, <code>patience</code> is the number of epochs allowed to perform worst than the best one before stopping the current trial. The parameter <code>execution_per_trial</code> denotes the number of runs before calculating the results of a trial, it should be set to value greater than 1 for small datasets that have high variance in results.</p> <pre><code>final_activation = None\nloss = \"mse\"\nmetrics = \"mse\"\nobjective = \"val_mse\"\ndirection = \"min\"\nmax_trials = 200\npatience = 5\nexecutions_per_trial = 3\n</code></pre> <p>The following table describes the best models and their hyperparameters found by the tuner:</p> 0 1 2 3 4 units 21 17 19 21 22 n_layers 2 2 2 2 2 activation elu elu elu elu elu learning_rate 0.073407 0.105021 0.080618 0.042817 0.107845 weight_decay 0.058583 0.064151 0.023706 0.045050 0.032343 dropout 0.157718 0.189830 0.149354 0.324661 0.237459 decay_rate 0.887923 0.828540 0.800000 0.988544 0.886158 val_mse_mean 8.371161 8.404634 8.420449 8.421339 8.430901 val_mse_std 0.084437 0.149566 0.110670 0.063357 0.115722 val_mse_min 8.251875 8.255271 8.294801 8.352478 8.297507 val_mse_max 8.476566 8.614701 8.576631 8.520736 8.565886 params 848 567 627 848 885"},{"location":"experiments/AutoMPG/#the-optimal-model","title":"The optimal model","text":"<p>These are the best hyperparameters found by previous runs of the tuner:</p> <pre><code>def final_hp_params_f(hp):\n    return dict(\n        units=hp.Fixed(\"units\", value=21),\n        n_layers=hp.Fixed(\"n_layers\", 2),\n        activation=hp.Fixed(\"activation\", value=\"elu\"),\n        learning_rate=hp.Fixed(\"learning_rate\", value=0.073407),\n        weight_decay=hp.Fixed(\"weight_decay\", value=0.058583),\n        dropout=hp.Fixed(\"dropout\", value=0.157718),\n        decay_rate=hp.Fixed(\"decay_rate\", value=0.887923),\n    )\n</code></pre> <p>The final evaluation of the optimal model:</p> 0 units 21 n_layers 2 activation elu learning_rate 0.073407 weight_decay 0.058583 dropout 0.157718 decay_rate 0.887923 val_mse_mean 8.371155 val_mse_std 0.084440 val_mse_min 8.251865 val_mse_max 8.476567 params 848"},{"location":"experiments/Blog/","title":"Blog","text":""},{"location":"experiments/Blog/#running-in-google-colab","title":"Running in Google Colab","text":"<p>You can run this experiment in Google Colab by clicking the button below:</p> <p> </p>"},{"location":"experiments/Blog/#dataset","title":"Dataset","text":"<p>Blog Feedback [1] is a dataset containing 54,270 data points from blog posts. The raw HTML-documents of the blog posts were crawled and processed. The prediction task associated with the data is the prediction of the number of comments in the upcoming 24 hours. The feature of the dataset has 276 dimensions, and 8 attributes among them should be monotonically non-decreasing with the prediction. They are A51, A52, A53, A54, A56, A57, A58, A59. Thus the <code>monotonicity_indicator</code> corrsponding to these features are set to 1. As done in [2], we only use the data points with targets smaller than the 90th percentile.</p> <p>References:</p> <ol> <li>Krisztian Buza. Feedback prediction for blogs. In Data analysis,     machine learning and knowledge discovery, pages 145\u2013152. Springer,     2014</li> <li>Xingchao Liu, Xing Han, Na Zhang, and Qiang Liu. Certified monotonic     neural networks. Advances in Neural Information Processing Systems,     33:15427\u201315438, 2020</li> </ol> <pre><code>monotonicity_indicator = {\n    f\"feature_{i}\": 1 if i in range(50, 54) or i in range(55, 59) else 0\n    for i in range(276)\n}\n</code></pre> <p>These are a few examples of the dataset:</p> 0 1 2 3 4 feature_0 0.001920 0.001920 0.000640 0.001920 0.001920 feature_1 0.001825 0.001825 0.001825 0.000000 0.000000 feature_2 0.002920 0.002920 0.000000 0.001460 0.001460 feature_3 0.001627 0.001627 0.000651 0.001627 0.001627 feature_4 0.000000 0.000000 0.000000 0.000000 0.000000 feature_5 0.000000 0.000000 0.000000 0.000000 0.000000 feature_6 0.000000 0.000000 0.000000 0.000000 0.000000 feature_7 0.000000 0.000000 0.000000 0.000000 0.000000 feature_8 0.035901 0.035901 0.035901 0.035901 0.035901 feature_9 0.096250 0.096250 0.096250 0.096250 0.096250 feature_10 0.000000 0.000000 0.000000 0.000000 0.000000 feature_11 0.196184 0.196184 0.196184 0.196184 0.196184 feature_12 0.011416 0.011416 0.011416 0.011416 0.011416 feature_13 0.035070 0.035070 0.035070 0.035070 0.035070 feature_14 0.090234 0.090234 0.090234 0.090234 0.090234 feature_15 0.000000 0.000000 0.000000 0.000000 0.000000 feature_16 0.264747 0.264747 0.264747 0.264747 0.264747 feature_17 0.005102 0.005102 0.005102 0.005102 0.005102 feature_18 0.032064 0.032064 0.032064 0.032064 0.032064 feature_19 0.089666 0.089666 0.089666 0.089666 0.089666 feature_20 0.264747 0.264747 0.264747 0.264747 0.264747 feature_21 0.003401 0.003401 0.003401 0.003401 0.003401 feature_22 0.031368 0.031368 0.031368 0.031368 0.031368 feature_23 0.083403 0.083403 0.083403 0.083403 0.083403 feature_24 0.000000 0.000000 0.000000 0.000000 0.000000 feature_25 0.195652 0.195652 0.195652 0.195652 0.195652 feature_26 0.009302 0.009302 0.009302 0.009302 0.009302 feature_27 0.068459 0.068459 0.068459 0.068459 0.068459 feature_28 0.085496 0.085496 0.085496 0.085496 0.085496 feature_29 0.716561 0.716561 0.716561 0.716561 0.716561 feature_30 0.265120 0.265120 0.265120 0.265120 0.265120 feature_31 0.419453 0.419453 0.419453 0.419453 0.419453 feature_32 0.120206 0.120206 0.120206 0.120206 0.120206 feature_33 0.345656 0.345656 0.345656 0.345656 0.345656 feature_34 0.000000 0.000000 0.000000 0.000000 0.000000 feature_35 0.366667 0.366667 0.366667 0.366667 0.366667 feature_36 0.000000 0.000000 0.000000 0.000000 0.000000 feature_37 0.126985 0.126985 0.126985 0.126985 0.126985 feature_38 0.226342 0.226342 0.226342 0.226342 0.226342 feature_39 0.375000 0.375000 0.375000 0.375000 0.375000 feature_40 0.000000 0.000000 0.000000 0.000000 0.000000 feature_41 0.125853 0.125853 0.125853 0.125853 0.125853 feature_42 0.224422 0.224422 0.224422 0.224422 0.224422 feature_43 0.375000 0.375000 0.375000 0.375000 0.375000 feature_44 0.000000 0.000000 0.000000 0.000000 0.000000 feature_45 0.114587 0.114587 0.114587 0.114587 0.114587 feature_46 0.343826 0.343826 0.343826 0.343826 0.343826 feature_47 0.000000 0.000000 0.000000 0.000000 0.000000 feature_48 0.384615 0.384615 0.384615 0.384615 0.384615 feature_49 0.000000 0.000000 0.000000 0.000000 0.000000 feature_50 0.108675 0.108675 0.108675 0.108675 0.108675 feature_51 0.195570 0.195570 0.195570 0.195570 0.195570 feature_52 0.600000 0.600000 0.600000 0.600000 0.600000 feature_53 0.391304 0.391304 0.391304 0.391304 0.391304 feature_54 0.333333 0.333333 0.333333 0.333333 0.333333 feature_55 0.516725 0.516725 0.518486 0.516725 0.516725 feature_56 0.550000 0.550000 0.550000 0.550000 0.550000 feature_57 0.486111 0.486111 0.138889 0.819444 0.819444 feature_58 0.000000 0.000000 0.000000 0.000000 0.000000 feature_59 0.000000 0.000000 0.000000 0.000000 0.000000 feature_60 0.000000 0.000000 0.000000 0.000000 0.000000 feature_61 0.000000 0.000000 0.000000 0.000000 0.000000 feature_62 0.000000 0.000000 0.000000 0.000000 0.000000 feature_63 0.000000 0.000000 0.000000 0.000000 0.000000 feature_64 0.000000 0.000000 0.000000 0.000000 0.000000 feature_65 0.000000 0.000000 0.000000 0.000000 0.000000 feature_66 0.000000 0.000000 0.000000 0.000000 0.000000 feature_67 0.000000 0.000000 0.000000 0.000000 0.000000 feature_68 0.000000 0.000000 0.000000 0.000000 0.000000 feature_69 0.000000 0.000000 0.000000 0.000000 0.000000 feature_70 0.000000 0.000000 0.000000 0.000000 0.000000 feature_71 0.000000 0.000000 0.000000 0.000000 0.000000 feature_72 0.000000 0.000000 0.000000 0.000000 0.000000 feature_73 0.000000 0.000000 0.000000 0.000000 0.000000 feature_74 0.000000 0.000000 0.000000 0.000000 0.000000 feature_75 0.000000 0.000000 0.000000 0.000000 0.000000 feature_76 0.000000 0.000000 0.000000 0.000000 0.000000 feature_77 0.000000 0.000000 0.000000 0.000000 0.000000 feature_78 0.000000 0.000000 0.000000 0.000000 0.000000 feature_79 0.000000 0.000000 0.000000 0.000000 0.000000 feature_80 0.000000 0.000000 0.000000 0.000000 0.000000 feature_81 0.000000 0.000000 0.000000 0.000000 0.000000 feature_82 0.000000 0.000000 0.000000 0.000000 0.000000 feature_83 0.000000 0.000000 0.000000 0.000000 0.000000 feature_84 0.000000 0.000000 0.000000 0.000000 0.000000 feature_85 0.000000 0.000000 0.000000 0.000000 0.000000 feature_86 0.000000 0.000000 0.000000 0.000000 0.000000 feature_87 0.000000 0.000000 0.000000 0.000000 0.000000 feature_88 0.000000 0.000000 0.000000 0.000000 0.000000 feature_89 0.000000 0.000000 0.000000 0.000000 0.000000 feature_90 0.000000 0.000000 0.000000 0.000000 0.000000 feature_91 0.000000 0.000000 0.000000 0.000000 0.000000 feature_92 0.000000 0.000000 0.000000 0.000000 0.000000 feature_93 0.000000 0.000000 0.000000 0.000000 0.000000 feature_94 0.000000 0.000000 0.000000 0.000000 0.000000 feature_95 0.000000 0.000000 0.000000 0.000000 0.000000 feature_96 0.000000 0.000000 0.000000 0.000000 0.000000 feature_97 0.000000 0.000000 0.000000 0.000000 0.000000 feature_98 0.000000 0.000000 0.000000 0.000000 0.000000 feature_99 0.000000 0.000000 0.000000 0.000000 0.000000 feature_100 0.000000 0.000000 0.000000 0.000000 0.000000 feature_101 0.000000 0.000000 0.000000 0.000000 0.000000 feature_102 0.000000 0.000000 0.000000 0.000000 0.000000 feature_103 0.000000 0.000000 0.000000 0.000000 0.000000 feature_104 0.000000 0.000000 0.000000 0.000000 0.000000 feature_105 0.000000 0.000000 0.000000 0.000000 0.000000 feature_106 0.000000 0.000000 0.000000 0.000000 0.000000 feature_107 0.000000 0.000000 0.000000 0.000000 0.000000 feature_108 0.000000 0.000000 0.000000 0.000000 0.000000 feature_109 0.000000 0.000000 0.000000 0.000000 0.000000 feature_110 0.000000 0.000000 0.000000 0.000000 0.000000 feature_111 0.000000 0.000000 0.000000 0.000000 0.000000 feature_112 0.000000 0.000000 0.000000 0.000000 0.000000 feature_113 0.000000 0.000000 0.000000 0.000000 0.000000 feature_114 0.000000 0.000000 0.000000 0.000000 0.000000 feature_115 0.000000 0.000000 0.000000 0.000000 0.000000 feature_116 0.000000 0.000000 0.000000 0.000000 0.000000 feature_117 0.000000 0.000000 0.000000 0.000000 0.000000 feature_118 0.000000 0.000000 0.000000 0.000000 0.000000 feature_119 0.000000 0.000000 0.000000 0.000000 0.000000 feature_120 0.000000 0.000000 0.000000 0.000000 0.000000 feature_121 0.000000 0.000000 0.000000 0.000000 0.000000 feature_122 0.000000 0.000000 0.000000 0.000000 0.000000 feature_123 0.000000 0.000000 0.000000 0.000000 0.000000 feature_124 0.000000 0.000000 0.000000 0.000000 0.000000 feature_125 0.000000 0.000000 0.000000 0.000000 0.000000 feature_126 0.000000 0.000000 0.000000 0.000000 0.000000 feature_127 0.000000 0.000000 0.000000 0.000000 0.000000 feature_128 0.000000 0.000000 0.000000 0.000000 0.000000 feature_129 0.000000 0.000000 0.000000 0.000000 0.000000 feature_130 0.000000 0.000000 0.000000 0.000000 0.000000 feature_131 0.000000 0.000000 0.000000 0.000000 0.000000 feature_132 0.000000 0.000000 0.000000 0.000000 0.000000 feature_133 0.000000 0.000000 0.000000 0.000000 0.000000 feature_134 0.000000 0.000000 0.000000 0.000000 0.000000 feature_135 0.000000 0.000000 0.000000 0.000000 0.000000 feature_136 0.000000 0.000000 0.000000 0.000000 0.000000 feature_137 0.000000 0.000000 0.000000 0.000000 0.000000 feature_138 0.000000 0.000000 0.000000 0.000000 0.000000 feature_139 0.000000 0.000000 0.000000 0.000000 0.000000 feature_140 0.000000 0.000000 0.000000 0.000000 0.000000 feature_141 0.000000 0.000000 0.000000 0.000000 0.000000 feature_142 0.000000 0.000000 0.000000 0.000000 0.000000 feature_143 0.000000 0.000000 0.000000 0.000000 0.000000 feature_144 0.000000 0.000000 0.000000 0.000000 0.000000 feature_145 0.000000 0.000000 0.000000 0.000000 0.000000 feature_146 0.000000 0.000000 0.000000 0.000000 0.000000 feature_147 0.000000 0.000000 0.000000 0.000000 0.000000 feature_148 0.000000 0.000000 0.000000 0.000000 0.000000 feature_149 0.000000 0.000000 0.000000 0.000000 0.000000 feature_150 0.000000 0.000000 0.000000 0.000000 0.000000 feature_151 0.000000 0.000000 0.000000 0.000000 0.000000 feature_152 0.000000 0.000000 0.000000 0.000000 0.000000 feature_153 0.000000 0.000000 0.000000 0.000000 0.000000 feature_154 0.000000 0.000000 0.000000 0.000000 0.000000 feature_155 0.000000 0.000000 0.000000 0.000000 0.000000 feature_156 0.000000 0.000000 0.000000 0.000000 0.000000 feature_157 0.000000 0.000000 0.000000 0.000000 0.000000 feature_158 0.000000 0.000000 0.000000 0.000000 0.000000 feature_159 0.000000 0.000000 0.000000 0.000000 0.000000 feature_160 0.000000 0.000000 0.000000 0.000000 0.000000 feature_161 0.000000 0.000000 0.000000 0.000000 0.000000 feature_162 0.000000 0.000000 0.000000 0.000000 0.000000 feature_163 0.000000 0.000000 0.000000 0.000000 0.000000 feature_164 0.000000 0.000000 0.000000 0.000000 0.000000 feature_165 0.000000 0.000000 0.000000 0.000000 0.000000 feature_166 0.000000 0.000000 0.000000 0.000000 0.000000 feature_167 0.000000 0.000000 0.000000 0.000000 0.000000 feature_168 0.000000 0.000000 0.000000 0.000000 0.000000 feature_169 0.000000 0.000000 0.000000 0.000000 0.000000 feature_170 0.000000 0.000000 0.000000 0.000000 0.000000 feature_171 0.000000 0.000000 0.000000 0.000000 0.000000 feature_172 0.000000 0.000000 0.000000 0.000000 0.000000 feature_173 0.000000 0.000000 0.000000 0.000000 0.000000 feature_174 0.000000 0.000000 0.000000 0.000000 0.000000 feature_175 0.000000 0.000000 0.000000 0.000000 0.000000 feature_176 0.000000 0.000000 0.000000 0.000000 0.000000 feature_177 0.000000 0.000000 0.000000 0.000000 0.000000 feature_178 0.000000 0.000000 0.000000 0.000000 0.000000 feature_179 0.000000 0.000000 0.000000 0.000000 0.000000 feature_180 0.000000 0.000000 0.000000 0.000000 0.000000 feature_181 0.000000 0.000000 0.000000 0.000000 0.000000 feature_182 0.000000 0.000000 0.000000 0.000000 0.000000 feature_183 0.000000 0.000000 0.000000 0.000000 0.000000 feature_184 0.000000 0.000000 0.000000 0.000000 0.000000 feature_185 0.000000 0.000000 0.000000 0.000000 0.000000 feature_186 0.000000 0.000000 0.000000 0.000000 0.000000 feature_187 0.000000 0.000000 0.000000 0.000000 0.000000 feature_188 0.000000 0.000000 0.000000 0.000000 0.000000 feature_189 0.000000 0.000000 0.000000 0.000000 0.000000 feature_190 0.000000 0.000000 0.000000 0.000000 0.000000 feature_191 0.000000 0.000000 0.000000 0.000000 0.000000 feature_192 0.000000 0.000000 0.000000 0.000000 0.000000 feature_193 0.000000 0.000000 0.000000 0.000000 0.000000 feature_194 0.000000 0.000000 0.000000 0.000000 0.000000 feature_195 0.000000 0.000000 0.000000 0.000000 0.000000 feature_196 0.000000 0.000000 0.000000 0.000000 0.000000 feature_197 0.000000 0.000000 0.000000 0.000000 0.000000 feature_198 0.000000 0.000000 0.000000 0.000000 0.000000 feature_199 0.000000 0.000000 0.000000 0.000000 0.000000 feature_200 0.000000 0.000000 0.000000 0.000000 0.000000 feature_201 0.000000 0.000000 0.000000 0.000000 0.000000 feature_202 0.000000 0.000000 0.000000 0.000000 0.000000 feature_203 0.000000 0.000000 0.000000 0.000000 0.000000 feature_204 0.000000 0.000000 0.000000 0.000000 0.000000 feature_205 0.000000 0.000000 0.000000 0.000000 0.000000 feature_206 0.000000 0.000000 0.000000 0.000000 0.000000 feature_207 0.000000 0.000000 0.000000 0.000000 0.000000 feature_208 0.000000 0.000000 0.000000 0.000000 0.000000 feature_209 0.000000 0.000000 0.000000 0.000000 0.000000 feature_210 0.000000 0.000000 0.000000 0.000000 0.000000 feature_211 0.000000 0.000000 0.000000 0.000000 0.000000 feature_212 0.000000 0.000000 0.000000 0.000000 0.000000 feature_213 0.000000 0.000000 0.000000 0.000000 0.000000 feature_214 0.000000 0.000000 0.000000 0.000000 0.000000 feature_215 0.000000 0.000000 0.000000 0.000000 0.000000 feature_216 0.000000 0.000000 0.000000 0.000000 0.000000 feature_217 0.000000 0.000000 0.000000 0.000000 0.000000 feature_218 0.000000 0.000000 0.000000 0.000000 0.000000 feature_219 0.000000 0.000000 0.000000 0.000000 0.000000 feature_220 0.000000 0.000000 0.000000 0.000000 0.000000 feature_221 0.000000 0.000000 0.000000 0.000000 0.000000 feature_222 0.000000 0.000000 0.000000 0.000000 0.000000 feature_223 0.000000 0.000000 0.000000 0.000000 0.000000 feature_224 0.000000 0.000000 0.000000 0.000000 0.000000 feature_225 0.000000 0.000000 0.000000 0.000000 0.000000 feature_226 0.000000 0.000000 0.000000 0.000000 0.000000 feature_227 0.000000 0.000000 0.000000 0.000000 0.000000 feature_228 0.000000 0.000000 0.000000 0.000000 0.000000 feature_229 0.000000 0.000000 0.000000 0.000000 0.000000 feature_230 0.000000 0.000000 0.000000 0.000000 0.000000 feature_231 0.000000 0.000000 0.000000 0.000000 0.000000 feature_232 0.000000 0.000000 0.000000 0.000000 0.000000 feature_233 0.000000 0.000000 0.000000 0.000000 0.000000 feature_234 0.000000 0.000000 0.000000 0.000000 0.000000 feature_235 0.000000 0.000000 0.000000 0.000000 0.000000 feature_236 0.000000 0.000000 0.000000 0.000000 0.000000 feature_237 0.000000 0.000000 0.000000 0.000000 0.000000 feature_238 0.000000 0.000000 0.000000 0.000000 0.000000 feature_239 0.000000 0.000000 0.000000 0.000000 0.000000 feature_240 0.000000 0.000000 0.000000 0.000000 0.000000 feature_241 0.000000 0.000000 0.000000 0.000000 0.000000 feature_242 0.000000 0.000000 0.000000 0.000000 0.000000 feature_243 0.000000 0.000000 0.000000 0.000000 0.000000 feature_244 0.000000 0.000000 0.000000 0.000000 0.000000 feature_245 0.000000 0.000000 0.000000 0.000000 0.000000 feature_246 0.000000 0.000000 0.000000 0.000000 0.000000 feature_247 0.000000 0.000000 0.000000 0.000000 0.000000 feature_248 0.000000 0.000000 0.000000 0.000000 0.000000 feature_249 0.000000 0.000000 0.000000 0.000000 0.000000 feature_250 0.000000 0.000000 0.000000 0.000000 0.000000 feature_251 0.000000 0.000000 0.000000 0.000000 0.000000 feature_252 0.000000 0.000000 0.000000 0.000000 0.000000 feature_253 0.000000 0.000000 0.000000 0.000000 0.000000 feature_254 0.000000 0.000000 0.000000 0.000000 0.000000 feature_255 0.000000 0.000000 0.000000 0.000000 0.000000 feature_256 0.000000 0.000000 0.000000 0.000000 0.000000 feature_257 0.000000 0.000000 0.000000 0.000000 0.000000 feature_258 0.000000 0.000000 0.000000 0.000000 0.000000 feature_259 0.000000 0.000000 0.000000 0.000000 0.000000 feature_260 0.000000 0.000000 0.000000 0.000000 0.000000 feature_261 0.000000 0.000000 0.000000 0.000000 0.000000 feature_262 0.000000 0.000000 0.000000 0.000000 0.000000 feature_263 1.000000 1.000000 1.000000 0.000000 0.000000 feature_264 0.000000 0.000000 0.000000 1.000000 1.000000 feature_265 0.000000 0.000000 0.000000 0.000000 0.000000 feature_266 0.000000 0.000000 0.000000 0.000000 0.000000 feature_267 0.000000 0.000000 0.000000 0.000000 0.000000 feature_268 1.000000 1.000000 0.000000 1.000000 1.000000 feature_269 0.000000 0.000000 1.000000 0.000000 0.000000 feature_270 0.000000 0.000000 0.000000 0.000000 0.000000 feature_271 0.000000 0.000000 0.000000 0.000000 0.000000 feature_272 0.000000 0.000000 0.000000 0.000000 0.000000 feature_273 0.000000 0.000000 0.000000 0.000000 0.000000 feature_274 0.000000 0.000000 0.000000 0.000000 0.000000 feature_275 0.000000 0.000000 0.000000 0.000000 0.000000 ground_truth 0.000000 0.000000 0.125000 0.000000 0.000000"},{"location":"experiments/Blog/#hyperparameter-search","title":"Hyperparameter search","text":"<p>The choice of the batch size and the maximum number of epochs depends on the dataset size. For this dataset, we use the following values:</p> <pre><code>batch_size = 256\nmax_epochs = 30\n</code></pre> <p>We use the Type-2 architecture built using <code>MonoDense</code> layer with the following set of hyperparameters ranges:</p> <pre><code>def hp_params_f(hp):\n    return dict(\n        units=hp.Int(\"units\", min_value=16, max_value=32, step=1),\n        n_layers=hp.Int(\"n_layers\", min_value=2, max_value=2),\n        activation=hp.Choice(\"activation\", values=[\"elu\"]),\n        learning_rate=hp.Float(\n            \"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\"\n        ),\n        weight_decay=hp.Float(\n            \"weight_decay\", min_value=3e-2, max_value=0.3, sampling=\"log\"\n        ),\n        dropout=hp.Float(\"dropout\", min_value=0.0, max_value=0.5, sampling=\"linear\"),\n        decay_rate=hp.Float(\n            \"decay_rate\", min_value=0.8, max_value=1.0, sampling=\"reverse_log\"\n        ),\n    )\n</code></pre> <p>The following fixed parameters are used to build the Type-2 architecture for this dataset:</p> <ul> <li> <p><code>final_activation</code> is used to build the final layer for regression   problem (set to <code>None</code>) or for the classification problem   (<code>\"sigmoid\"</code>),</p> </li> <li> <p><code>loss</code> is used for training regression (<code>\"mse\"</code>) or classification   (<code>\"binary_crossentropy\"</code>) problem, and</p> </li> <li> <p><code>metrics</code> denotes metrics used to compare with previosly published   results: <code>\"accuracy\"</code> for classification and \u201c<code>mse</code>\u201d or \u201c<code>rmse</code>\u201d for   regression.</p> </li> </ul> <p>Parameters <code>objective</code> and <code>direction</code> are used by the tuner such that <code>objective=f\"val_{metrics}\"</code> and direction is either <code>\"min</code> or <code>\"max\"</code>.</p> <p>Parameters <code>max_trials</code> denotes the number of trial performed buy the tuner, <code>patience</code> is the number of epochs allowed to perform worst than the best one before stopping the current trial. The parameter <code>execution_per_trial</code> denotes the number of runs before calculating the results of a trial, it should be set to value greater than 1 for small datasets that have high variance in results.</p> <pre><code>final_activation = None\nloss = \"mse\"\nmetrics = tf.keras.metrics.RootMeanSquaredError()\nobjective = \"val_root_mean_squared_error\"\ndirection = \"min\"\nmax_trials = 50\nexecutions_per_trial = 1\npatience = 10\n</code></pre> <p>The following table describes the best models and their hyperparameters found by the tuner:</p>"},{"location":"experiments/Blog/#the-optimal-model","title":"The optimal model","text":"<p>These are the best hyperparameters found by previous runs of the tuner:</p> <pre><code>def final_hp_params_f(hp):\n    return dict(\n        units=hp.Fixed(\"units\", value=4),\n        n_layers=hp.Fixed(\"n_layers\", 2),\n        activation=hp.Fixed(\"activation\", value=\"elu\"),\n        learning_rate=hp.Fixed(\"learning_rate\", value=0.01),\n        weight_decay=hp.Fixed(\"weight_decay\", value=0.0),\n        dropout=hp.Fixed(\"dropout\", value=0.0),\n        decay_rate=hp.Fixed(\"decay_rate\", value=0.95),\n    )\n</code></pre> <p>The final evaluation of the optimal model:</p> 0 units 4 n_layers 2 activation elu learning_rate 0.010000 weight_decay 0.000000 dropout 0.000000 decay_rate 0.950000 val_root_mean_squared_error_mean 0.154109 val_root_mean_squared_error_std 0.000568 val_root_mean_squared_error_min 0.153669 val_root_mean_squared_error_max 0.154894 params 1665"},{"location":"experiments/Compas/","title":"COMPAS","text":""},{"location":"experiments/Compas/#running-in-google-colab","title":"Running in Google Colab","text":"<p>You can run this experiment in Google Colab by clicking the button below:</p> <p> </p>"},{"location":"experiments/Compas/#dataset","title":"Dataset","text":"<p>COMPAS [1] is a dataset containing the criminal records of 6,172 individuals arrested in Florida. The task is to predict whether the individual will commit a crime again in 2 years. The probability predicted by the system will be used as a risk score. As mentioned in [2] 13 attributes for prediction. The risk score should be monotonically increasing w.r.t. four attributes, number of prior adult convictions, number of juvenile felony, number of juvenile misdemeanor, and number of other convictions. The <code>monotonicity_indicator</code> corrsponding to these features are set to 1.</p> <p>References:</p> <ol> <li> <p>S. Mattu J. Angwin, J. Larson and L. Kirchner. Machine bias: There\u2019s     software used across the country to predict future criminals. and     it\u2019s biased against blacks. ProPublica, 2016.</p> </li> <li> <p>Xingchao Liu, Xing Han, Na Zhang, and Qiang Liu. Certified monotonic     neural networks. Advances in Neural Information Processing Systems,     33:15427\u201315438, 2020</p> </li> </ol> <pre><code>monotonicity_indicator = {\n    \"priors_count\": 1,\n    \"juv_fel_count\": 1,\n    \"juv_misd_count\": 1,\n    \"juv_other_count\": 1,\n    \"age\": 0,\n    \"race_0\": 0,\n    \"race_1\": 0,\n    \"race_2\": 0,\n    \"race_3\": 0,\n    \"race_4\": 0,\n    \"race_5\": 0,\n    \"sex_0\": 0,\n    \"sex_1\": 0,\n}\n</code></pre> <p>These are a few examples of the dataset:</p> 0 1 2 3 4 priors_count 0.368421 0.000000 0.026316 0.394737 0.052632 juv_fel_count 0.000000 0.000000 0.000000 0.000000 0.000000 juv_misd_count 0.000000 0.000000 0.000000 0.000000 0.000000 juv_other_count 0.000000 0.000000 0.000000 0.000000 0.000000 age 0.230769 0.051282 0.179487 0.230769 0.102564 race_0 1.000000 1.000000 0.000000 1.000000 1.000000 race_1 0.000000 0.000000 1.000000 0.000000 0.000000 race_2 0.000000 0.000000 0.000000 0.000000 0.000000 race_3 0.000000 0.000000 0.000000 0.000000 0.000000 race_4 0.000000 0.000000 0.000000 0.000000 0.000000 race_5 0.000000 0.000000 0.000000 0.000000 0.000000 sex_0 1.000000 1.000000 1.000000 1.000000 1.000000 sex_1 0.000000 0.000000 0.000000 0.000000 0.000000 ground_truth 1.000000 0.000000 0.000000 0.000000 1.000000"},{"location":"experiments/Compas/#hyperparameter-search","title":"Hyperparameter search","text":"<p>The choice of the batch size and the maximum number of epochs depends on the dataset size. For this dataset, we use the following values:</p> <pre><code>batch_size = 8\nmax_epochs = 50\n</code></pre> <p>We use the Type-2 architecture built using <code>MonoDense</code> layer with the following set of hyperparameters ranges:</p> <pre><code>def hp_params_f(hp):\n    return dict(\n        units=hp.Int(\"units\", min_value=16, max_value=32, step=1),\n        n_layers=hp.Int(\"n_layers\", min_value=2, max_value=2),\n        activation=hp.Choice(\"activation\", values=[\"elu\"]),\n        learning_rate=hp.Float(\n            \"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\"\n        ),\n        weight_decay=hp.Float(\n            \"weight_decay\", min_value=3e-2, max_value=0.3, sampling=\"log\"\n        ),\n        dropout=hp.Float(\"dropout\", min_value=0.0, max_value=0.5, sampling=\"linear\"),\n        decay_rate=hp.Float(\n            \"decay_rate\", min_value=0.8, max_value=1.0, sampling=\"reverse_log\"\n        ),\n    )\n</code></pre> <p>The following fixed parameters are used to build the Type-2 architecture for this dataset:</p> <ul> <li> <p><code>final_activation</code> is used to build the final layer for regression   problem (set to <code>None</code>) or for the classification problem   (<code>\"sigmoid\"</code>),</p> </li> <li> <p><code>loss</code> is used for training regression (<code>\"mse\"</code>) or classification   (<code>\"binary_crossentropy\"</code>) problem, and</p> </li> <li> <p><code>metrics</code> denotes metrics used to compare with previosly published   results: <code>\"accuracy\"</code> for classification and \u201c<code>mse</code>\u201d or \u201c<code>rmse</code>\u201d for   regression.</p> </li> </ul> <p>Parameters <code>objective</code> and <code>direction</code> are used by the tuner such that <code>objective=f\"val_{metrics}\"</code> and direction is either <code>\"min</code> or <code>\"max\"</code>.</p> <p>Parameters <code>max_trials</code> denotes the number of trial performed buy the tuner, <code>patience</code> is the number of epochs allowed to perform worst than the best one before stopping the current trial. The parameter <code>execution_per_trial</code> denotes the number of runs before calculating the results of a trial, it should be set to value greater than 1 for small datasets that have high variance in results.</p> <pre><code>final_activation = \"sigmoid\"\nloss = \"binary_crossentropy\"\nmetrics = \"accuracy\"\nobjective = \"val_accuracy\"\ndirection = \"max\"\nmax_trials = 50\nexecutions_per_trial = 1\npatience = 5\n</code></pre> <p>The following table describes the best models and their hyperparameters found by the tuner:</p> 0 1 2 3 4 units 27 28 26 31 25 n_layers 2 3 2 3 2 activation elu elu elu elu elu learning_rate 0.084685 0.105227 0.086301 0.018339 0.069011 weight_decay 0.137518 0.120702 0.147297 0.105921 0.153525 dropout 0.175917 0.160270 0.162063 0.480390 0.180772 decay_rate 0.899399 0.872222 0.927282 0.964135 0.874505 val_accuracy_mean 0.694413 0.693603 0.692955 0.692308 0.692146 val_accuracy_std 0.003464 0.000923 0.002710 0.002217 0.002649 val_accuracy_min 0.689879 0.692308 0.689069 0.689069 0.689879 val_accuracy_max 0.698785 0.694737 0.695547 0.694737 0.696356 params 2317 3599 2237 4058 2157"},{"location":"experiments/Compas/#the-optimal-model","title":"The optimal model","text":"<p>These are the best hyperparameters found by previous runs of the tuner:</p> <pre><code>def final_hp_params_f(hp):\n    return dict(\n        units=hp.Fixed(\"units\", value=27),\n        n_layers=hp.Fixed(\"n_layers\", 2),\n        activation=hp.Fixed(\"activation\", value=\"elu\"),\n        learning_rate=hp.Fixed(\"learning_rate\", value=0.084685),\n        weight_decay=hp.Fixed(\"weight_decay\", value=0.137518),\n        dropout=hp.Fixed(\"dropout\", value=0.175917),\n        decay_rate=hp.Fixed(\"decay_rate\", value=0.899399),\n    )\n</code></pre> <p>The final evaluation of the optimal model:</p> 0 units 27 n_layers 2 activation elu learning_rate 0.084685 weight_decay 0.137518 dropout 0.175917 decay_rate 0.899399 val_accuracy_mean 0.691660 val_accuracy_std 0.001056 val_accuracy_min 0.690688 val_accuracy_max 0.693117 params 2317"},{"location":"experiments/Heart/","title":"Heart disease","text":""},{"location":"experiments/Heart/#running-in-google-colab","title":"Running in Google Colab","text":"<p>You can run this experiment in Google Colab by clicking the button below:</p> <p> </p>"},{"location":"experiments/Heart/#dataset","title":"Dataset","text":"<p>Heart Disease [1] is a classification dataset used for predicting the presence of heart disease with 13 features:</p> <ul> <li> <p>age</p> </li> <li> <p>sex</p> </li> <li> <p>cp</p> </li> <li> <p>trestbps</p> </li> <li> <p>chol</p> </li> <li> <p>fbs</p> </li> <li> <p>restecg</p> </li> <li> <p>thalach</p> </li> <li> <p>exang</p> </li> <li> <p>oldpeak</p> </li> <li> <p>slope</p> </li> <li> <p>ca</p> </li> <li> <p>thal</p> </li> </ul> <p>The dependant variable is monotonically increasing with respect to features <code>trestbps</code> and cholestrol (<code>chol</code>). The <code>monotonicity_indicator</code> corrsponding to these features are set to 1.</p> <p>References:</p> <ol> <li> <p>John H. Gennari, Pat Langley, and Douglas H. Fisher. Models of     incremental concept formation. Artif. Intell., 40(1-3):11\u201361, 1989.</p> <p>https://archive.ics.uci.edu/ml/datasets/heart+disease</p> </li> <li> <p>Aishwarya Sivaraman, Golnoosh Farnadi, Todd Millstein, and Guy Van     den Broeck. Counterexample-guided learning of monotonic neural     networks. Advances in Neural Information Processing Systems,     33:11936\u201311948, 2020</p> </li> </ol> <pre><code>monotonicity_indicator = {\n    \"age\": 0,\n    \"sex\": 0,\n    \"cp\": 0,\n    \"trestbps\": 1,\n    \"chol\": 1,\n    \"fbs\": 0,\n    \"restecg\": 0,\n    \"thalach\": 0,\n    \"exang\": 0,\n    \"oldpeak\": 0,\n    \"slope\": 0,\n    \"ca\": 0,\n    \"thal\": 0,\n}\n</code></pre> <p>These are a few examples of the dataset:</p> 0 1 2 3 4 age 0.972778 1.415074 1.415074 -1.902148 -1.459852 sex 0.649445 0.649445 0.649445 0.649445 -1.533413 cp -2.020077 0.884034 0.884034 -0.084003 -1.052040 trestbps 0.721008 1.543527 -0.649858 -0.101512 -0.101512 chol -0.251855 0.740555 -0.326754 0.066465 -0.794872 fbs 2.426901 -0.410346 -0.410346 -0.410346 -0.410346 restecg 1.070838 1.070838 1.070838 -0.953715 1.070838 thalach -0.025055 -1.831151 -0.928103 1.566030 0.920995 exang -0.721010 1.381212 1.381212 -0.721010 -0.721010 oldpeak 0.986440 0.330395 1.232457 1.970508 0.248389 slope 2.334348 0.687374 0.687374 2.334348 -0.959601 ca -0.770198 2.425024 1.359950 -0.770198 -0.770198 thal -2.070238 -0.514345 1.041548 -0.514345 -0.514345 ground_truth 0.000000 1.000000 0.000000 0.000000 0.000000"},{"location":"experiments/Heart/#hyperparameter-search","title":"Hyperparameter search","text":"<p>The choice of the batch size and the maximum number of epochs depends on the dataset size. For this dataset, we use the following values:</p> <pre><code>batch_size = 16\nmax_epochs = 50\n</code></pre> <p>We use the Type-2 architecture built using <code>MonoDense</code> layer with the following set of hyperparameters ranges:</p> <pre><code>def hp_params_f(hp):\n    return dict(\n        units=hp.Int(\"units\", min_value=16, max_value=32, step=1),\n        n_layers=hp.Int(\"n_layers\", min_value=2, max_value=2),\n        activation=hp.Choice(\"activation\", values=[\"elu\"]),\n        learning_rate=hp.Float(\n            \"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\"\n        ),\n        weight_decay=hp.Float(\n            \"weight_decay\", min_value=3e-2, max_value=0.3, sampling=\"log\"\n        ),\n        dropout=hp.Float(\"dropout\", min_value=0.0, max_value=0.5, sampling=\"linear\"),\n        decay_rate=hp.Float(\n            \"decay_rate\", min_value=0.8, max_value=1.0, sampling=\"reverse_log\"\n        ),\n    )\n</code></pre> <p>The following fixed parameters are used to build the Type-2 architecture for this dataset:</p> <ul> <li> <p><code>final_activation</code> is used to build the final layer for regression   problem (set to <code>None</code>) or for the classification problem   (<code>\"sigmoid\"</code>),</p> </li> <li> <p><code>loss</code> is used for training regression (<code>\"mse\"</code>) or classification   (<code>\"binary_crossentropy\"</code>) problem, and</p> </li> <li> <p><code>metrics</code> denotes metrics used to compare with previosly published   results: <code>\"accuracy\"</code> for classification and \u201c<code>mse</code>\u201d or \u201c<code>rmse</code>\u201d for   regression.</p> </li> </ul> <p>Parameters <code>objective</code> and <code>direction</code> are used by the tuner such that <code>objective=f\"val_{metrics}\"</code> and direction is either <code>\"min</code> or <code>\"max\"</code>.</p> <p>Parameters <code>max_trials</code> denotes the number of trial performed buy the tuner, <code>patience</code> is the number of epochs allowed to perform worst than the best one before stopping the current trial. The parameter <code>execution_per_trial</code> denotes the number of runs before calculating the results of a trial, it should be set to value greater than 1 for small datasets that have high variance in results.</p> <pre><code>final_activation = \"sigmoid\"\nloss = \"binary_crossentropy\"\nmetrics = \"accuracy\"\nobjective = \"val_accuracy\"\ndirection = \"max\"\nmax_trials = 200\nexecutions_per_trial = 3\npatience = 5\n</code></pre> <p>The following table describes the best models and their hyperparameters found by the tuner:</p> 0 1 2 3 4 units 22 18 23 23 21 n_layers 2 2 2 2 2 activation elu elu elu elu elu learning_rate 0.001000 0.001000 0.001328 0.001000 0.001000 weight_decay 0.113929 0.122019 0.111481 0.139452 0.140732 dropout 0.397874 0.460844 0.405396 0.424631 0.418484 decay_rate 0.894921 0.921600 0.901050 0.897339 0.889619 val_accuracy_mean 0.885246 0.885246 0.881967 0.881967 0.878689 val_accuracy_std 0.000000 0.000000 0.007331 0.007331 0.008979 val_accuracy_min 0.885246 0.885246 0.868852 0.868852 0.868852 val_accuracy_max 0.885246 0.885246 0.885246 0.885246 0.885246 params 1605 1077 1672 1672 1538"},{"location":"experiments/Heart/#the-optimal-model","title":"The optimal model","text":"<p>These are the best hyperparameters found by previous runs of the tuner:</p> <pre><code>def final_hp_params_f(hp):\n    return dict(\n        units=hp.Fixed(\"units\", value=22),\n        n_layers=hp.Fixed(\"n_layers\", 2),\n        activation=hp.Fixed(\"activation\", value=\"elu\"),\n        learning_rate=hp.Fixed(\"learning_rate\", value=0.001),\n        weight_decay=hp.Fixed(\"weight_decay\", value=0.113929),\n        dropout=hp.Fixed(\"dropout\", value=0.397874),\n        decay_rate=hp.Fixed(\"decay_rate\", value=0.894921),\n    )\n</code></pre> <p>The final evaluation of the optimal model:</p> 0 units 22 n_layers 2 activation elu learning_rate 0.001000 weight_decay 0.113929 dropout 0.397874 decay_rate 0.894921 val_accuracy_mean 0.885246 val_accuracy_std 0.000000 val_accuracy_min 0.885246 val_accuracy_max 0.885246 params 1605"},{"location":"experiments/Loan/","title":"Loan","text":""},{"location":"experiments/Loan/#running-in-google-colab","title":"Running in Google Colab","text":"<p>You can run this experiment in Google Colab by clicking the button below:</p> <p> </p>"},{"location":"experiments/Loan/#dataset","title":"Dataset","text":"<p>Lending club loan data contains complete loan data for all loans issued through 2007-2015 of several banks. Each data point is a 28-dimensional feature including the current loan status, latest payment information, and other additional features. The task is to predict loan defaulters given the feature vector. The possibility of loan default should be nondecreasing w.r.t. number of public record bankruptcies, Debt-to-Income ratio, and non-increasing w.r.t. credit score, length of employment, annual income. Thus the <code>monotonicity_indicator</code> corrsponding to these features are set to 1.</p> <p>References:</p> <ol> <li>https://www.kaggle.com/wendykan/lending-club-loan-data (Note:     Currently, the dataset seems to be withdrawn from kaggle)</li> </ol> <pre><code>monotonicity_indicator = {\n    f\"feature_{i}\": mi for i, mi in enumerate([-1, 1, -1, -1, 1] + [0] * 23)\n}\n</code></pre> <p>These are a few examples of the dataset:</p> 0 1 2 3 4 feature_0 0.833333 1.000000 0.666667 0.333333 0.666667 feature_1 0.000000 0.000000 0.000000 0.000000 0.000000 feature_2 0.400000 1.000000 0.800000 0.500000 0.700000 feature_3 0.005263 0.003474 0.005263 0.007158 0.006842 feature_4 0.005185 0.023804 0.029700 0.024434 0.021962 feature_5 0.185751 0.134860 0.236641 0.745547 0.440204 feature_6 0.240654 0.036215 0.271807 0.778037 0.260125 feature_7 0.000000 0.000000 0.000000 1.000000 0.000000 feature_8 0.000000 0.000000 0.000000 0.000000 0.000000 feature_9 0.000000 0.000000 1.000000 0.000000 1.000000 feature_10 0.000000 0.000000 0.000000 0.000000 0.000000 feature_11 0.000000 0.000000 0.000000 0.000000 0.000000 feature_12 0.000000 1.000000 0.000000 0.000000 0.000000 feature_13 1.000000 0.000000 0.000000 1.000000 0.000000 feature_14 0.000000 0.000000 0.000000 0.000000 0.000000 feature_15 1.000000 1.000000 1.000000 0.000000 1.000000 feature_16 0.000000 0.000000 0.000000 1.000000 0.000000 feature_17 0.000000 0.000000 0.000000 0.000000 0.000000 feature_18 0.000000 0.000000 0.000000 0.000000 0.000000 feature_19 0.000000 0.000000 0.000000 0.000000 0.000000 feature_20 0.000000 0.000000 0.000000 0.000000 0.000000 feature_21 0.000000 0.000000 0.000000 0.000000 0.000000 feature_22 0.000000 0.000000 0.000000 0.000000 0.000000 feature_23 0.000000 0.000000 0.000000 0.000000 0.000000 feature_24 0.000000 0.000000 0.000000 0.000000 0.000000 feature_25 0.000000 0.000000 0.000000 0.000000 0.000000 feature_26 0.000000 0.000000 0.000000 0.000000 0.000000 feature_27 0.000000 0.000000 0.000000 0.000000 0.000000 ground_truth 0.000000 0.000000 0.000000 0.000000 0.000000"},{"location":"experiments/Loan/#hyperparameter-search","title":"Hyperparameter search","text":"<p>The choice of the batch size and the maximum number of epochs depends on the dataset size. For this dataset, we use the following values:</p> <pre><code>batch_size = 256\nmax_epochs = 20\n</code></pre> <p>We use the Type-2 architecture built using <code>MonoDense</code> layer with the following set of hyperparameters ranges:</p> <pre><code>def hp_params_f(hp):\n    return dict(\n        units=hp.Int(\"units\", min_value=4, max_value=32, step=1),\n        n_layers=hp.Int(\"n_layers\", min_value=1, max_value=2),\n        activation=hp.Choice(\"activation\", values=[\"elu\"]),\n        learning_rate=hp.Float(\n            \"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\"\n        ),\n        weight_decay=hp.Float(\n            \"weight_decay\", min_value=3e-2, max_value=0.3, sampling=\"log\"\n        ),\n        dropout=hp.Float(\"dropout\", min_value=0.0, max_value=0.5, sampling=\"linear\"),\n        decay_rate=hp.Float(\n            \"decay_rate\", min_value=0.8, max_value=1.0, sampling=\"reverse_log\"\n        ),\n    )\n</code></pre> <p>The following fixed parameters are used to build the Type-2 architecture for this dataset:</p> <ul> <li> <p><code>final_activation</code> is used to build the final layer for regression   problem (set to <code>None</code>) or for the classification problem   (<code>\"sigmoid\"</code>),</p> </li> <li> <p><code>loss</code> is used for training regression (<code>\"mse\"</code>) or classification   (<code>\"binary_crossentropy\"</code>) problem, and</p> </li> <li> <p><code>metrics</code> denotes metrics used to compare with previosly published   results: <code>\"accuracy\"</code> for classification and \u201c<code>mse</code>\u201d or \u201c<code>rmse</code>\u201d for   regression.</p> </li> </ul> <p>Parameters <code>objective</code> and <code>direction</code> are used by the tuner such that <code>objective=f\"val_{metrics}\"</code> and direction is either <code>\"min</code> or <code>\"max\"</code>.</p> <p>Parameters <code>max_trials</code> denotes the number of trial performed buy the tuner, <code>patience</code> is the number of epochs allowed to perform worst than the best one before stopping the current trial. The parameter <code>execution_per_trial</code> denotes the number of runs before calculating the results of a trial, it should be set to value greater than 1 for small datasets that have high variance in results.</p> <pre><code>final_activation = None\nloss = \"binary_crossentropy\"\nmetrics = \"accuracy\"\nobjective = \"val_accuracy\"\ndirection = \"max\"\nmax_trials = 50\nexecutions_per_trial = 1\npatience = 5\n</code></pre> <p>The following table describes the best models and their hyperparameters found by the tuner:</p>"},{"location":"experiments/Loan/#the-optimal-model","title":"The optimal model","text":"<p>These are the best hyperparameters found by previous runs of the tuner:</p> <pre><code>def final_hp_params_f(hp):\n    return dict(\n        units=hp.Fixed(\"units\", value=8),\n        n_layers=hp.Fixed(\"n_layers\", 2),\n        activation=hp.Fixed(\"activation\", value=\"elu\"),\n        learning_rate=hp.Fixed(\"learning_rate\", value=0.008),\n        weight_decay=hp.Fixed(\"weight_decay\", value=0.0),\n        dropout=hp.Fixed(\"dropout\", value=0.0),\n        decay_rate=hp.Fixed(\"decay_rate\", value=1.0),\n    )\n</code></pre> <p>The final evaluation of the optimal model:</p> 0 units 8 n_layers 2 activation elu learning_rate 0.008000 weight_decay 0.000000 dropout 0.000000 decay_rate 1.000000 val_accuracy_mean 0.652917 val_accuracy_std 0.000085 val_accuracy_min 0.652851 val_accuracy_max 0.653065 params 577"}]}