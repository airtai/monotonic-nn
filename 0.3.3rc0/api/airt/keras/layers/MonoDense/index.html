
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Monotonic Neural Networks implemented in Keras">
      
      
        <meta name="author" content="AIRT Technologies d.o.o.">
      
      
        <link rel="canonical" href="https://monotonic.airt.ai/0.3.3rc0/api/airt/keras/layers/MonoDense/">
      
      
        <link rel="prev" href="../../experiments/peek/">
      
      
        <link rel="next" href="../../../../../CHANGELOG/">
      
      <link rel="icon" href="../../../../../overrides/images/airt_icon_blue.svg">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.15">
    
    
      
        <title>MonoDense - Monotonic Neural Networks</title>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/stylesheets/main.26e3688c.min.css">
      
        
        <link rel="stylesheet" href="../../../../../assets/stylesheets/palette.ecc896b0.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../../../overrides/css/extra.css">
    
    <script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  


  <script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-F7V44YPJHR"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-F7V44YPJHR",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-F7V44YPJHR",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>

  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  
  
    
  
  
  <meta property="og:type" content="website" />
  <meta property="og:title" content="Monotonic Neural Networks - MonoDense" />
  <meta property="og:description" content="Monotonic Neural Networks implemented in Keras" />
  <meta property="og:url" content="https://monotonic.airt.ai/0.3.3rc0/api/airt/keras/layers/MonoDense/" />
  <meta property="og:image" content="https://opengraph.githubassets.com/1686060464.736638/airtai/monotonic-nn" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />

  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Monotonic Neural Networks - MonoDense" />
  <meta name="twitter:description" content="Monotonic Neural Networks implemented in Keras" />
  <meta name="twitter:image" content="https://opengraph.githubassets.com/1686060464.736638/airtai/monotonic-nn" />

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="custom" data-md-color-accent="light-blue">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#airt.keras.layers.MonoDense" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
          <aside class="md-banner md-banner--warning">
            <div class="md-banner__inner md-grid md-typeset">
              
  You're not viewing the latest version.
  <!-- nosemgrep -->
  <a href="../../../../../.."> 
    <strong>Click here to go to latest.</strong>
  </a>

            </div>
            <script>var el=document.querySelector("[data-md-component=outdated]"),outdated=__md_get("__outdated",sessionStorage);!0===outdated&&el&&(el.hidden=!1)</script>
          </aside>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../.." title="Monotonic Neural Networks" class="md-header__button md-logo" aria-label="Monotonic Neural Networks" data-md-component="logo">
      
  <img src="../../../../../overrides/images/airt_icon_blue.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Monotonic Neural Networks
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              MonoDense
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
          
            
            
            
            <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="custom" data-md-color-accent="light-blue"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
            
              <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_2" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
              </label>
            
          
            
            
            
            <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="custom" data-md-color-accent="light-blue"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_2">
            
              <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
              </label>
            
          
        </form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/airtai/monotonic-nn" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    monotonic-nn
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../.." title="Monotonic Neural Networks" class="md-nav__button md-logo" aria-label="Monotonic Neural Networks" data-md-component="logo">
      
  <img src="../../../../../overrides/images/airt_icon_blue.svg" alt="logo">

    </a>
    Monotonic Neural Networks
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/airtai/monotonic-nn" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    monotonic-nn
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../.." class="md-nav__link">
        Introduction
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../../InDepth/" class="md-nav__link">
        In-depth explanation
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
      
      
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          Experiments
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Experiments
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../experiments/AutoMPG/" class="md-nav__link">
        Auto MPG
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../experiments/Heart/" class="md-nav__link">
        Heart disease
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../experiments/Compas/" class="md-nav__link">
        COMPAS
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../experiments/Blog/" class="md-nav__link">
        Blog
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../experiments/Loan/" class="md-nav__link">
        Loan
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../../License/" class="md-nav__link">
        License
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
      
      
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
          API
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          API
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1" checked>
      
      
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
          airt
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_1_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_5_1">
          <span class="md-nav__icon md-icon"></span>
          airt
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1_1" checked>
      
      
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_1_1" id="__nav_5_1_1_label" tabindex="0">
          keras
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_1_1_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_5_1_1">
          <span class="md-nav__icon md-icon"></span>
          keras
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1_1_1" >
      
      
        
          
        
          
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_1_1_1" id="__nav_5_1_1_1_label" tabindex="0">
          experiments
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_1_1_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5_1_1_1">
          <span class="md-nav__icon md-icon"></span>
          experiments
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../experiments/create_tuner_stats/" class="md-nav__link">
        create_tuner_stats
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../experiments/df2ds/" class="md-nav__link">
        df2ds
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../experiments/find_hyperparameters/" class="md-nav__link">
        find_hyperparameters
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../experiments/get_train_n_test_data/" class="md-nav__link">
        get_train_n_test_data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../experiments/peek/" class="md-nav__link">
        peek
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_1_1_2" checked>
      
      
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_1_1_2" id="__nav_5_1_1_2_label" tabindex="0">
          layers
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_1_1_2_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_5_1_1_2">
          <span class="md-nav__icon md-icon"></span>
          layers
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          MonoDense
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        MonoDense
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#airt.keras.layers.MonoDense" class="md-nav__link">
    MonoDense
  </a>
  
    <nav class="md-nav" aria-label="MonoDense">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#airt.keras.layers.MonoDense-attributes" class="md-nav__link">
    Attributes
  </a>
  
    <nav class="md-nav" aria-label="Attributes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.activation_weights" class="md-nav__link">
    activation_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.is_concave" class="md-nav__link">
    is_concave
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.is_convex" class="md-nav__link">
    is_convex
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.monotonicity_indicator" class="md-nav__link">
    monotonicity_indicator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.org_activation" class="md-nav__link">
    org_activation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.units" class="md-nav__link">
    units
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt.keras.layers.MonoDense-functions" class="md-nav__link">
    Functions
  </a>
  
    <nav class="md-nav" aria-label="Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.add_loss" class="md-nav__link">
    add_loss()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.add_metric" class="md-nav__link">
    add_metric()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.add_update" class="md-nav__link">
    add_update()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.add_variable" class="md-nav__link">
    add_variable()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.add_weight" class="md-nav__link">
    add_weight()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.build" class="md-nav__link">
    build()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.call" class="md-nav__link">
    call()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.compute_mask" class="md-nav__link">
    compute_mask()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.compute_output_signature" class="md-nav__link">
    compute_output_signature()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.count_params" class="md-nav__link">
    count_params()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.finalize_state" class="md-nav__link">
    finalize_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.get_config" class="md-nav__link">
    get_config()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.get_input_at" class="md-nav__link">
    get_input_at()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.get_input_mask_at" class="md-nav__link">
    get_input_mask_at()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.get_input_shape_at" class="md-nav__link">
    get_input_shape_at()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.get_output_at" class="md-nav__link">
    get_output_at()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.get_output_mask_at" class="md-nav__link">
    get_output_mask_at()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.get_output_shape_at" class="md-nav__link">
    get_output_shape_at()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.get_weights" class="md-nav__link">
    get_weights()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.set_weights" class="md-nav__link">
    set_weights()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../../../CHANGELOG/" class="md-nav__link">
        Releases
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#airt.keras.layers.MonoDense" class="md-nav__link">
    MonoDense
  </a>
  
    <nav class="md-nav" aria-label="MonoDense">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#airt.keras.layers.MonoDense-attributes" class="md-nav__link">
    Attributes
  </a>
  
    <nav class="md-nav" aria-label="Attributes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.activation_weights" class="md-nav__link">
    activation_weights
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.is_concave" class="md-nav__link">
    is_concave
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.is_convex" class="md-nav__link">
    is_convex
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.monotonicity_indicator" class="md-nav__link">
    monotonicity_indicator
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.org_activation" class="md-nav__link">
    org_activation
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.units" class="md-nav__link">
    units
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt.keras.layers.MonoDense-functions" class="md-nav__link">
    Functions
  </a>
  
    <nav class="md-nav" aria-label="Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.add_loss" class="md-nav__link">
    add_loss()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.add_metric" class="md-nav__link">
    add_metric()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.add_update" class="md-nav__link">
    add_update()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.add_variable" class="md-nav__link">
    add_variable()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.add_weight" class="md-nav__link">
    add_weight()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.build" class="md-nav__link">
    build()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.call" class="md-nav__link">
    call()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.compute_mask" class="md-nav__link">
    compute_mask()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.compute_output_signature" class="md-nav__link">
    compute_output_signature()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.count_params" class="md-nav__link">
    count_params()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.finalize_state" class="md-nav__link">
    finalize_state()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#airt._components.mono_dense_layer.MonoDense.get_config" class="md-nav__link">
    get_config()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.get_input_at" class="md-nav__link">
    get_input_at()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.get_input_mask_at" class="md-nav__link">
    get_input_mask_at()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.get_input_shape_at" class="md-nav__link">
    get_input_shape_at()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.get_output_at" class="md-nav__link">
    get_output_at()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.get_output_mask_at" class="md-nav__link">
    get_output_mask_at()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.get_output_shape_at" class="md-nav__link">
    get_output_shape_at()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.get_weights" class="md-nav__link">
    get_weights()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#keras.engine.base_layer.Layer.set_weights" class="md-nav__link">
    set_weights()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  <h1>MonoDense</h1>

<div class="doc doc-object doc-class">



<h2 id="airt.keras.layers.MonoDense" class="doc doc-heading">
        <code>airt.keras.layers.MonoDense</code>


<a href="#airt.keras.layers.MonoDense" class="headerlink" title="Permanent link">Â¤</a></h2>


  <div class="doc doc-contents first">
      <p class="doc doc-class-bases">
        Bases: <code><span title="tensorflow.keras.layers.Dense">Dense</span></code></p>

  
      <p>Monotonic counterpart of the regular Dense Layer of tf.keras</p>
<p>This is an implementation of our Monotonic Dense Unit or Constrained Monotone Fully Connected Layer. The below is the figure from the paper for reference.</p>
<ul>
<li>
<p>the parameter <code>monotonicity_indicator</code> corresponds to <strong>t</strong> in the figure below, and</p>
</li>
<li>
<p>parameters <code>is_convex</code>, <code>is_concave</code> and <code>activation_weights</code> are used to calculate the activation selector <strong>s</strong> as follows:</p>
<ul>
<li>
<p>if <code>is_convex</code> or <code>is_concave</code> is <strong>True</strong>, then the activation selector <strong>s</strong> will be (<code>units</code>, 0, 0) and (0, <code>units</code>, 0), respecively.</p>
</li>
<li>
<p>if both  <code>is_convex</code> or <code>is_concave</code> is <strong>False</strong>, then the <code>activation_weights</code> represent ratios between <span class="arithmatex">\(\breve{s}\)</span>, <span class="arithmatex">\(\hat{s}\)</span> and <span class="arithmatex">\(\tilde{s}\)</span>,
  respecively. E.g. if <code>activation_weights = (2, 2, 1)</code> and <code>units = 10</code>, then</p>
</li>
</ul>
</li>
</ul>
<div class="arithmatex">\[
(\breve{s}, \hat{s}, \tilde{s}) = (4, 4, 2)
\]</div>
<p><img alt="mono-dense-layer-diagram.png" src="../../../../../images/nbs/images/mono-dense-layer-diagram.png" /></p>


        <details class="quote">
          <summary>Source code in <code>airt/_components/mono_dense_layer.py</code></summary>
          <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@export</span>
<span class="k">class</span> <span class="nc">MonoDense</span><span class="p">(</span><span class="n">Dense</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Monotonic counterpart of the regular Dense Layer of tf.keras</span>

<span class="sd">    This is an implementation of our Monotonic Dense Unit or Constrained Monotone Fully Connected Layer. The below is the figure from the paper for reference.</span>

<span class="sd">    - the parameter `monotonicity_indicator` corresponds to **t** in the figure below, and</span>

<span class="sd">    - parameters `is_convex`, `is_concave` and `activation_weights` are used to calculate the activation selector **s** as follows:</span>

<span class="sd">        - if `is_convex` or `is_concave` is **True**, then the activation selector **s** will be (`units`, 0, 0) and (0, `units`, 0), respecively.</span>

<span class="sd">        - if both  `is_convex` or `is_concave` is **False**, then the `activation_weights` represent ratios between $\\breve{s}$, $\\hat{s}$ and $\\tilde{s}$,</span>
<span class="sd">          respecively. E.g. if `activation_weights = (2, 2, 1)` and `units = 10`, then</span>

<span class="sd">    $$</span>
<span class="sd">    (\\breve{s}, \\hat{s}, \\tilde{s}) = (4, 4, 2)</span>
<span class="sd">    $$</span>

<span class="sd">    ![mono-dense-layer-diagram.png](../../../../../images/nbs/images/mono-dense-layer-diagram.png)</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">activation</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorLike</span><span class="p">],</span> <span class="n">TensorLike</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">monotonicity_indicator</span><span class="p">:</span> <span class="n">ArrayLike</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">is_convex</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">is_concave</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">activation_weights</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">),</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Constructs a new MonoDense instance.</span>

<span class="sd">        Params:</span>
<span class="sd">            units: Positive integer, dimensionality of the output space.</span>
<span class="sd">            activation: Activation function to use, it is assumed to be convex monotonically</span>
<span class="sd">                increasing function such as &quot;relu&quot; or &quot;elu&quot;</span>
<span class="sd">            monotonicity_indicator: Vector to indicate which of the inputs are monotonically increasing or</span>
<span class="sd">                monotonically decreasing or non-monotonic. Has value 1 for monotonically increasing,</span>
<span class="sd">                -1 for monotonically decreasing and 0 for non-monotonic.</span>
<span class="sd">            is_convex: convex if set to True</span>
<span class="sd">            is_concave: concave if set to True</span>
<span class="sd">            activation_weights: relative weights for each type of activation, the default is (1.0, 1.0, 1.0).</span>
<span class="sd">                Ignored if is_convex or is_concave is set to True</span>
<span class="sd">            **kwargs: passed as kwargs to the constructor of `Dense`</span>

<span class="sd">        Raise:</span>
<span class="sd">            ValueError:</span>
<span class="sd">                - if both **is_concave** and **is_convex** are set to **True**, or</span>
<span class="sd">                - if any component of activation_weights is negative or there is not exactly three components</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">is_convex</span> <span class="ow">and</span> <span class="n">is_concave</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The model cannot be set to be both convex and concave (only linear functions are both).&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">activation_weights</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;There must be exactly three components of activation_weights, but we have this instead: </span><span class="si">{</span><span class="n">activation_weights</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">activation_weights</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Values of activation_weights must be non-negative, but we have this instead: </span><span class="si">{</span><span class="n">activation_weights</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="nb">super</span><span class="p">(</span><span class="n">MonoDense</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">units</span> <span class="o">=</span> <span class="n">units</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">org_activation</span> <span class="o">=</span> <span class="n">activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">monotonicity_indicator</span> <span class="o">=</span> <span class="n">monotonicity_indicator</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_convex</span> <span class="o">=</span> <span class="n">is_convex</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_concave</span> <span class="o">=</span> <span class="n">is_concave</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation_weights</span> <span class="o">=</span> <span class="n">activation_weights</span>

        <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">convex_activation</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">concave_activation</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">saturated_activation</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">get_activation_functions</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">org_activation</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get config is used for saving the model&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">org_activation</span><span class="p">,</span>
            <span class="n">monotonicity_indicator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">monotonicity_indicator</span><span class="p">,</span>
            <span class="n">is_convex</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_convex</span><span class="p">,</span>
            <span class="n">is_concave</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_concave</span><span class="p">,</span>
            <span class="n">activation_weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation_weights</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Build</span>

<span class="sd">        Args:</span>
<span class="sd">            input_shape: input tensor</span>
<span class="sd">            args: positional arguments passed to Dense.build()</span>
<span class="sd">            kwargs: keyword arguments passed to Dense.build()</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MonoDense</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">monotonicity_indicator</span> <span class="o">=</span> <span class="n">get_monotonicity_indicator</span><span class="p">(</span>
            <span class="n">monotonicity_indicator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">monotonicity_indicator</span><span class="p">,</span>
            <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span>
            <span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">TensorLike</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorLike</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Call</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs: input tensor of shape (batch_size, ..., x_length)</span>

<span class="sd">        Returns:</span>
<span class="sd">            N-D tensor with shape: `(batch_size, ..., units)`.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># calculate W&#39;*x+y after we replace the kernal according to monotonicity vector</span>
        <span class="k">with</span> <span class="n">replace_kernel_using_monotonicity_indicator</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span> <span class="n">monotonicity_indicator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">monotonicity_indicator</span>
        <span class="p">):</span>
            <span class="n">h</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">MonoDense</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">apply_activations</span><span class="p">(</span>
            <span class="n">h</span><span class="p">,</span>
            <span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,</span>
            <span class="n">convex_activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">convex_activation</span><span class="p">,</span>
            <span class="n">concave_activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">concave_activation</span><span class="p">,</span>
            <span class="n">saturated_activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">saturated_activation</span><span class="p">,</span>
            <span class="n">is_convex</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_convex</span><span class="p">,</span>
            <span class="n">is_concave</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_concave</span><span class="p">,</span>
            <span class="n">activation_weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation_weights</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">y</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">create_type_1</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">TensorLike</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorLike</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorLike</span><span class="p">]],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">final_units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">activation</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorLike</span><span class="p">],</span> <span class="n">TensorLike</span><span class="p">]],</span>
        <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">final_activation</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorLike</span><span class="p">],</span> <span class="n">TensorLike</span><span class="p">]]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">monotonicity_indicator</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">is_convex</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">is_concave</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">dropout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorLike</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Builds Type-1 monotonic network</span>

<span class="sd">        Type-1 architecture corresponds to the standard MLP type of neural network architecture used in general, where each</span>
<span class="sd">        of the input features is concatenated to form one single input feature vector $\mathbf{x}$ and fed into the network,</span>
<span class="sd">        with the only difference being that instead of standard fully connected or dense layers, we employ monotonic dense units</span>
<span class="sd">        throughout. For the first (or input layer) layer, the indicator vector $\mathbf{t}$, is used to identify the monotonicity</span>
<span class="sd">        property of the input feature with respect to the output. Specifically, $\mathbf{t}$ is set to $1$ for those components</span>
<span class="sd">        in the input feature vector that are monotonically increasing and is set to $-1$ for those components that are monotonically</span>
<span class="sd">        decreasing and set to $0$ if the feature is non-monotonic. For the subsequent hidden layers, monotonic dense units with the</span>
<span class="sd">        indicator vector $\mathbf{t}$ always being set to $1$ are used in order to preserve monotonicity. Finally, depending on</span>
<span class="sd">        whether the problem at hand is a regression problem or a classification problem (or even a multi-task problem), an appropriate</span>
<span class="sd">        activation function (such as linear activation or sigmoid or softmax) to obtain the final output.</span>

<span class="sd">        ![mono-dense-layer-diagram.png](../../../images/nbs/images/type-1.png)</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs: input tensor or a dictionary of tensors</span>
<span class="sd">            units: number of units in hidden layers</span>
<span class="sd">            final_units: number of units in the output layer</span>
<span class="sd">            activation: the base activation function</span>
<span class="sd">            n_layers: total number of layers (hidden layers plus the output layer)</span>
<span class="sd">            final_activation: the activation function of the final layer (typicall softmax, sigmoid or linear).</span>
<span class="sd">                If set to None (default value), then the linear activation is used.</span>
<span class="sd">            monotonicity_indicator: if an instance of dictionary, then maps names of input feature to their monotonicity</span>
<span class="sd">                indicator (-1 for monotonically decreasing, 1 for monotonically increasing and 0 otherwise). If int,</span>
<span class="sd">                then all input features are set to the same monotinicity indicator.</span>
<span class="sd">            is_convex: set to True if a particular input feature is convex</span>
<span class="sd">            is_concave: set to True if a particular inputs feature is concave</span>
<span class="sd">            dropout: dropout rate. If set to float greater than 0, Dropout layers are inserted after hidden layers.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Output tensor</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_create_type_1</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">units</span><span class="o">=</span><span class="n">units</span><span class="p">,</span>
            <span class="n">final_units</span><span class="o">=</span><span class="n">final_units</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
            <span class="n">n_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
            <span class="n">final_activation</span><span class="o">=</span><span class="n">final_activation</span><span class="p">,</span>
            <span class="n">monotonicity_indicator</span><span class="o">=</span><span class="n">monotonicity_indicator</span><span class="p">,</span>
            <span class="n">is_convex</span><span class="o">=</span><span class="n">is_convex</span><span class="p">,</span>
            <span class="n">is_concave</span><span class="o">=</span><span class="n">is_concave</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">create_type_2</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">TensorLike</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorLike</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">TensorLike</span><span class="p">]],</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">input_units</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">final_units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">activation</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorLike</span><span class="p">],</span> <span class="n">TensorLike</span><span class="p">]],</span>
        <span class="n">n_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">final_activation</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorLike</span><span class="p">],</span> <span class="n">TensorLike</span><span class="p">]]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">monotonicity_indicator</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">is_convex</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">is_concave</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">bool</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">dropout</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorLike</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Builds Type-2 monotonic network</span>

<span class="sd">        Type-2 architecture is another example of a neural network architecture that can be built employing proposed</span>
<span class="sd">        monotonic dense blocks. The difference when compared to the architecture described above lies in the way input</span>
<span class="sd">        features are fed into the hidden layers of neural network architecture. Instead of concatenating the features</span>
<span class="sd">        directly, this architecture provides flexibility to employ any form of complex feature extractors for the</span>
<span class="sd">        non-monotonic features and use the extracted feature vectors as inputs. Another difference is that each monotonic</span>
<span class="sd">        input is passed through separate monotonic dense units. This provides an advantage since depending on whether the</span>
<span class="sd">        input is completely concave or convex or both, we can adjust the activation selection vector $\mathbf{s}$ appropriately</span>
<span class="sd">        along with an appropriate value for the indicator vector $\mathbf{t}$. Thus, each of the monotonic input features has</span>
<span class="sd">        a separate monotonic dense layer associated with it. Thus as the major difference to the above-mentioned architecture,</span>
<span class="sd">        we concatenate the feature vectors instead of concatenating the inputs directly. The subsequent parts of the network are</span>
<span class="sd">        similar to the architecture described above wherein for the rest of the hidden monotonic dense units, the indicator vector</span>
<span class="sd">        $\mathbf{t}$ is always set to $1$ to preserve monotonicity.</span>

<span class="sd">        ![mono-dense-layer-diagram.png](../../../images/nbs/images/type-2.png)</span>

<span class="sd">        Args:</span>
<span class="sd">            inputs: input tensor or a dictionary of tensors</span>
<span class="sd">            input_units: used to preprocess features before entering the common mono block</span>
<span class="sd">            units: number of units in hidden layers</span>
<span class="sd">            final_units: number of units in the output layer</span>
<span class="sd">            activation: the base activation function</span>
<span class="sd">            n_layers: total number of layers (hidden layers plus the output layer)</span>
<span class="sd">            final_activation: the activation function of the final layer (typicall softmax, sigmoid or linear).</span>
<span class="sd">                If set to None (default value), then the linear activation is used.</span>
<span class="sd">            monotonicity_indicator: if an instance of dictionary, then maps names of input feature to their monotonicity</span>
<span class="sd">                indicator (-1 for monotonically decreasing, 1 for monotonically increasing and 0 otherwise). If int,</span>
<span class="sd">                then all input features are set to the same monotinicity indicator.</span>
<span class="sd">            is_convex: set to True if a particular input feature is convex</span>
<span class="sd">            is_concave: set to True if a particular inputs feature is concave</span>
<span class="sd">            dropout: dropout rate. If set to float greater than 0, Dropout layers are inserted after hidden layers.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Output tensor</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">_create_type_2</span><span class="p">(</span>
            <span class="n">inputs</span><span class="p">,</span>
            <span class="n">input_units</span><span class="o">=</span><span class="n">input_units</span><span class="p">,</span>
            <span class="n">units</span><span class="o">=</span><span class="n">units</span><span class="p">,</span>
            <span class="n">final_units</span><span class="o">=</span><span class="n">final_units</span><span class="p">,</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">,</span>
            <span class="n">n_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
            <span class="n">final_activation</span><span class="o">=</span><span class="n">final_activation</span><span class="p">,</span>
            <span class="n">monotonicity_indicator</span><span class="o">=</span><span class="n">monotonicity_indicator</span><span class="p">,</span>
            <span class="n">is_convex</span><span class="o">=</span><span class="n">is_convex</span><span class="p">,</span>
            <span class="n">is_concave</span><span class="o">=</span><span class="n">is_concave</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
        </details>

  

  <div class="doc doc-children">





<h3 id="airt.keras.layers.MonoDense-attributes">Attributes<a href="#airt.keras.layers.MonoDense-attributes" class="headerlink" title="Permanent link">Â¤</a></h3>

<div class="doc doc-object doc-attribute">



<h4 id="airt._components.mono_dense_layer.MonoDense.activation_weights" class="doc doc-heading">
<code class="highlight language-python"><span class="n">activation_weights</span> <span class="o">=</span> <span class="n">activation_weights</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#airt._components.mono_dense_layer.MonoDense.activation_weights" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents ">
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="airt._components.mono_dense_layer.MonoDense.is_concave" class="doc doc-heading">
<code class="highlight language-python"><span class="n">is_concave</span> <span class="o">=</span> <span class="n">is_concave</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#airt._components.mono_dense_layer.MonoDense.is_concave" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents ">
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="airt._components.mono_dense_layer.MonoDense.is_convex" class="doc doc-heading">
<code class="highlight language-python"><span class="n">is_convex</span> <span class="o">=</span> <span class="n">is_convex</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#airt._components.mono_dense_layer.MonoDense.is_convex" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents ">
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="airt._components.mono_dense_layer.MonoDense.monotonicity_indicator" class="doc doc-heading">
<code class="highlight language-python"><span class="n">monotonicity_indicator</span> <span class="o">=</span> <span class="n">monotonicity_indicator</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#airt._components.mono_dense_layer.MonoDense.monotonicity_indicator" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents ">
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="airt._components.mono_dense_layer.MonoDense.org_activation" class="doc doc-heading">
<code class="highlight language-python"><span class="n">org_activation</span> <span class="o">=</span> <span class="n">activation</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#airt._components.mono_dense_layer.MonoDense.org_activation" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents ">
  </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="airt._components.mono_dense_layer.MonoDense.units" class="doc doc-heading">
<code class="highlight language-python"><span class="n">units</span> <span class="o">=</span> <span class="n">units</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#airt._components.mono_dense_layer.MonoDense.units" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents ">
  </div>

</div>

<h3 id="airt.keras.layers.MonoDense-functions">Functions<a href="#airt.keras.layers.MonoDense-functions" class="headerlink" title="Permanent link">Â¤</a></h3>

<div class="doc doc-object doc-function">



<h4 id="airt._components.mono_dense_layer.MonoDense.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="n">units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">activation</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorLike</span><span class="p">],</span> <span class="n">TensorLike</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">monotonicity_indicator</span><span class="p">:</span> <span class="n">ArrayLike</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">is_convex</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">is_concave</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">activation_weights</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span></code>

<a href="#airt._components.mono_dense_layer.MonoDense.__init__" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents ">
  
      <p>Constructs a new MonoDense instance.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>units</code></td>
          <td>
                <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Positive integer, dimensionality of the output space.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>activation</code></td>
          <td>
                <code>Optional[Union[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/stdtypes.html#str">str</a>, Callable[[<span title="tensorflow.types.experimental.TensorLike">TensorLike</span>], <span title="tensorflow.types.experimental.TensorLike">TensorLike</span>]]]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Activation function to use, it is assumed to be convex monotonically
increasing function such as "relu" or "elu"</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>monotonicity_indicator</code></td>
          <td>
                <code><span title="numpy.typing.ArrayLike">ArrayLike</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Vector to indicate which of the inputs are monotonically increasing or
monotonically decreasing or non-monotonic. Has value 1 for monotonically increasing,
-1 for monotonically decreasing and 0 for non-monotonic.</p>
            </div>
          </td>
          <td>
                <code>1</code>
          </td>
        </tr>
        <tr>
          <td><code>is_convex</code></td>
          <td>
                <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>convex if set to True</p>
            </div>
          </td>
          <td>
                <code>False</code>
          </td>
        </tr>
        <tr>
          <td><code>is_concave</code></td>
          <td>
                <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>concave if set to True</p>
            </div>
          </td>
          <td>
                <code>False</code>
          </td>
        </tr>
        <tr>
          <td><code>activation_weights</code></td>
          <td>
                <code>Tuple[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a>, <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a>, <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a>]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>relative weights for each type of activation, the default is (1.0, 1.0, 1.0).
Ignored if is_convex or is_concave is set to True</p>
            </div>
          </td>
          <td>
                <code>(7.0, 7.0, 2.0)</code>
          </td>
        </tr>
        <tr>
          <td><code>**kwargs</code></td>
          <td>
                <code>Any</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>passed as kwargs to the constructor of <code>Dense</code></p>
            </div>
          </td>
          <td>
                <code>{}</code>
          </td>
        </tr>
    </tbody>
  </table>

<details class="raise" open>
  <summary>Raise</summary>
  <p>ValueError:
    - if both <strong>is_concave</strong> and <strong>is_convex</strong> are set to <strong>True</strong>, or
    - if any component of activation_weights is negative or there is not exactly three components</p>
</details>
      <details class="quote">
        <summary>Source code in <code>airt/_components/mono_dense_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">units</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">activation</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">TensorLike</span><span class="p">],</span> <span class="n">TensorLike</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">monotonicity_indicator</span><span class="p">:</span> <span class="n">ArrayLike</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">is_convex</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">is_concave</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">activation_weights</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">7.0</span><span class="p">,</span> <span class="mf">7.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">),</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Constructs a new MonoDense instance.</span>

<span class="sd">    Params:</span>
<span class="sd">        units: Positive integer, dimensionality of the output space.</span>
<span class="sd">        activation: Activation function to use, it is assumed to be convex monotonically</span>
<span class="sd">            increasing function such as &quot;relu&quot; or &quot;elu&quot;</span>
<span class="sd">        monotonicity_indicator: Vector to indicate which of the inputs are monotonically increasing or</span>
<span class="sd">            monotonically decreasing or non-monotonic. Has value 1 for monotonically increasing,</span>
<span class="sd">            -1 for monotonically decreasing and 0 for non-monotonic.</span>
<span class="sd">        is_convex: convex if set to True</span>
<span class="sd">        is_concave: concave if set to True</span>
<span class="sd">        activation_weights: relative weights for each type of activation, the default is (1.0, 1.0, 1.0).</span>
<span class="sd">            Ignored if is_convex or is_concave is set to True</span>
<span class="sd">        **kwargs: passed as kwargs to the constructor of `Dense`</span>

<span class="sd">    Raise:</span>
<span class="sd">        ValueError:</span>
<span class="sd">            - if both **is_concave** and **is_convex** are set to **True**, or</span>
<span class="sd">            - if any component of activation_weights is negative or there is not exactly three components</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">is_convex</span> <span class="ow">and</span> <span class="n">is_concave</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;The model cannot be set to be both convex and concave (only linear functions are both).&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">activation_weights</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;There must be exactly three components of activation_weights, but we have this instead: </span><span class="si">{</span><span class="n">activation_weights</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">activation_weights</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Values of activation_weights must be non-negative, but we have this instead: </span><span class="si">{</span><span class="n">activation_weights</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">MonoDense</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">units</span> <span class="o">=</span> <span class="n">units</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">org_activation</span> <span class="o">=</span> <span class="n">activation</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">monotonicity_indicator</span> <span class="o">=</span> <span class="n">monotonicity_indicator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">is_convex</span> <span class="o">=</span> <span class="n">is_convex</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">is_concave</span> <span class="o">=</span> <span class="n">is_concave</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">activation_weights</span> <span class="o">=</span> <span class="n">activation_weights</span>

    <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">convex_activation</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">concave_activation</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">saturated_activation</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="n">get_activation_functions</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">org_activation</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="keras.engine.base_layer.Layer.add_loss" class="doc doc-heading">
<code class="highlight language-python"><span class="n">add_loss</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#keras.engine.base_layer.Layer.add_loss" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Add loss tensor(s), potentially dependent on layer inputs.</p>
<p>Some losses (for instance, activity regularization losses) may be
dependent on the inputs passed when calling a layer. Hence, when reusing
the same layer on different inputs <code>a</code> and <code>b</code>, some entries in
<code>layer.losses</code> may be dependent on <code>a</code> and some on <code>b</code>. This method
automatically keeps track of dependencies.</p>
<p>This method can be used inside a subclassed layer or model's <code>call</code>
function, in which case <code>losses</code> should be a Tensor or list of Tensors.</p>
<p>Example:</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">MyLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">inputs</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">inputs</span>
</code></pre></div>
<p>The same code works in distributed training: the input to <code>add_loss()</code>
is treated like a regularization loss and averaged across replicas
by the training loop (both built-in <code>Model.fit()</code> and compliant custom
training loops).</p>
<p>The <code>add_loss</code> method can also be called directly on a Functional Model
during construction. In this case, any loss Tensors passed to this Model
must be symbolic and be able to be traced back to the model's <code>Input</code>s.
These losses become part of the model's topology and are tracked in
<code>get_config</code>.</p>
<p>Example:</p>
<div class="highlight"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="c1"># Activity regularization.</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
</code></pre></div>
<p>If this is not the case for your loss (if, for example, your loss
references a <code>Variable</code> of one of the model's layers), you can wrap your
loss in a zero-argument lambda. These losses are not tracked as part of
the model's topology since they can't be serialized.</p>
<p>Example:</p>
<div class="highlight"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">d</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="c1"># Weight regularization.</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">kernel</span><span class="p">))</span>
</code></pre></div>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>losses</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Loss tensor, or list/tuple of tensors. Rather than tensors,
losses may also be zero-argument callables which create a loss
tensor.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>**kwargs</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Used for backwards compatibility only.</p>
            </div>
          </td>
          <td>
                <code>{}</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1429</span>
<span class="normal">1430</span>
<span class="normal">1431</span>
<span class="normal">1432</span>
<span class="normal">1433</span>
<span class="normal">1434</span>
<span class="normal">1435</span>
<span class="normal">1436</span>
<span class="normal">1437</span>
<span class="normal">1438</span>
<span class="normal">1439</span>
<span class="normal">1440</span>
<span class="normal">1441</span>
<span class="normal">1442</span>
<span class="normal">1443</span>
<span class="normal">1444</span>
<span class="normal">1445</span>
<span class="normal">1446</span>
<span class="normal">1447</span>
<span class="normal">1448</span>
<span class="normal">1449</span>
<span class="normal">1450</span>
<span class="normal">1451</span>
<span class="normal">1452</span>
<span class="normal">1453</span>
<span class="normal">1454</span>
<span class="normal">1455</span>
<span class="normal">1456</span>
<span class="normal">1457</span>
<span class="normal">1458</span>
<span class="normal">1459</span>
<span class="normal">1460</span>
<span class="normal">1461</span>
<span class="normal">1462</span>
<span class="normal">1463</span>
<span class="normal">1464</span>
<span class="normal">1465</span>
<span class="normal">1466</span>
<span class="normal">1467</span>
<span class="normal">1468</span>
<span class="normal">1469</span>
<span class="normal">1470</span>
<span class="normal">1471</span>
<span class="normal">1472</span>
<span class="normal">1473</span>
<span class="normal">1474</span>
<span class="normal">1475</span>
<span class="normal">1476</span>
<span class="normal">1477</span>
<span class="normal">1478</span>
<span class="normal">1479</span>
<span class="normal">1480</span>
<span class="normal">1481</span>
<span class="normal">1482</span>
<span class="normal">1483</span>
<span class="normal">1484</span>
<span class="normal">1485</span>
<span class="normal">1486</span>
<span class="normal">1487</span>
<span class="normal">1488</span>
<span class="normal">1489</span>
<span class="normal">1490</span>
<span class="normal">1491</span>
<span class="normal">1492</span>
<span class="normal">1493</span>
<span class="normal">1494</span>
<span class="normal">1495</span>
<span class="normal">1496</span>
<span class="normal">1497</span>
<span class="normal">1498</span>
<span class="normal">1499</span>
<span class="normal">1500</span>
<span class="normal">1501</span>
<span class="normal">1502</span>
<span class="normal">1503</span>
<span class="normal">1504</span>
<span class="normal">1505</span>
<span class="normal">1506</span>
<span class="normal">1507</span>
<span class="normal">1508</span>
<span class="normal">1509</span>
<span class="normal">1510</span>
<span class="normal">1511</span>
<span class="normal">1512</span>
<span class="normal">1513</span>
<span class="normal">1514</span>
<span class="normal">1515</span>
<span class="normal">1516</span>
<span class="normal">1517</span>
<span class="normal">1518</span>
<span class="normal">1519</span>
<span class="normal">1520</span>
<span class="normal">1521</span>
<span class="normal">1522</span>
<span class="normal">1523</span>
<span class="normal">1524</span>
<span class="normal">1525</span>
<span class="normal">1526</span>
<span class="normal">1527</span>
<span class="normal">1528</span>
<span class="normal">1529</span>
<span class="normal">1530</span>
<span class="normal">1531</span>
<span class="normal">1532</span>
<span class="normal">1533</span>
<span class="normal">1534</span>
<span class="normal">1535</span>
<span class="normal">1536</span>
<span class="normal">1537</span>
<span class="normal">1538</span>
<span class="normal">1539</span>
<span class="normal">1540</span>
<span class="normal">1541</span>
<span class="normal">1542</span>
<span class="normal">1543</span>
<span class="normal">1544</span>
<span class="normal">1545</span>
<span class="normal">1546</span>
<span class="normal">1547</span>
<span class="normal">1548</span>
<span class="normal">1549</span>
<span class="normal">1550</span>
<span class="normal">1551</span>
<span class="normal">1552</span>
<span class="normal">1553</span>
<span class="normal">1554</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">add_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Add loss tensor(s), potentially dependent on layer inputs.</span>

<span class="sd">    Some losses (for instance, activity regularization losses) may be</span>
<span class="sd">    dependent on the inputs passed when calling a layer. Hence, when reusing</span>
<span class="sd">    the same layer on different inputs `a` and `b`, some entries in</span>
<span class="sd">    `layer.losses` may be dependent on `a` and some on `b`. This method</span>
<span class="sd">    automatically keeps track of dependencies.</span>

<span class="sd">    This method can be used inside a subclassed layer or model&#39;s `call`</span>
<span class="sd">    function, in which case `losses` should be a Tensor or list of Tensors.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```python</span>
<span class="sd">    class MyLayer(tf.keras.layers.Layer):</span>
<span class="sd">      def call(self, inputs):</span>
<span class="sd">        self.add_loss(tf.abs(tf.reduce_mean(inputs)))</span>
<span class="sd">        return inputs</span>
<span class="sd">    ```</span>

<span class="sd">    The same code works in distributed training: the input to `add_loss()`</span>
<span class="sd">    is treated like a regularization loss and averaged across replicas</span>
<span class="sd">    by the training loop (both built-in `Model.fit()` and compliant custom</span>
<span class="sd">    training loops).</span>

<span class="sd">    The `add_loss` method can also be called directly on a Functional Model</span>
<span class="sd">    during construction. In this case, any loss Tensors passed to this Model</span>
<span class="sd">    must be symbolic and be able to be traced back to the model&#39;s `Input`s.</span>
<span class="sd">    These losses become part of the model&#39;s topology and are tracked in</span>
<span class="sd">    `get_config`.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```python</span>
<span class="sd">    inputs = tf.keras.Input(shape=(10,))</span>
<span class="sd">    x = tf.keras.layers.Dense(10)(inputs)</span>
<span class="sd">    outputs = tf.keras.layers.Dense(1)(x)</span>
<span class="sd">    model = tf.keras.Model(inputs, outputs)</span>
<span class="sd">    # Activity regularization.</span>
<span class="sd">    model.add_loss(tf.abs(tf.reduce_mean(x)))</span>
<span class="sd">    ```</span>

<span class="sd">    If this is not the case for your loss (if, for example, your loss</span>
<span class="sd">    references a `Variable` of one of the model&#39;s layers), you can wrap your</span>
<span class="sd">    loss in a zero-argument lambda. These losses are not tracked as part of</span>
<span class="sd">    the model&#39;s topology since they can&#39;t be serialized.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```python</span>
<span class="sd">    inputs = tf.keras.Input(shape=(10,))</span>
<span class="sd">    d = tf.keras.layers.Dense(10)</span>
<span class="sd">    x = d(inputs)</span>
<span class="sd">    outputs = tf.keras.layers.Dense(1)(x)</span>
<span class="sd">    model = tf.keras.Model(inputs, outputs)</span>
<span class="sd">    # Weight regularization.</span>
<span class="sd">    model.add_loss(lambda: tf.reduce_mean(d.kernel))</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      losses: Loss tensor, or list/tuple of tensors. Rather than tensors,</span>
<span class="sd">        losses may also be zero-argument callables which create a loss</span>
<span class="sd">        tensor.</span>
<span class="sd">      **kwargs: Used for backwards compatibility only.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;inputs&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown keyword arguments: </span><span class="si">{</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_tag_callable</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Tags callable loss tensor as `_unconditional_loss`.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
            <span class="c1"># We run the loss without autocasting, as regularizers are often</span>
            <span class="c1"># numerically unstable in float16.</span>
            <span class="k">with</span> <span class="n">autocast_variable</span><span class="o">.</span><span class="n">enable_auto_cast_variables</span><span class="p">(</span><span class="kc">None</span><span class="p">):</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Will be filtered out when computing the .losses property</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">backend</span><span class="o">.</span><span class="n">floatx</span><span class="p">())</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">_unconditional_loss</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="n">losses</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>

    <span class="n">callable_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">eager_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">symbolic_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">loss</span> <span class="ow">in</span> <span class="n">losses</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
            <span class="n">callable_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">_tag_callable</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>
            <span class="k">continue</span>
        <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">keras_tensor</span><span class="o">.</span><span class="n">KerasTensor</span>
        <span class="p">):</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">backend</span><span class="o">.</span><span class="n">floatx</span><span class="p">())</span>
        <span class="c1"># TF Functions should take the eager path.</span>
        <span class="k">if</span> <span class="p">(</span>
            <span class="n">tf_utils</span><span class="o">.</span><span class="n">is_symbolic_tensor</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">keras_tensor</span><span class="o">.</span><span class="n">KerasTensor</span><span class="p">)</span>
        <span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">base_layer_utils</span><span class="o">.</span><span class="n">is_in_tf_function</span><span class="p">():</span>
            <span class="n">symbolic_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">tf</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
            <span class="n">eager_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_callable_losses</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">callable_losses</span><span class="p">)</span>

    <span class="n">in_call_context</span> <span class="o">=</span> <span class="n">base_layer_utils</span><span class="o">.</span><span class="n">call_context</span><span class="p">()</span><span class="o">.</span><span class="n">in_call</span>
    <span class="k">if</span> <span class="n">eager_losses</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">in_call_context</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Expected a symbolic Tensors or a callable for the loss value. &quot;</span>
            <span class="s2">&quot;Please wrap your loss computation in a zero argument `lambda`.&quot;</span>
        <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_eager_losses</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">eager_losses</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">symbolic_loss</span> <span class="ow">in</span> <span class="n">symbolic_losses</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_is_graph_network&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_graph_network_add_loss</span><span class="p">(</span><span class="n">symbolic_loss</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Possible a loss was added in a Layer&#39;s `build`.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">symbolic_loss</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="keras.engine.base_layer.Layer.add_metric" class="doc doc-heading">
<code class="highlight language-python"><span class="n">add_metric</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#keras.engine.base_layer.Layer.add_metric" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Adds metric tensor to the layer.</p>
<p>This method can be used inside the <code>call()</code> method of a subclassed layer
or model.</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">MyMetricLayer</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Layer</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MyMetricLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;my_metric_layer&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_2&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">inputs</span>
</code></pre></div>
<p>This method can also be called directly on a Functional Model during
construction. In this case, any tensor passed to this Model must
be symbolic and be able to be traced back to the model's <code>Input</code>s. These
metrics become part of the model's topology and are tracked when you
save the model via <code>save()</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">math_ops</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>
</code></pre></div>
<p>Note: Calling <code>add_metric()</code> with the result of a metric object on a
Functional Model, as shown in the example below, is not supported. This
is because we cannot trace the metric result tensor back to the model's
inputs.</p>
<div class="highlight"><pre><span></span><code><span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_metric</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Mean</span><span class="p">()(</span><span class="n">x</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;metric_1&#39;</span><span class="p">)</span>
</code></pre></div>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>value</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Metric tensor.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>name</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>String metric name.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>**kwargs</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Additional keyword arguments for backward compatibility.
Accepted values:
<code>aggregation</code> - When the <code>value</code> tensor provided is not the result
of calling a <code>keras.Metric</code> instance, it will be aggregated by
default using a <code>keras.Metric.Mean</code>.</p>
            </div>
          </td>
          <td>
                <code>{}</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1581</span>
<span class="normal">1582</span>
<span class="normal">1583</span>
<span class="normal">1584</span>
<span class="normal">1585</span>
<span class="normal">1586</span>
<span class="normal">1587</span>
<span class="normal">1588</span>
<span class="normal">1589</span>
<span class="normal">1590</span>
<span class="normal">1591</span>
<span class="normal">1592</span>
<span class="normal">1593</span>
<span class="normal">1594</span>
<span class="normal">1595</span>
<span class="normal">1596</span>
<span class="normal">1597</span>
<span class="normal">1598</span>
<span class="normal">1599</span>
<span class="normal">1600</span>
<span class="normal">1601</span>
<span class="normal">1602</span>
<span class="normal">1603</span>
<span class="normal">1604</span>
<span class="normal">1605</span>
<span class="normal">1606</span>
<span class="normal">1607</span>
<span class="normal">1608</span>
<span class="normal">1609</span>
<span class="normal">1610</span>
<span class="normal">1611</span>
<span class="normal">1612</span>
<span class="normal">1613</span>
<span class="normal">1614</span>
<span class="normal">1615</span>
<span class="normal">1616</span>
<span class="normal">1617</span>
<span class="normal">1618</span>
<span class="normal">1619</span>
<span class="normal">1620</span>
<span class="normal">1621</span>
<span class="normal">1622</span>
<span class="normal">1623</span>
<span class="normal">1624</span>
<span class="normal">1625</span>
<span class="normal">1626</span>
<span class="normal">1627</span>
<span class="normal">1628</span>
<span class="normal">1629</span>
<span class="normal">1630</span>
<span class="normal">1631</span>
<span class="normal">1632</span>
<span class="normal">1633</span>
<span class="normal">1634</span>
<span class="normal">1635</span>
<span class="normal">1636</span>
<span class="normal">1637</span>
<span class="normal">1638</span>
<span class="normal">1639</span>
<span class="normal">1640</span>
<span class="normal">1641</span>
<span class="normal">1642</span>
<span class="normal">1643</span>
<span class="normal">1644</span>
<span class="normal">1645</span>
<span class="normal">1646</span>
<span class="normal">1647</span>
<span class="normal">1648</span>
<span class="normal">1649</span>
<span class="normal">1650</span>
<span class="normal">1651</span>
<span class="normal">1652</span>
<span class="normal">1653</span>
<span class="normal">1654</span>
<span class="normal">1655</span>
<span class="normal">1656</span>
<span class="normal">1657</span>
<span class="normal">1658</span>
<span class="normal">1659</span>
<span class="normal">1660</span>
<span class="normal">1661</span>
<span class="normal">1662</span>
<span class="normal">1663</span>
<span class="normal">1664</span>
<span class="normal">1665</span>
<span class="normal">1666</span>
<span class="normal">1667</span>
<span class="normal">1668</span>
<span class="normal">1669</span>
<span class="normal">1670</span>
<span class="normal">1671</span>
<span class="normal">1672</span>
<span class="normal">1673</span>
<span class="normal">1674</span>
<span class="normal">1675</span>
<span class="normal">1676</span>
<span class="normal">1677</span>
<span class="normal">1678</span>
<span class="normal">1679</span>
<span class="normal">1680</span>
<span class="normal">1681</span>
<span class="normal">1682</span>
<span class="normal">1683</span>
<span class="normal">1684</span>
<span class="normal">1685</span>
<span class="normal">1686</span>
<span class="normal">1687</span>
<span class="normal">1688</span>
<span class="normal">1689</span>
<span class="normal">1690</span>
<span class="normal">1691</span>
<span class="normal">1692</span>
<span class="normal">1693</span>
<span class="normal">1694</span>
<span class="normal">1695</span>
<span class="normal">1696</span>
<span class="normal">1697</span>
<span class="normal">1698</span>
<span class="normal">1699</span>
<span class="normal">1700</span>
<span class="normal">1701</span>
<span class="normal">1702</span>
<span class="normal">1703</span>
<span class="normal">1704</span>
<span class="normal">1705</span>
<span class="normal">1706</span>
<span class="normal">1707</span>
<span class="normal">1708</span>
<span class="normal">1709</span>
<span class="normal">1710</span>
<span class="normal">1711</span>
<span class="normal">1712</span>
<span class="normal">1713</span>
<span class="normal">1714</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">add_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Adds metric tensor to the layer.</span>

<span class="sd">    This method can be used inside the `call()` method of a subclassed layer</span>
<span class="sd">    or model.</span>

<span class="sd">    ```python</span>
<span class="sd">    class MyMetricLayer(tf.keras.layers.Layer):</span>
<span class="sd">      def __init__(self):</span>
<span class="sd">        super(MyMetricLayer, self).__init__(name=&#39;my_metric_layer&#39;)</span>
<span class="sd">        self.mean = tf.keras.metrics.Mean(name=&#39;metric_1&#39;)</span>

<span class="sd">      def call(self, inputs):</span>
<span class="sd">        self.add_metric(self.mean(inputs))</span>
<span class="sd">        self.add_metric(tf.reduce_sum(inputs), name=&#39;metric_2&#39;)</span>
<span class="sd">        return inputs</span>
<span class="sd">    ```</span>

<span class="sd">    This method can also be called directly on a Functional Model during</span>
<span class="sd">    construction. In this case, any tensor passed to this Model must</span>
<span class="sd">    be symbolic and be able to be traced back to the model&#39;s `Input`s. These</span>
<span class="sd">    metrics become part of the model&#39;s topology and are tracked when you</span>
<span class="sd">    save the model via `save()`.</span>

<span class="sd">    ```python</span>
<span class="sd">    inputs = tf.keras.Input(shape=(10,))</span>
<span class="sd">    x = tf.keras.layers.Dense(10)(inputs)</span>
<span class="sd">    outputs = tf.keras.layers.Dense(1)(x)</span>
<span class="sd">    model = tf.keras.Model(inputs, outputs)</span>
<span class="sd">    model.add_metric(math_ops.reduce_sum(x), name=&#39;metric_1&#39;)</span>
<span class="sd">    ```</span>

<span class="sd">    Note: Calling `add_metric()` with the result of a metric object on a</span>
<span class="sd">    Functional Model, as shown in the example below, is not supported. This</span>
<span class="sd">    is because we cannot trace the metric result tensor back to the model&#39;s</span>
<span class="sd">    inputs.</span>

<span class="sd">    ```python</span>
<span class="sd">    inputs = tf.keras.Input(shape=(10,))</span>
<span class="sd">    x = tf.keras.layers.Dense(10)(inputs)</span>
<span class="sd">    outputs = tf.keras.layers.Dense(1)(x)</span>
<span class="sd">    model = tf.keras.Model(inputs, outputs)</span>
<span class="sd">    model.add_metric(tf.keras.metrics.Mean()(x), name=&#39;metric_1&#39;)</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">      value: Metric tensor.</span>
<span class="sd">      name: String metric name.</span>
<span class="sd">      **kwargs: Additional keyword arguments for backward compatibility.</span>
<span class="sd">        Accepted values:</span>
<span class="sd">        `aggregation` - When the `value` tensor provided is not the result</span>
<span class="sd">        of calling a `keras.Metric` instance, it will be aggregated by</span>
<span class="sd">        default using a `keras.Metric.Mean`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">kwargs_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">kwargs_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="p">(</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">kwargs_keys</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">kwargs_keys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;aggregation&quot;</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Unknown keyword arguments: </span><span class="si">{</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span><span class="si">}</span><span class="s2">. &quot;</span>
            <span class="s2">&quot;Expected `aggregation`.&quot;</span>
        <span class="p">)</span>

    <span class="n">from_metric_obj</span> <span class="o">=</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;_metric_obj&quot;</span><span class="p">)</span>
    <span class="n">is_symbolic</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">keras_tensor</span><span class="o">.</span><span class="n">KerasTensor</span><span class="p">)</span>
    <span class="n">in_call_context</span> <span class="o">=</span> <span class="n">base_layer_utils</span><span class="o">.</span><span class="n">call_context</span><span class="p">()</span><span class="o">.</span><span class="n">in_call</span>

    <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">from_metric_obj</span><span class="p">:</span>
        <span class="c1"># Eg. `self.add_metric(math_ops.reduce_sum(x))` In eager mode, we</span>
        <span class="c1"># use metric name to lookup a metric. Without a name, a new Mean</span>
        <span class="c1"># metric wrapper will be created on every model/layer call. So, we</span>
        <span class="c1"># raise an error when no name is provided. We will do the same for</span>
        <span class="c1"># symbolic mode for consistency although a name will be generated if</span>
        <span class="c1"># no name is provided.</span>

        <span class="c1"># We will not raise this error in the foll use case for the sake of</span>
        <span class="c1"># consistency as name in provided in the metric constructor.</span>
        <span class="c1"># mean = metrics.Mean(name=&#39;my_metric&#39;)</span>
        <span class="c1"># model.add_metric(mean(outputs))</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Please provide a name for your metric like &quot;</span>
            <span class="s2">&quot;`self.add_metric(tf.reduce_sum(inputs), &quot;</span>
            <span class="s2">&quot;name=&#39;mean_activation&#39;)`&quot;</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">from_metric_obj</span><span class="p">:</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">_metric_obj</span><span class="o">.</span><span class="n">name</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">in_call_context</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_symbolic</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;Expected a symbolic Tensor for the metric value, received: &quot;</span>
            <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="c1"># If a metric was added in a Layer&#39;s `call` or `build`.</span>
    <span class="k">if</span> <span class="n">in_call_context</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_is_graph_network&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
        <span class="c1"># TF Function path should take the eager path.</span>

        <span class="c1"># If the given metric is available in `metrics` list we just update</span>
        <span class="c1"># state on it, otherwise we create a new metric instance and</span>
        <span class="c1"># add it to the `metrics` list.</span>
        <span class="n">metric_obj</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;_metric_obj&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="c1"># Tensors that come from a Metric object already updated the Metric</span>
        <span class="c1"># state.</span>
        <span class="n">should_update_state</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">metric_obj</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">metric_obj</span><span class="o">.</span><span class="n">name</span> <span class="k">if</span> <span class="n">metric_obj</span> <span class="k">else</span> <span class="n">name</span>

        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_metrics_lock</span><span class="p">:</span>
            <span class="n">match</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_existing_metric</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">match</span><span class="p">:</span>
                <span class="n">metric_obj</span> <span class="o">=</span> <span class="n">match</span>
            <span class="k">elif</span> <span class="n">metric_obj</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_metrics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metric_obj</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Build the metric object with the value&#39;s dtype if it</span>
                <span class="c1"># defines one</span>
                <span class="n">metric_obj</span> <span class="o">=</span> <span class="n">metrics_mod</span><span class="o">.</span><span class="n">Mean</span><span class="p">(</span>
                    <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="s2">&quot;dtype&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_metrics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metric_obj</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">should_update_state</span><span class="p">:</span>
            <span class="n">metric_obj</span><span class="p">(</span><span class="n">value</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">from_metric_obj</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Using the result of calling a `Metric` object &quot;</span>
                <span class="s2">&quot;when calling `add_metric` on a Functional &quot;</span>
                <span class="s2">&quot;Model is not supported. Please pass the &quot;</span>
                <span class="s2">&quot;Tensor to monitor directly.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Insert layers into the Keras Graph Network.</span>
        <span class="n">aggregation</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">from_metric_obj</span> <span class="k">else</span> <span class="s2">&quot;mean&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_graph_network_add_metric</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">aggregation</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="keras.engine.base_layer.Layer.add_update" class="doc doc-heading">
<code class="highlight language-python"><span class="n">add_update</span><span class="p">(</span><span class="n">updates</span><span class="p">)</span></code>

<a href="#keras.engine.base_layer.Layer.add_update" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Add update op(s), potentially dependent on layer inputs.</p>
<p>Weight updates (for instance, the updates of the moving mean and
variance in a BatchNormalization layer) may be dependent on the inputs
passed when calling a layer. Hence, when reusing the same layer on
different inputs <code>a</code> and <code>b</code>, some entries in <code>layer.updates</code> may be
dependent on <code>a</code> and some on <code>b</code>. This method automatically keeps track
of dependencies.</p>
<p>This call is ignored when eager execution is enabled (in that case,
variable updates are run on the fly and thus do not need to be tracked
for later execution).</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>updates</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Update op, or list/tuple of update ops, or zero-arg callable
that returns an update op. A zero-arg callable should be passed in
order to disable running the updates by setting <code>trainable=False</code>
on this Layer, when executing in Eager mode.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1716</span>
<span class="normal">1717</span>
<span class="normal">1718</span>
<span class="normal">1719</span>
<span class="normal">1720</span>
<span class="normal">1721</span>
<span class="normal">1722</span>
<span class="normal">1723</span>
<span class="normal">1724</span>
<span class="normal">1725</span>
<span class="normal">1726</span>
<span class="normal">1727</span>
<span class="normal">1728</span>
<span class="normal">1729</span>
<span class="normal">1730</span>
<span class="normal">1731</span>
<span class="normal">1732</span>
<span class="normal">1733</span>
<span class="normal">1734</span>
<span class="normal">1735</span>
<span class="normal">1736</span>
<span class="normal">1737</span>
<span class="normal">1738</span>
<span class="normal">1739</span>
<span class="normal">1740</span>
<span class="normal">1741</span>
<span class="normal">1742</span>
<span class="normal">1743</span>
<span class="normal">1744</span>
<span class="normal">1745</span>
<span class="normal">1746</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@doc_controls</span><span class="o">.</span><span class="n">do_not_doc_inheritable</span>
<span class="k">def</span> <span class="nf">add_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">updates</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Add update op(s), potentially dependent on layer inputs.</span>

<span class="sd">    Weight updates (for instance, the updates of the moving mean and</span>
<span class="sd">    variance in a BatchNormalization layer) may be dependent on the inputs</span>
<span class="sd">    passed when calling a layer. Hence, when reusing the same layer on</span>
<span class="sd">    different inputs `a` and `b`, some entries in `layer.updates` may be</span>
<span class="sd">    dependent on `a` and some on `b`. This method automatically keeps track</span>
<span class="sd">    of dependencies.</span>

<span class="sd">    This call is ignored when eager execution is enabled (in that case,</span>
<span class="sd">    variable updates are run on the fly and thus do not need to be tracked</span>
<span class="sd">    for later execution).</span>

<span class="sd">    Args:</span>
<span class="sd">      updates: Update op, or list/tuple of update ops, or zero-arg callable</span>
<span class="sd">        that returns an update op. A zero-arg callable should be passed in</span>
<span class="sd">        order to disable running the updates by setting `trainable=False`</span>
<span class="sd">        on this Layer, when executing in Eager mode.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">call_context</span> <span class="o">=</span> <span class="n">base_layer_utils</span><span class="o">.</span><span class="n">call_context</span><span class="p">()</span>
    <span class="c1"># No need to run updates during Functional API construction.</span>
    <span class="k">if</span> <span class="n">call_context</span><span class="o">.</span><span class="n">in_keras_graph</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="c1"># Callable updates are disabled by setting `trainable=False`.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">call_context</span><span class="o">.</span><span class="n">frozen</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">update</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">updates</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="n">update</span><span class="p">):</span>
                <span class="n">update</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="keras.engine.base_layer.Layer.add_variable" class="doc doc-heading">
<code class="highlight language-python"><span class="n">add_variable</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#keras.engine.base_layer.Layer.add_variable" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Deprecated, do NOT use! Alias for <code>add_weight</code>.</p>

      <details class="quote">
        <summary>Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2283</span>
<span class="normal">2284</span>
<span class="normal">2285</span>
<span class="normal">2286</span>
<span class="normal">2287</span>
<span class="normal">2288</span>
<span class="normal">2289</span>
<span class="normal">2290</span>
<span class="normal">2291</span>
<span class="normal">2292</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@doc_controls</span><span class="o">.</span><span class="n">do_not_doc_inheritable</span>
<span class="k">def</span> <span class="nf">add_variable</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Deprecated, do NOT use! Alias for `add_weight`.&quot;&quot;&quot;</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;`layer.add_variable` is deprecated and &quot;</span>
        <span class="s2">&quot;will be removed in a future version. &quot;</span>
        <span class="s2">&quot;Please use the `layer.add_weight()` method instead.&quot;</span><span class="p">,</span>
        <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_weight</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="keras.engine.base_layer.Layer.add_weight" class="doc doc-heading">
<code class="highlight language-python"><span class="n">add_weight</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">initializer</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">regularizer</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">trainable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">constraint</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">use_resource</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">synchronization</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">VariableSynchronization</span><span class="o">.</span><span class="n">AUTO</span><span class="p">,</span> <span class="n">aggregation</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">VariableAggregation</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#keras.engine.base_layer.Layer.add_weight" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Adds a new variable to the layer.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>name</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Variable name.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>shape</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Variable shape. Defaults to scalar if unspecified.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>dtype</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The type of the variable. Defaults to <code>self.dtype</code>.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>initializer</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Initializer instance (callable).</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>regularizer</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Regularizer instance (callable).</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>trainable</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Boolean, whether the variable should be part of the layer's
"trainable_variables" (e.g. variables, biases)
or "non_trainable_variables" (e.g. BatchNorm mean and variance).
Note that <code>trainable</code> cannot be <code>True</code> if <code>synchronization</code>
is set to <code>ON_READ</code>.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>constraint</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Constraint instance (callable).</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>use_resource</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Whether to use a <code>ResourceVariable</code> or not.
See <a href="https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables">this guide</a>
 for more information.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
        <tr>
          <td><code>synchronization</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Indicates when a distributed a variable will be
aggregated. Accepted values are constants defined in the class
<code>tf.VariableSynchronization</code>. By default the synchronization is set
to <code>AUTO</code> and the current <code>DistributionStrategy</code> chooses when to
synchronize. If <code>synchronization</code> is set to <code>ON_READ</code>, <code>trainable</code>
must not be set to <code>True</code>.</p>
            </div>
          </td>
          <td>
                <code>tf.VariableSynchronization.AUTO</code>
          </td>
        </tr>
        <tr>
          <td><code>aggregation</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Indicates how a distributed variable will be aggregated.
Accepted values are constants defined in the class
<code>tf.VariableAggregation</code>.</p>
            </div>
          </td>
          <td>
                <code>tf.VariableAggregation.NONE</code>
          </td>
        </tr>
        <tr>
          <td><code>**kwargs</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Additional keyword arguments. Accepted values are <code>getter</code>,
<code>collections</code>, <code>experimental_autocast</code> and <code>caching_device</code>.</p>
            </div>
          </td>
          <td>
                <code>{}</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>The variable created.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/exceptions.html#ValueError">ValueError</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>When giving unsupported dtype and no initializer or when
trainable has been set to True with synchronization set as
<code>ON_READ</code>.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
<span class="k">def</span> <span class="nf">add_weight</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">trainable</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">constraint</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">use_resource</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">synchronization</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">VariableSynchronization</span><span class="o">.</span><span class="n">AUTO</span><span class="p">,</span>
    <span class="n">aggregation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">VariableAggregation</span><span class="o">.</span><span class="n">NONE</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Adds a new variable to the layer.</span>

<span class="sd">    Args:</span>
<span class="sd">      name: Variable name.</span>
<span class="sd">      shape: Variable shape. Defaults to scalar if unspecified.</span>
<span class="sd">      dtype: The type of the variable. Defaults to `self.dtype`.</span>
<span class="sd">      initializer: Initializer instance (callable).</span>
<span class="sd">      regularizer: Regularizer instance (callable).</span>
<span class="sd">      trainable: Boolean, whether the variable should be part of the layer&#39;s</span>
<span class="sd">        &quot;trainable_variables&quot; (e.g. variables, biases)</span>
<span class="sd">        or &quot;non_trainable_variables&quot; (e.g. BatchNorm mean and variance).</span>
<span class="sd">        Note that `trainable` cannot be `True` if `synchronization`</span>
<span class="sd">        is set to `ON_READ`.</span>
<span class="sd">      constraint: Constraint instance (callable).</span>
<span class="sd">      use_resource: Whether to use a `ResourceVariable` or not.</span>
<span class="sd">        See [this guide](</span>
<span class="sd">        https://www.tensorflow.org/guide/migrate/tf1_vs_tf2#resourcevariables_instead_of_referencevariables)</span>
<span class="sd">         for more information.</span>
<span class="sd">      synchronization: Indicates when a distributed a variable will be</span>
<span class="sd">        aggregated. Accepted values are constants defined in the class</span>
<span class="sd">        `tf.VariableSynchronization`. By default the synchronization is set</span>
<span class="sd">        to `AUTO` and the current `DistributionStrategy` chooses when to</span>
<span class="sd">        synchronize. If `synchronization` is set to `ON_READ`, `trainable`</span>
<span class="sd">        must not be set to `True`.</span>
<span class="sd">      aggregation: Indicates how a distributed variable will be aggregated.</span>
<span class="sd">        Accepted values are constants defined in the class</span>
<span class="sd">        `tf.VariableAggregation`.</span>
<span class="sd">      **kwargs: Additional keyword arguments. Accepted values are `getter`,</span>
<span class="sd">        `collections`, `experimental_autocast` and `caching_device`.</span>

<span class="sd">    Returns:</span>
<span class="sd">      The variable created.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: When giving unsupported dtype and no initializer or when</span>
<span class="sd">        trainable has been set to True with synchronization set as</span>
<span class="sd">        `ON_READ`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">()</span>
    <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;partitioner&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>  <span class="c1"># Ignored.</span>
    <span class="c1"># Validate optional keyword arguments.</span>
    <span class="k">for</span> <span class="n">kwarg</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">kwarg</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="s2">&quot;collections&quot;</span><span class="p">,</span>
            <span class="s2">&quot;experimental_autocast&quot;</span><span class="p">,</span>
            <span class="s2">&quot;caching_device&quot;</span><span class="p">,</span>
            <span class="s2">&quot;getter&quot;</span><span class="p">,</span>
            <span class="s2">&quot;layout&quot;</span><span class="p">,</span>
        <span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Unknown keyword argument:&quot;</span><span class="p">,</span> <span class="n">kwarg</span><span class="p">)</span>
    <span class="n">collections_arg</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;collections&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="c1"># &#39;experimental_autocast&#39; can be set to False by the caller to indicate</span>
    <span class="c1"># an AutoCastVariable should never be created.</span>
    <span class="n">autocast</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;experimental_autocast&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="c1"># See the docstring for tf.Variable about the details for</span>
    <span class="c1"># caching_device.</span>
    <span class="n">caching_device</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;caching_device&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="n">layout</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;layout&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="c1"># Specially handling of auto layout fetch, based on the variable name</span>
    <span class="c1"># and attribute name. For built-in keras layers, usually the variable</span>
    <span class="c1"># name, eg &#39;kernel&#39;, will match with a &#39;kernel_layout&#39; attribute name on</span>
    <span class="c1"># the instance. We will try to do this auto fetch if layout is not</span>
    <span class="c1"># explicitly specified. This is mainly a quick workaround for not</span>
    <span class="c1"># applying too many interface change to built-in layers, until DTensor</span>
    <span class="c1"># is a public API.  Also see dtensor.utils.allow_initializer_layout for</span>
    <span class="c1"># more details.</span>
    <span class="c1"># TODO(scottzhu): Remove this once dtensor is public to end user.</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">layout</span> <span class="ow">and</span> <span class="n">name</span><span class="p">:</span>
        <span class="n">layout</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_layout&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">or</span> <span class="n">backend</span><span class="o">.</span><span class="n">floatx</span><span class="p">()</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">as_dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_policy</span><span class="o">.</span><span class="n">variable_dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># The policy is &quot;_infer&quot;, so we infer the policy from the variable</span>
        <span class="c1"># dtype.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set_dtype_policy</span><span class="p">(</span><span class="n">policy</span><span class="o">.</span><span class="n">Policy</span><span class="p">(</span><span class="n">dtype</span><span class="o">.</span><span class="n">base_dtype</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
    <span class="n">initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">initializer</span><span class="p">)</span>
    <span class="n">regularizer</span> <span class="o">=</span> <span class="n">regularizers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">regularizer</span><span class="p">)</span>
    <span class="n">constraint</span> <span class="o">=</span> <span class="n">constraints</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">constraint</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">synchronization</span> <span class="o">==</span> <span class="n">tf</span><span class="o">.</span><span class="n">VariableSynchronization</span><span class="o">.</span><span class="n">ON_READ</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">trainable</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Synchronization value can be set to &quot;</span>
                <span class="s2">&quot;VariableSynchronization.ON_READ only for non-trainable &quot;</span>
                <span class="s2">&quot;variables. You have specified trainable=True and &quot;</span>
                <span class="s2">&quot;synchronization=VariableSynchronization.ON_READ.&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Set trainable to be false when variable is to be synced on</span>
            <span class="c1"># read.</span>
            <span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">elif</span> <span class="n">trainable</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># Initialize variable when no initializer provided</span>
    <span class="k">if</span> <span class="n">initializer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># If dtype is DT_FLOAT, provide a uniform unit scaling initializer</span>
        <span class="k">if</span> <span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span><span class="p">:</span>
            <span class="n">initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;glorot_uniform&quot;</span><span class="p">)</span>
        <span class="c1"># If dtype is DT_INT/DT_UINT, provide a default value `zero`</span>
        <span class="c1"># If dtype is DT_BOOL, provide a default value `FALSE`</span>
        <span class="k">elif</span> <span class="n">dtype</span><span class="o">.</span><span class="n">is_integer</span> <span class="ow">or</span> <span class="n">dtype</span><span class="o">.</span><span class="n">is_unsigned</span> <span class="ow">or</span> <span class="n">dtype</span><span class="o">.</span><span class="n">is_bool</span><span class="p">:</span>
            <span class="n">initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;zeros&quot;</span><span class="p">)</span>
        <span class="c1"># NOTES:Do we need to support for handling DT_STRING and DT_COMPLEX</span>
        <span class="c1"># here?</span>
        <span class="k">elif</span> <span class="s2">&quot;getter&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="c1"># When `getter` is specified, it&#39;s possibly fine for</span>
            <span class="c1"># `initializer` to be None since it&#39;s up to the custom `getter`</span>
            <span class="c1"># to raise error in case it indeed needs `initializer`.</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;An initializer for variable </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> of type &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dtype</span><span class="o">.</span><span class="n">base_dtype</span><span class="si">}</span><span class="s2"> is required for layer &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">. Received: </span><span class="si">{</span><span class="n">initializer</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

    <span class="n">getter</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;getter&quot;</span><span class="p">,</span> <span class="n">base_layer_utils</span><span class="o">.</span><span class="n">make_variable</span><span class="p">)</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="n">autocast</span>
        <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_policy</span><span class="o">.</span><span class="n">compute_dtype</span>
        <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_policy</span><span class="o">.</span><span class="n">variable_dtype</span>
        <span class="ow">and</span> <span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span>
    <span class="p">):</span>
        <span class="n">old_getter</span> <span class="o">=</span> <span class="n">getter</span>

        <span class="c1"># Wrap variable constructor to return an AutoCastVariable.</span>
        <span class="k">def</span> <span class="nf">getter</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
            <span class="n">variable</span> <span class="o">=</span> <span class="n">old_getter</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">autocast_variable</span><span class="o">.</span><span class="n">create_autocast_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>

        <span class="c1"># Also the caching_device does not work with the mixed precision</span>
        <span class="c1"># API, disable it if it is specified.</span>
        <span class="c1"># TODO(b/142020079): Re-enable it once the bug is fixed.</span>
        <span class="k">if</span> <span class="n">caching_device</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">tf_logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;`caching_device` does not work with mixed precision API. &quot;</span>
                <span class="s2">&quot;Ignoring user specified `caching_device`.&quot;</span>
            <span class="p">)</span>
            <span class="n">caching_device</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">layout</span><span class="p">:</span>
        <span class="n">getter</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">getter</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="n">layout</span><span class="p">)</span>

    <span class="n">variable</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_variable_with_custom_getter</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
        <span class="c1"># TODO(allenl): a `make_variable` equivalent should be added as a</span>
        <span class="c1"># `Trackable` method.</span>
        <span class="n">getter</span><span class="o">=</span><span class="n">getter</span><span class="p">,</span>
        <span class="c1"># Manage errors in Layer rather than Trackable.</span>
        <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">initializer</span><span class="o">=</span><span class="n">initializer</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">constraint</span><span class="o">=</span><span class="n">constraint</span><span class="p">,</span>
        <span class="n">trainable</span><span class="o">=</span><span class="n">trainable</span><span class="p">,</span>
        <span class="n">use_resource</span><span class="o">=</span><span class="n">use_resource</span><span class="p">,</span>
        <span class="n">collections</span><span class="o">=</span><span class="n">collections_arg</span><span class="p">,</span>
        <span class="n">synchronization</span><span class="o">=</span><span class="n">synchronization</span><span class="p">,</span>
        <span class="n">aggregation</span><span class="o">=</span><span class="n">aggregation</span><span class="p">,</span>
        <span class="n">caching_device</span><span class="o">=</span><span class="n">caching_device</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">regularizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># TODO(fchollet): in the future, this should be handled at the</span>
        <span class="c1"># level of variable creation, and weight regularization losses</span>
        <span class="c1"># should be variable attributes.</span>
        <span class="n">name_in_scope</span> <span class="o">=</span> <span class="n">variable</span><span class="o">.</span><span class="n">name</span><span class="p">[:</span> <span class="n">variable</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">)]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_handle_weight_regularization</span><span class="p">(</span>
            <span class="n">name_in_scope</span><span class="p">,</span> <span class="n">variable</span><span class="p">,</span> <span class="n">regularizer</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">base_layer_utils</span><span class="o">.</span><span class="n">is_split_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">variable</span><span class="p">:</span>
            <span class="n">backend</span><span class="o">.</span><span class="n">track_variable</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">trainable</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_trainable_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">backend</span><span class="o">.</span><span class="n">track_variable</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">trainable</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_trainable_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">variable</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">variable</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="airt._components.mono_dense_layer.MonoDense.build" class="doc doc-heading">
<code class="highlight language-python"><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span></code>

<a href="#airt._components.mono_dense_layer.MonoDense.build" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Build</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>input_shape</code></td>
          <td>
                <code>Tuple</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>input tensor</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>args</code></td>
          <td>
                <code>List[Any]</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>positional arguments passed to Dense.build()</p>
            </div>
          </td>
          <td>
                <code>()</code>
          </td>
        </tr>
        <tr>
          <td><code>kwargs</code></td>
          <td>
                <code>Any</code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>keyword arguments passed to Dense.build()</p>
            </div>
          </td>
          <td>
                <code>{}</code>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>airt/_components/mono_dense_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Build</span>

<span class="sd">    Args:</span>
<span class="sd">        input_shape: input tensor</span>
<span class="sd">        args: positional arguments passed to Dense.build()</span>
<span class="sd">        kwargs: keyword arguments passed to Dense.build()</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MonoDense</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">monotonicity_indicator</span> <span class="o">=</span> <span class="n">get_monotonicity_indicator</span><span class="p">(</span>
        <span class="n">monotonicity_indicator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">monotonicity_indicator</span><span class="p">,</span>
        <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span>
        <span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="airt._components.mono_dense_layer.MonoDense.call" class="doc doc-heading">
<code class="highlight language-python"><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">:</span> <span class="n">TensorLike</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorLike</span></code>

<a href="#airt._components.mono_dense_layer.MonoDense.call" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Call</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>inputs</code></td>
          <td>
                <code><span title="tensorflow.types.experimental.TensorLike">TensorLike</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>input tensor of shape (batch_size, ..., x_length)</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><span title="tensorflow.types.experimental.TensorLike">TensorLike</span></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>N-D tensor with shape: <code>(batch_size, ..., units)</code>.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>airt/_components/mono_dense_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">TensorLike</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">TensorLike</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Call</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs: input tensor of shape (batch_size, ..., x_length)</span>

<span class="sd">    Returns:</span>
<span class="sd">        N-D tensor with shape: `(batch_size, ..., units)`.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># calculate W&#39;*x+y after we replace the kernal according to monotonicity vector</span>
    <span class="k">with</span> <span class="n">replace_kernel_using_monotonicity_indicator</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">monotonicity_indicator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">monotonicity_indicator</span>
    <span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">MonoDense</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">apply_activations</span><span class="p">(</span>
        <span class="n">h</span><span class="p">,</span>
        <span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,</span>
        <span class="n">convex_activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">convex_activation</span><span class="p">,</span>
        <span class="n">concave_activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">concave_activation</span><span class="p">,</span>
        <span class="n">saturated_activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">saturated_activation</span><span class="p">,</span>
        <span class="n">is_convex</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_convex</span><span class="p">,</span>
        <span class="n">is_concave</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_concave</span><span class="p">,</span>
        <span class="n">activation_weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation_weights</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">y</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="keras.engine.base_layer.Layer.compute_mask" class="doc doc-heading">
<code class="highlight language-python"><span class="n">compute_mask</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span></code>

<a href="#keras.engine.base_layer.Layer.compute_mask" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Computes an output mask tensor.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>inputs</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Tensor or list of tensors.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
        <tr>
          <td><code>mask</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Tensor or list of tensors.</p>
            </div>
          </td>
          <td>
                <code>None</code>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>None or a tensor (or list of tensors,
one per output tensor of the layer).</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">976</span>
<span class="normal">977</span>
<span class="normal">978</span>
<span class="normal">979</span>
<span class="normal">980</span>
<span class="normal">981</span>
<span class="normal">982</span>
<span class="normal">983</span>
<span class="normal">984</span>
<span class="normal">985</span>
<span class="normal">986</span>
<span class="normal">987</span>
<span class="normal">988</span>
<span class="normal">989</span>
<span class="normal">990</span>
<span class="normal">991</span>
<span class="normal">992</span>
<span class="normal">993</span>
<span class="normal">994</span>
<span class="normal">995</span>
<span class="normal">996</span>
<span class="normal">997</span>
<span class="normal">998</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@generic_utils</span><span class="o">.</span><span class="n">default</span>
<span class="k">def</span> <span class="nf">compute_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes an output mask tensor.</span>

<span class="sd">    Args:</span>
<span class="sd">        inputs: Tensor or list of tensors.</span>
<span class="sd">        mask: Tensor or list of tensors.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None or a tensor (or list of tensors,</span>
<span class="sd">            one per output tensor of the layer).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_supports_masking</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">m</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">mask</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;Layer &quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot; does not support masking, &quot;</span>
                <span class="s2">&quot;but was passed an input_mask: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="c1"># masking not explicitly supported: return None as mask.</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="c1"># if masking is explicitly supported, by default</span>
    <span class="c1"># carry over the input mask</span>
    <span class="k">return</span> <span class="n">mask</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="keras.engine.base_layer.Layer.compute_output_signature" class="doc doc-heading">
<code class="highlight language-python"><span class="n">compute_output_signature</span><span class="p">(</span><span class="n">input_signature</span><span class="p">)</span></code>

<a href="#keras.engine.base_layer.Layer.compute_output_signature" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Compute the output tensor signature of the layer based on the inputs.</p>
<p>Unlike a TensorShape object, a TensorSpec object contains both shape
and dtype information for a tensor. This method allows layers to provide
output dtype information if it is different from the input dtype.
For any layer that doesn't implement this function,
the framework will fall back to use <code>compute_output_shape</code>, and will
assume that the output dtype matches the input dtype.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>input_signature</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Single TensorSpec or nested structure of TensorSpec
objects, describing a candidate input for the layer.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Single TensorSpec or nested structure of TensorSpec objects,
describing how the layer would transform the provided input.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/exceptions.html#TypeError">TypeError</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>If input_signature contains a non-TensorSpec object.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">931</span>
<span class="normal">932</span>
<span class="normal">933</span>
<span class="normal">934</span>
<span class="normal">935</span>
<span class="normal">936</span>
<span class="normal">937</span>
<span class="normal">938</span>
<span class="normal">939</span>
<span class="normal">940</span>
<span class="normal">941</span>
<span class="normal">942</span>
<span class="normal">943</span>
<span class="normal">944</span>
<span class="normal">945</span>
<span class="normal">946</span>
<span class="normal">947</span>
<span class="normal">948</span>
<span class="normal">949</span>
<span class="normal">950</span>
<span class="normal">951</span>
<span class="normal">952</span>
<span class="normal">953</span>
<span class="normal">954</span>
<span class="normal">955</span>
<span class="normal">956</span>
<span class="normal">957</span>
<span class="normal">958</span>
<span class="normal">959</span>
<span class="normal">960</span>
<span class="normal">961</span>
<span class="normal">962</span>
<span class="normal">963</span>
<span class="normal">964</span>
<span class="normal">965</span>
<span class="normal">966</span>
<span class="normal">967</span>
<span class="normal">968</span>
<span class="normal">969</span>
<span class="normal">970</span>
<span class="normal">971</span>
<span class="normal">972</span>
<span class="normal">973</span>
<span class="normal">974</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
<span class="k">def</span> <span class="nf">compute_output_signature</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_signature</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute the output tensor signature of the layer based on the inputs.</span>

<span class="sd">    Unlike a TensorShape object, a TensorSpec object contains both shape</span>
<span class="sd">    and dtype information for a tensor. This method allows layers to provide</span>
<span class="sd">    output dtype information if it is different from the input dtype.</span>
<span class="sd">    For any layer that doesn&#39;t implement this function,</span>
<span class="sd">    the framework will fall back to use `compute_output_shape`, and will</span>
<span class="sd">    assume that the output dtype matches the input dtype.</span>

<span class="sd">    Args:</span>
<span class="sd">      input_signature: Single TensorSpec or nested structure of TensorSpec</span>
<span class="sd">        objects, describing a candidate input for the layer.</span>

<span class="sd">    Returns:</span>
<span class="sd">      Single TensorSpec or nested structure of TensorSpec objects,</span>
<span class="sd">        describing how the layer would transform the provided input.</span>

<span class="sd">    Raises:</span>
<span class="sd">      TypeError: If input_signature contains a non-TensorSpec object.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">check_type_return_shape</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="s2">&quot;Only TensorSpec signature types are supported. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Received: </span><span class="si">{</span><span class="n">s</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">s</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span>
        <span class="n">check_type_return_shape</span><span class="p">,</span> <span class="n">input_signature</span>
    <span class="p">)</span>
    <span class="n">output_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_output_shape</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_dtype</span>
    <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">input_dtypes</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">dtype</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">input_signature</span><span class="p">)]</span>
        <span class="c1"># Default behavior when self.dtype is None, is to use the first</span>
        <span class="c1"># input&#39;s dtype.</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">input_dtypes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">s</span><span class="p">),</span> <span class="n">output_shape</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="keras.engine.base_layer.Layer.count_params" class="doc doc-heading">
<code class="highlight language-python"><span class="n">count_params</span><span class="p">()</span></code>

<a href="#keras.engine.base_layer.Layer.count_params" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Count the total number of scalars composing the weights.</p>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>An integer count.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/exceptions.html#ValueError">ValueError</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>if the layer isn't yet built
(in which case its weights aren't yet defined).</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2146</span>
<span class="normal">2147</span>
<span class="normal">2148</span>
<span class="normal">2149</span>
<span class="normal">2150</span>
<span class="normal">2151</span>
<span class="normal">2152</span>
<span class="normal">2153</span>
<span class="normal">2154</span>
<span class="normal">2155</span>
<span class="normal">2156</span>
<span class="normal">2157</span>
<span class="normal">2158</span>
<span class="normal">2159</span>
<span class="normal">2160</span>
<span class="normal">2161</span>
<span class="normal">2162</span>
<span class="normal">2163</span>
<span class="normal">2164</span>
<span class="normal">2165</span>
<span class="normal">2166</span>
<span class="normal">2167</span>
<span class="normal">2168</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">count_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Count the total number of scalars composing the weights.</span>

<span class="sd">    Returns:</span>
<span class="sd">        An integer count.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: if the layer isn&#39;t yet built</span>
<span class="sd">          (in which case its weights aren&#39;t yet defined).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">built</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_is_graph_network&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">maybe_init_scope</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_build</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;You tried to call `count_params` &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;on layer </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="s2">&quot;, but the layer isn&#39;t built. &quot;</span>
                <span class="s2">&quot;You can build it manually via: &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;`</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">.build(batch_input_shape)`.&quot;</span>
            <span class="p">)</span>
    <span class="k">return</span> <span class="n">layer_utils</span><span class="o">.</span><span class="n">count_params</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="keras.engine.base_layer.Layer.finalize_state" class="doc doc-heading">
<code class="highlight language-python"><span class="n">finalize_state</span><span class="p">()</span></code>

<a href="#keras.engine.base_layer.Layer.finalize_state" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Finalizes the layers state after updating layer weights.</p>
<p>This function can be subclassed in a layer and will be called after
updating a layer weights. It can be overridden to finalize any
additional layer state after a weight update.</p>
<p>This function will be called after weights of a layer have been restored
from a loaded model.</p>

      <details class="quote">
        <summary>Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1885</span>
<span class="normal">1886</span>
<span class="normal">1887</span>
<span class="normal">1888</span>
<span class="normal">1889</span>
<span class="normal">1890</span>
<span class="normal">1891</span>
<span class="normal">1892</span>
<span class="normal">1893</span>
<span class="normal">1894</span>
<span class="normal">1895</span>
<span class="normal">1896</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@doc_controls</span><span class="o">.</span><span class="n">do_not_generate_docs</span>
<span class="k">def</span> <span class="nf">finalize_state</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Finalizes the layers state after updating layer weights.</span>

<span class="sd">    This function can be subclassed in a layer and will be called after</span>
<span class="sd">    updating a layer weights. It can be overridden to finalize any</span>
<span class="sd">    additional layer state after a weight update.</span>

<span class="sd">    This function will be called after weights of a layer have been restored</span>
<span class="sd">    from a loaded model.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">pass</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="airt._components.mono_dense_layer.MonoDense.get_config" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_config</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span></code>

<a href="#airt._components.mono_dense_layer.MonoDense.get_config" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Get config is used for saving the model</p>

      <details class="quote">
        <summary>Source code in <code>airt/_components/mono_dense_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get config is used for saving the model&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">units</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">units</span><span class="p">,</span>
        <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">org_activation</span><span class="p">,</span>
        <span class="n">monotonicity_indicator</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">monotonicity_indicator</span><span class="p">,</span>
        <span class="n">is_convex</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_convex</span><span class="p">,</span>
        <span class="n">is_concave</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_concave</span><span class="p">,</span>
        <span class="n">activation_weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">activation_weights</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="keras.engine.base_layer.Layer.get_input_at" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_input_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span></code>

<a href="#keras.engine.base_layer.Layer.get_input_at" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Retrieves the input tensor(s) of a layer at a given node.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>node_index</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Integer, index of the node
from which to retrieve the attribute.
E.g. <code>node_index=0</code> will correspond to the
first input node of the layer.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>A tensor (or list of tensors if the layer has multiple inputs).</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError">RuntimeError</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>If called in Eager mode.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2024</span>
<span class="normal">2025</span>
<span class="normal">2026</span>
<span class="normal">2027</span>
<span class="normal">2028</span>
<span class="normal">2029</span>
<span class="normal">2030</span>
<span class="normal">2031</span>
<span class="normal">2032</span>
<span class="normal">2033</span>
<span class="normal">2034</span>
<span class="normal">2035</span>
<span class="normal">2036</span>
<span class="normal">2037</span>
<span class="normal">2038</span>
<span class="normal">2039</span>
<span class="normal">2040</span>
<span class="normal">2041</span>
<span class="normal">2042</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@doc_controls</span><span class="o">.</span><span class="n">do_not_doc_inheritable</span>
<span class="k">def</span> <span class="nf">get_input_at</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_index</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Retrieves the input tensor(s) of a layer at a given node.</span>

<span class="sd">    Args:</span>
<span class="sd">        node_index: Integer, index of the node</span>
<span class="sd">            from which to retrieve the attribute.</span>
<span class="sd">            E.g. `node_index=0` will correspond to the</span>
<span class="sd">            first input node of the layer.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tensor (or list of tensors if the layer has multiple inputs).</span>

<span class="sd">    Raises:</span>
<span class="sd">      RuntimeError: If called in Eager mode.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span>
        <span class="n">node_index</span><span class="p">,</span> <span class="s2">&quot;input_tensors&quot;</span><span class="p">,</span> <span class="s2">&quot;input&quot;</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="keras.engine.base_layer.Layer.get_input_mask_at" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_input_mask_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span></code>

<a href="#keras.engine.base_layer.Layer.get_input_mask_at" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Retrieves the input mask tensor(s) of a layer at a given node.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>node_index</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Integer, index of the node
from which to retrieve the attribute.
E.g. <code>node_index=0</code> will correspond to the
first time the layer was called.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>A mask tensor</p>
            </div>
          </td>
        </tr>
        <tr>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>(or list of tensors if the layer has multiple inputs).</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1898</span>
<span class="normal">1899</span>
<span class="normal">1900</span>
<span class="normal">1901</span>
<span class="normal">1902</span>
<span class="normal">1903</span>
<span class="normal">1904</span>
<span class="normal">1905</span>
<span class="normal">1906</span>
<span class="normal">1907</span>
<span class="normal">1908</span>
<span class="normal">1909</span>
<span class="normal">1910</span>
<span class="normal">1911</span>
<span class="normal">1912</span>
<span class="normal">1913</span>
<span class="normal">1914</span>
<span class="normal">1915</span>
<span class="normal">1916</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@doc_controls</span><span class="o">.</span><span class="n">do_not_doc_inheritable</span>
<span class="k">def</span> <span class="nf">get_input_mask_at</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_index</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Retrieves the input mask tensor(s) of a layer at a given node.</span>

<span class="sd">    Args:</span>
<span class="sd">        node_index: Integer, index of the node</span>
<span class="sd">            from which to retrieve the attribute.</span>
<span class="sd">            E.g. `node_index=0` will correspond to the</span>
<span class="sd">            first time the layer was called.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A mask tensor</span>
<span class="sd">        (or list of tensors if the layer has multiple inputs).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_input_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="nb">getattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s2">&quot;_keras_mask&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="s2">&quot;_keras_mask&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="keras.engine.base_layer.Layer.get_input_shape_at" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_input_shape_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span></code>

<a href="#keras.engine.base_layer.Layer.get_input_shape_at" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Retrieves the input shape(s) of a layer at a given node.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>node_index</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Integer, index of the node
from which to retrieve the attribute.
E.g. <code>node_index=0</code> will correspond to the
first time the layer was called.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>A shape tuple</p>
            </div>
          </td>
        </tr>
        <tr>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>(or list of shape tuples if the layer has multiple inputs).</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError">RuntimeError</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>If called in Eager mode.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1982</span>
<span class="normal">1983</span>
<span class="normal">1984</span>
<span class="normal">1985</span>
<span class="normal">1986</span>
<span class="normal">1987</span>
<span class="normal">1988</span>
<span class="normal">1989</span>
<span class="normal">1990</span>
<span class="normal">1991</span>
<span class="normal">1992</span>
<span class="normal">1993</span>
<span class="normal">1994</span>
<span class="normal">1995</span>
<span class="normal">1996</span>
<span class="normal">1997</span>
<span class="normal">1998</span>
<span class="normal">1999</span>
<span class="normal">2000</span>
<span class="normal">2001</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@doc_controls</span><span class="o">.</span><span class="n">do_not_doc_inheritable</span>
<span class="k">def</span> <span class="nf">get_input_shape_at</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_index</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Retrieves the input shape(s) of a layer at a given node.</span>

<span class="sd">    Args:</span>
<span class="sd">        node_index: Integer, index of the node</span>
<span class="sd">            from which to retrieve the attribute.</span>
<span class="sd">            E.g. `node_index=0` will correspond to the</span>
<span class="sd">            first time the layer was called.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A shape tuple</span>
<span class="sd">        (or list of shape tuples if the layer has multiple inputs).</span>

<span class="sd">    Raises:</span>
<span class="sd">      RuntimeError: If called in Eager mode.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span>
        <span class="n">node_index</span><span class="p">,</span> <span class="s2">&quot;input_shapes&quot;</span><span class="p">,</span> <span class="s2">&quot;input shape&quot;</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="keras.engine.base_layer.Layer.get_output_at" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_output_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span></code>

<a href="#keras.engine.base_layer.Layer.get_output_at" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Retrieves the output tensor(s) of a layer at a given node.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>node_index</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Integer, index of the node
from which to retrieve the attribute.
E.g. <code>node_index=0</code> will correspond to the
first output node of the layer.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>A tensor (or list of tensors if the layer has multiple outputs).</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError">RuntimeError</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>If called in Eager mode.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2044</span>
<span class="normal">2045</span>
<span class="normal">2046</span>
<span class="normal">2047</span>
<span class="normal">2048</span>
<span class="normal">2049</span>
<span class="normal">2050</span>
<span class="normal">2051</span>
<span class="normal">2052</span>
<span class="normal">2053</span>
<span class="normal">2054</span>
<span class="normal">2055</span>
<span class="normal">2056</span>
<span class="normal">2057</span>
<span class="normal">2058</span>
<span class="normal">2059</span>
<span class="normal">2060</span>
<span class="normal">2061</span>
<span class="normal">2062</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@doc_controls</span><span class="o">.</span><span class="n">do_not_doc_inheritable</span>
<span class="k">def</span> <span class="nf">get_output_at</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_index</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Retrieves the output tensor(s) of a layer at a given node.</span>

<span class="sd">    Args:</span>
<span class="sd">        node_index: Integer, index of the node</span>
<span class="sd">            from which to retrieve the attribute.</span>
<span class="sd">            E.g. `node_index=0` will correspond to the</span>
<span class="sd">            first output node of the layer.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tensor (or list of tensors if the layer has multiple outputs).</span>

<span class="sd">    Raises:</span>
<span class="sd">      RuntimeError: If called in Eager mode.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span>
        <span class="n">node_index</span><span class="p">,</span> <span class="s2">&quot;output_tensors&quot;</span><span class="p">,</span> <span class="s2">&quot;output&quot;</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="keras.engine.base_layer.Layer.get_output_mask_at" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_output_mask_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span></code>

<a href="#keras.engine.base_layer.Layer.get_output_mask_at" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Retrieves the output mask tensor(s) of a layer at a given node.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>node_index</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Integer, index of the node
from which to retrieve the attribute.
E.g. <code>node_index=0</code> will correspond to the
first time the layer was called.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>A mask tensor</p>
            </div>
          </td>
        </tr>
        <tr>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>(or list of tensors if the layer has multiple outputs).</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1918</span>
<span class="normal">1919</span>
<span class="normal">1920</span>
<span class="normal">1921</span>
<span class="normal">1922</span>
<span class="normal">1923</span>
<span class="normal">1924</span>
<span class="normal">1925</span>
<span class="normal">1926</span>
<span class="normal">1927</span>
<span class="normal">1928</span>
<span class="normal">1929</span>
<span class="normal">1930</span>
<span class="normal">1931</span>
<span class="normal">1932</span>
<span class="normal">1933</span>
<span class="normal">1934</span>
<span class="normal">1935</span>
<span class="normal">1936</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@doc_controls</span><span class="o">.</span><span class="n">do_not_doc_inheritable</span>
<span class="k">def</span> <span class="nf">get_output_mask_at</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_index</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Retrieves the output mask tensor(s) of a layer at a given node.</span>

<span class="sd">    Args:</span>
<span class="sd">        node_index: Integer, index of the node</span>
<span class="sd">            from which to retrieve the attribute.</span>
<span class="sd">            E.g. `node_index=0` will correspond to the</span>
<span class="sd">            first time the layer was called.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A mask tensor</span>
<span class="sd">        (or list of tensors if the layer has multiple outputs).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_output_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="nb">getattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s2">&quot;_keras_mask&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">output</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="s2">&quot;_keras_mask&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="keras.engine.base_layer.Layer.get_output_shape_at" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_output_shape_at</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span></code>

<a href="#keras.engine.base_layer.Layer.get_output_shape_at" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Retrieves the output shape(s) of a layer at a given node.</p>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>node_index</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Integer, index of the node
from which to retrieve the attribute.
E.g. <code>node_index=0</code> will correspond to the
first time the layer was called.</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>A shape tuple</p>
            </div>
          </td>
        </tr>
        <tr>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>(or list of shape tuples if the layer has multiple outputs).</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/exceptions.html#RuntimeError">RuntimeError</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>If called in Eager mode.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">2003</span>
<span class="normal">2004</span>
<span class="normal">2005</span>
<span class="normal">2006</span>
<span class="normal">2007</span>
<span class="normal">2008</span>
<span class="normal">2009</span>
<span class="normal">2010</span>
<span class="normal">2011</span>
<span class="normal">2012</span>
<span class="normal">2013</span>
<span class="normal">2014</span>
<span class="normal">2015</span>
<span class="normal">2016</span>
<span class="normal">2017</span>
<span class="normal">2018</span>
<span class="normal">2019</span>
<span class="normal">2020</span>
<span class="normal">2021</span>
<span class="normal">2022</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@doc_controls</span><span class="o">.</span><span class="n">do_not_doc_inheritable</span>
<span class="k">def</span> <span class="nf">get_output_shape_at</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_index</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Retrieves the output shape(s) of a layer at a given node.</span>

<span class="sd">    Args:</span>
<span class="sd">        node_index: Integer, index of the node</span>
<span class="sd">            from which to retrieve the attribute.</span>
<span class="sd">            E.g. `node_index=0` will correspond to the</span>
<span class="sd">            first time the layer was called.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A shape tuple</span>
<span class="sd">        (or list of shape tuples if the layer has multiple outputs).</span>

<span class="sd">    Raises:</span>
<span class="sd">      RuntimeError: If called in Eager mode.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span>
        <span class="n">node_index</span><span class="p">,</span> <span class="s2">&quot;output_shapes&quot;</span><span class="p">,</span> <span class="s2">&quot;output shape&quot;</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="keras.engine.base_layer.Layer.get_weights" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_weights</span><span class="p">()</span></code>

<a href="#keras.engine.base_layer.Layer.get_weights" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Returns the current weights of the layer, as NumPy arrays.</p>
<p>The weights of a layer represent the state of the layer. This function
returns both trainable and non-trainable weight values associated with
this layer as a list of NumPy arrays, which can in turn be used to load
state into similarly parameterized layers.</p>
<p>For example, a <code>Dense</code> layer returns a list of two values: the kernel
matrix and the bias vector. These can be used to set the weights of
another <code>Dense</code> layer:</p>
<blockquote>
<blockquote>
<blockquote>
<p>layer_a = tf.keras.layers.Dense(1,
...   kernel_initializer=tf.constant_initializer(1.))
a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))
layer_a.get_weights()
[array([[1.],
       [1.],
       [1.]], dtype=float32), array([0.], dtype=float32)]
layer_b = tf.keras.layers.Dense(1,
...   kernel_initializer=tf.constant_initializer(2.))
b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))
layer_b.get_weights()
[array([[2.],
       [2.],
       [2.]], dtype=float32), array([0.], dtype=float32)]
layer_b.set_weights(layer_a.get_weights())
layer_b.get_weights()
[array([[1.],
       [1.],
       [1.]], dtype=float32), array([0.], dtype=float32)]</p>
</blockquote>
</blockquote>
</blockquote>

  <p><strong>Returns:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>Weights values as a list of NumPy arrays.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1841</span>
<span class="normal">1842</span>
<span class="normal">1843</span>
<span class="normal">1844</span>
<span class="normal">1845</span>
<span class="normal">1846</span>
<span class="normal">1847</span>
<span class="normal">1848</span>
<span class="normal">1849</span>
<span class="normal">1850</span>
<span class="normal">1851</span>
<span class="normal">1852</span>
<span class="normal">1853</span>
<span class="normal">1854</span>
<span class="normal">1855</span>
<span class="normal">1856</span>
<span class="normal">1857</span>
<span class="normal">1858</span>
<span class="normal">1859</span>
<span class="normal">1860</span>
<span class="normal">1861</span>
<span class="normal">1862</span>
<span class="normal">1863</span>
<span class="normal">1864</span>
<span class="normal">1865</span>
<span class="normal">1866</span>
<span class="normal">1867</span>
<span class="normal">1868</span>
<span class="normal">1869</span>
<span class="normal">1870</span>
<span class="normal">1871</span>
<span class="normal">1872</span>
<span class="normal">1873</span>
<span class="normal">1874</span>
<span class="normal">1875</span>
<span class="normal">1876</span>
<span class="normal">1877</span>
<span class="normal">1878</span>
<span class="normal">1879</span>
<span class="normal">1880</span>
<span class="normal">1881</span>
<span class="normal">1882</span>
<span class="normal">1883</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Returns the current weights of the layer, as NumPy arrays.</span>

<span class="sd">    The weights of a layer represent the state of the layer. This function</span>
<span class="sd">    returns both trainable and non-trainable weight values associated with</span>
<span class="sd">    this layer as a list of NumPy arrays, which can in turn be used to load</span>
<span class="sd">    state into similarly parameterized layers.</span>

<span class="sd">    For example, a `Dense` layer returns a list of two values: the kernel</span>
<span class="sd">    matrix and the bias vector. These can be used to set the weights of</span>
<span class="sd">    another `Dense` layer:</span>

<span class="sd">    &gt;&gt;&gt; layer_a = tf.keras.layers.Dense(1,</span>
<span class="sd">    ...   kernel_initializer=tf.constant_initializer(1.))</span>
<span class="sd">    &gt;&gt;&gt; a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))</span>
<span class="sd">    &gt;&gt;&gt; layer_a.get_weights()</span>
<span class="sd">    [array([[1.],</span>
<span class="sd">           [1.],</span>
<span class="sd">           [1.]], dtype=float32), array([0.], dtype=float32)]</span>
<span class="sd">    &gt;&gt;&gt; layer_b = tf.keras.layers.Dense(1,</span>
<span class="sd">    ...   kernel_initializer=tf.constant_initializer(2.))</span>
<span class="sd">    &gt;&gt;&gt; b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))</span>
<span class="sd">    &gt;&gt;&gt; layer_b.get_weights()</span>
<span class="sd">    [array([[2.],</span>
<span class="sd">           [2.],</span>
<span class="sd">           [2.]], dtype=float32), array([0.], dtype=float32)]</span>
<span class="sd">    &gt;&gt;&gt; layer_b.set_weights(layer_a.get_weights())</span>
<span class="sd">    &gt;&gt;&gt; layer_b.get_weights()</span>
<span class="sd">    [array([[1.],</span>
<span class="sd">           [1.],</span>
<span class="sd">           [1.]], dtype=float32), array([0.], dtype=float32)]</span>

<span class="sd">    Returns:</span>
<span class="sd">        Weights values as a list of NumPy arrays.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
    <span class="n">output_weights</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">weights</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">base_layer_utils</span><span class="o">.</span><span class="n">TrackableWeightHandler</span><span class="p">):</span>
            <span class="n">output_weights</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">get_tensors</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">backend</span><span class="o">.</span><span class="n">batch_get_value</span><span class="p">(</span><span class="n">output_weights</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>

<div class="doc doc-object doc-function">



<h4 id="keras.engine.base_layer.Layer.set_weights" class="doc doc-heading">
<code class="highlight language-python"><span class="n">set_weights</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span></code>

<a href="#keras.engine.base_layer.Layer.set_weights" class="headerlink" title="Permanent link">Â¤</a></h4>


  <div class="doc doc-contents first">
  
      <p>Sets the weights of the layer, from NumPy arrays.</p>
<p>The weights of a layer represent the state of the layer. This function
sets the weight values from numpy arrays. The weight values should be
passed in the order they are created by the layer. Note that the layer's
weights must be instantiated before calling this function, by calling
the layer.</p>
<p>For example, a <code>Dense</code> layer returns a list of two values: the kernel
matrix and the bias vector. These can be used to set the weights of
another <code>Dense</code> layer:</p>
<blockquote>
<blockquote>
<blockquote>
<p>layer_a = tf.keras.layers.Dense(1,
...   kernel_initializer=tf.constant_initializer(1.))
a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))
layer_a.get_weights()
[array([[1.],
       [1.],
       [1.]], dtype=float32), array([0.], dtype=float32)]
layer_b = tf.keras.layers.Dense(1,
...   kernel_initializer=tf.constant_initializer(2.))
b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))
layer_b.get_weights()
[array([[2.],
       [2.],
       [2.]], dtype=float32), array([0.], dtype=float32)]
layer_b.set_weights(layer_a.get_weights())
layer_b.get_weights()
[array([[1.],
       [1.],
       [1.]], dtype=float32), array([0.], dtype=float32)]</p>
</blockquote>
</blockquote>
</blockquote>

  <p><strong>Parameters:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Name</th>
        <th>Type</th>
        <th>Description</th>
        <th>Default</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>weights</code></td>
          <td>
          </td>
          <td>
            <div class="doc-md-description">
              <p>a list of NumPy arrays. The number
of arrays and their shape must match
number of the dimensions of the weights
of the layer (i.e. it should match the
output of <code>get_weights</code>).</p>
            </div>
          </td>
          <td>
              <em>required</em>
          </td>
        </tr>
    </tbody>
  </table>

  <p><strong>Raises:</strong></p>
  <table>
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
                <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/exceptions.html#ValueError">ValueError</a></code>
          </td>
          <td>
            <div class="doc-md-description">
              <p>If the provided weights list does not match the
layer's specifications.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

      <details class="quote">
        <summary>Source code in <code>/opt/hostedtoolcache/Python/3.9.16/x64/lib/python3.9/site-packages/keras/engine/base_layer.py</code></summary>
        <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">1748</span>
<span class="normal">1749</span>
<span class="normal">1750</span>
<span class="normal">1751</span>
<span class="normal">1752</span>
<span class="normal">1753</span>
<span class="normal">1754</span>
<span class="normal">1755</span>
<span class="normal">1756</span>
<span class="normal">1757</span>
<span class="normal">1758</span>
<span class="normal">1759</span>
<span class="normal">1760</span>
<span class="normal">1761</span>
<span class="normal">1762</span>
<span class="normal">1763</span>
<span class="normal">1764</span>
<span class="normal">1765</span>
<span class="normal">1766</span>
<span class="normal">1767</span>
<span class="normal">1768</span>
<span class="normal">1769</span>
<span class="normal">1770</span>
<span class="normal">1771</span>
<span class="normal">1772</span>
<span class="normal">1773</span>
<span class="normal">1774</span>
<span class="normal">1775</span>
<span class="normal">1776</span>
<span class="normal">1777</span>
<span class="normal">1778</span>
<span class="normal">1779</span>
<span class="normal">1780</span>
<span class="normal">1781</span>
<span class="normal">1782</span>
<span class="normal">1783</span>
<span class="normal">1784</span>
<span class="normal">1785</span>
<span class="normal">1786</span>
<span class="normal">1787</span>
<span class="normal">1788</span>
<span class="normal">1789</span>
<span class="normal">1790</span>
<span class="normal">1791</span>
<span class="normal">1792</span>
<span class="normal">1793</span>
<span class="normal">1794</span>
<span class="normal">1795</span>
<span class="normal">1796</span>
<span class="normal">1797</span>
<span class="normal">1798</span>
<span class="normal">1799</span>
<span class="normal">1800</span>
<span class="normal">1801</span>
<span class="normal">1802</span>
<span class="normal">1803</span>
<span class="normal">1804</span>
<span class="normal">1805</span>
<span class="normal">1806</span>
<span class="normal">1807</span>
<span class="normal">1808</span>
<span class="normal">1809</span>
<span class="normal">1810</span>
<span class="normal">1811</span>
<span class="normal">1812</span>
<span class="normal">1813</span>
<span class="normal">1814</span>
<span class="normal">1815</span>
<span class="normal">1816</span>
<span class="normal">1817</span>
<span class="normal">1818</span>
<span class="normal">1819</span>
<span class="normal">1820</span>
<span class="normal">1821</span>
<span class="normal">1822</span>
<span class="normal">1823</span>
<span class="normal">1824</span>
<span class="normal">1825</span>
<span class="normal">1826</span>
<span class="normal">1827</span>
<span class="normal">1828</span>
<span class="normal">1829</span>
<span class="normal">1830</span>
<span class="normal">1831</span>
<span class="normal">1832</span>
<span class="normal">1833</span>
<span class="normal">1834</span>
<span class="normal">1835</span>
<span class="normal">1836</span>
<span class="normal">1837</span>
<span class="normal">1838</span>
<span class="normal">1839</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Sets the weights of the layer, from NumPy arrays.</span>

<span class="sd">    The weights of a layer represent the state of the layer. This function</span>
<span class="sd">    sets the weight values from numpy arrays. The weight values should be</span>
<span class="sd">    passed in the order they are created by the layer. Note that the layer&#39;s</span>
<span class="sd">    weights must be instantiated before calling this function, by calling</span>
<span class="sd">    the layer.</span>

<span class="sd">    For example, a `Dense` layer returns a list of two values: the kernel</span>
<span class="sd">    matrix and the bias vector. These can be used to set the weights of</span>
<span class="sd">    another `Dense` layer:</span>

<span class="sd">    &gt;&gt;&gt; layer_a = tf.keras.layers.Dense(1,</span>
<span class="sd">    ...   kernel_initializer=tf.constant_initializer(1.))</span>
<span class="sd">    &gt;&gt;&gt; a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))</span>
<span class="sd">    &gt;&gt;&gt; layer_a.get_weights()</span>
<span class="sd">    [array([[1.],</span>
<span class="sd">           [1.],</span>
<span class="sd">           [1.]], dtype=float32), array([0.], dtype=float32)]</span>
<span class="sd">    &gt;&gt;&gt; layer_b = tf.keras.layers.Dense(1,</span>
<span class="sd">    ...   kernel_initializer=tf.constant_initializer(2.))</span>
<span class="sd">    &gt;&gt;&gt; b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))</span>
<span class="sd">    &gt;&gt;&gt; layer_b.get_weights()</span>
<span class="sd">    [array([[2.],</span>
<span class="sd">           [2.],</span>
<span class="sd">           [2.]], dtype=float32), array([0.], dtype=float32)]</span>
<span class="sd">    &gt;&gt;&gt; layer_b.set_weights(layer_a.get_weights())</span>
<span class="sd">    &gt;&gt;&gt; layer_b.get_weights()</span>
<span class="sd">    [array([[1.],</span>
<span class="sd">           [1.],</span>
<span class="sd">           [1.]], dtype=float32), array([0.], dtype=float32)]</span>

<span class="sd">    Args:</span>
<span class="sd">      weights: a list of NumPy arrays. The number</span>
<span class="sd">        of arrays and their shape must match</span>
<span class="sd">        number of the dimensions of the weights</span>
<span class="sd">        of the layer (i.e. it should match the</span>
<span class="sd">        output of `get_weights`).</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If the provided weights list does not match the</span>
<span class="sd">        layer&#39;s specifications.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>

    <span class="n">expected_num_weights</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">base_layer_utils</span><span class="o">.</span><span class="n">TrackableWeightHandler</span><span class="p">):</span>
            <span class="n">expected_num_weights</span> <span class="o">+=</span> <span class="n">param</span><span class="o">.</span><span class="n">num_tensors</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">expected_num_weights</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">expected_num_weights</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;You called `set_weights(weights)` on layer &quot;</span><span class="si">%s</span><span class="s1">&quot; &#39;</span>
            <span class="s2">&quot;with a weight list of length </span><span class="si">%s</span><span class="s2">, but the layer was &quot;</span>
            <span class="s2">&quot;expecting </span><span class="si">%s</span><span class="s2"> weights. Provided weights: </span><span class="si">%s</span><span class="s2">...&quot;</span>
            <span class="o">%</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span>
                <span class="n">expected_num_weights</span><span class="p">,</span>
                <span class="nb">str</span><span class="p">(</span><span class="n">weights</span><span class="p">)[:</span><span class="mi">50</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="n">weight_index</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">weight_value_tuples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">base_layer_utils</span><span class="o">.</span><span class="n">TrackableWeightHandler</span><span class="p">):</span>
            <span class="n">num_tensors</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">num_tensors</span>
            <span class="n">tensors</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">weight_index</span> <span class="p">:</span> <span class="n">weight_index</span> <span class="o">+</span> <span class="n">num_tensors</span><span class="p">]</span>
            <span class="n">param</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="n">tensors</span><span class="p">)</span>
            <span class="n">weight_index</span> <span class="o">+=</span> <span class="n">num_tensors</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">weight</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">weight_index</span><span class="p">]</span>
            <span class="n">weight_shape</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">shape</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="p">()</span>
            <span class="n">ref_shape</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">shape</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">ref_shape</span><span class="o">.</span><span class="n">is_compatible_with</span><span class="p">(</span><span class="n">weight_shape</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Layer </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2"> weight shape </span><span class="si">{</span><span class="n">ref_shape</span><span class="si">}</span><span class="s2"> &quot;</span>
                    <span class="s2">&quot;is not compatible with provided weight &quot;</span>
                    <span class="sa">f</span><span class="s2">&quot;shape </span><span class="si">{</span><span class="n">weight_shape</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="n">weight_value_tuples</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">param</span><span class="p">,</span> <span class="n">weight</span><span class="p">))</span>
            <span class="n">weight_index</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">backend</span><span class="o">.</span><span class="n">batch_set_value</span><span class="p">(</span><span class="n">weight_value_tuples</span><span class="p">)</span>

    <span class="c1"># Perform any layer defined finalization of the layer state.</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_layers</span><span class="p">():</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">finalize_state</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
      </details>
  </div>

</div>


  




                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            Back to top
          </button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      2022 onwards, AIRT Technologies d.o.o.
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
    and 
    <a href="https://nbdev-mkdocs.airt.ai/" target="_blank" rel="noopener">
      Material for nbdev
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../../../..", "features": ["navigation.instant", "navigation.indexes", "navigation.top", "search.suggest", "search.highlight", "search.share", "content.code.copy"], "search": "../../../../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../../../../assets/javascripts/bundle.b4d07000.min.js"></script>
      
        <script src="../../../../../overrides/js/extra.js"></script>
      
        <script src="../../../../../overrides/js/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>